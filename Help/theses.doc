<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="http://www.nongnu.org/elyxer/">
<meta name="create-date" content="2020-04-19">
<link rel="stylesheet" href="http://elyxer.nongnu.org/lyx.css" type="text/css" media="all">
<title>Converted document</title>
</head>
<body>
<div id="globalWrapper">
<div class="Standard">
<div class="center">
<span class="larger"><span lang="en"> </span></span><span class="huge"><br>
</span><span class="larger"> </span><span class="huge"><br>
Classification of Regulatory Sequences <br>
in the Human Genome Using Higher-Order <br>
Generalized Hidden Markov Model <br>
 <br>
סיווג קטעי בקרה מהגנום האנושי על ידי מודל מרקוב<span lang="en"><br>
חבוי מוכלל מסדר גבוה<span lang="en"> <br>
 <br>
</span></span></span>
</div>

</div>
<div class="Standard">
<div class="center">
<span lang="en">by<br>
<span class="larger">David Taub </span><span class="small">(302546163)</span></span>
</div>

</div>
<div class="Standard">
<div class="center">
<span lang="en">Supervised by<br>
<span class="larger">Prof. Tommy Kaplan<br>
 </span><span class="huge"><br>
</span><span class="larger"> </span><span class="huge"><br>
</span></span>
</div>

</div>
<div class="Standard">
<div class="center">
<span lang="en">A thesis submitted in partial fulfillment of the requirements for the<br>
degree of Master of Science in Computer Science</span>
</div>

</div>
<div class="Standard">
<div class="center">
<span class="large"><span lang="en">April 2020<br>
</span></span><span class="larger">ניסן תש"פ<span lang="en"> </span></span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span>
</div>

</div>
<div class="Standard">
<div class="center">
<span class="larger"><span lang="en">The Faculty of Computer Science and Engineering<br>
The Hebrew University of Jerusalem, Israel</span></span>
</div>

</div>
<div class="Standard">
<span lang="en"><p><br>
</p>
</span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--1"></a>תקציר
</h1>
<div class="Standard">
מעצמים )srecnahne( הם קטעי בקרה גנטיים שבהקשרם לחלבונים גורמי שעתוק )rotcaf noitpircsnart( הם מגבירים את סיכוי השעתוק של גן המטרה של המעצם. בקרת השעתוק היא צורה חשובה של בקרת ביטוי הגנים וממלאת תפקיד משמעותי בבקרת גנים יחודיים לשלבי תא ורקמות ספציפיים. במשך השנים נצטברו עדויות לכך ששינויים גנטיים ברצפי המעצמים עלולים לגרום לשינוי בהתנהגותם של תאים ולמחלות. הכללים והדקויות של מבנה המעצם טרם הובנו לחלוטין, אף כי ניסויים הראו כי גורמי שעתוק נוטים להצמד לאתרי קשירה של גורמי שעתוק, שהם מוטיבים יחודיים אשר נפוצים יחסית בקטעי המעצמים. ניתן לאתר את פעילות המעצם לפי מידע אפיגנטי בסביבתו, כשהסימנים העיקריים הם השינויי בהיסטונים )snoitacifidom enotsih( אשר סביבם כרוכים אגפי המעצם. המעצם נוטה להיות נגיש מרחבית עבור אינטראקציות ביוכימיות בין ה-AND לחלבונים שסביבו. על אף תועלתו הרבה, המידע האפיגנטי לעיתים קרובות רועש ומצריך תהליכים יקרים של חילוץ תאים ספציפיים מתוך רקמותיהם, פעולה אשר לא תמיד ברת ביצוע לכלל סוגי התאים בשלביהם השונים. דרך נוספת לזיהוים של מעצמים היא בחינת תוכנם של רצפם הגנטי, משום שבהם נמצא כל המידע הדרוש ל-AND על מנת שיתחיל לפעול כמעצם. ניסויים אשר נערכו בחיות מעבדה הראו כי התא איננו זקוק למנגנון נוסף מעבר לרצף הגנטי על מנת לגרום לבקרת הגנים שבו. בשל תפישה זו, אנו מציעים גישה חישובית לזיהוי של מעצמים על בסיס רצפם הגנטי בלבד, בדרך למידה לא מונחית. יצרנו מודל מרקוב חבוי מסדר גבוה מבוסס מטריצות משקול מיקום, בעלי שני סוגי מצבים: מצב אחד אשר פולט אתרי קשירה של גורמי שעתוק מתוך מטריצות משקול מקום, ואחד אשר פולט נוקלאוטידים בודדים תוך תלות מסדר גבוה באלה שנפלטו לפניהם. בהשוואה למודל מרקוב חבוי רגיל, מודל זה לומד מבנה מורכב יותר של הרצף הגנטי, אשר מכיל מוטבים של אתרי קשירה והתפלגות מסדר גבוה של נוקלאוטידים המצויים בינהם. אנו נבחן תחילה את הרקע הביולוגי של המעצמים, תוך התרכזות בבני אדם. לאחר מכן נסקור לעומק את הרקע של מודלי מרקוב חבויים, ונדון בדרך לחישוב הנראות )doohilekil( של רצפים בהנתן המודל. נתאר לפרטים את המודל המוכלל שלנו ונפתח את אלגוריתם מיקסום התוחלת )noitazimixam noitatcepxe( ואת אלגוריתם ויטרבי עבור מודלי מרקוב חבויים, ולאחר מכן את ההתאמות הנדרשות עבור המודל המוכלל שלנו. מימושי האלגוריתמים הללו מוצגים על ידי הפעלתם על מידע סינטטי של רצפים דמויי-מעצמים אשר נוצרו תוך שימו ביכולת הגנרטיבית של מודל המרקוב החבוי המוכלל. אנו מדמים למודל סביבה מבוקרת על מנת להעריך את ביצועיו בשיערוך פרמטרי המודל והשוואתם לפרמטרים האמיתיים בהם היה שימוש עבור יצירת המידע. לסיום, אני מבצעים את אלגוריתם מיקסום התוחלת על מנת לאמן את המודל שלנו על רצפים גנטיים של מעצמים אנושיים, אשר נבחרו לפי המידע האפיגנטי של פרוייקט ה-pamdaoR. אנו מדגימים את יכולות המודל על ידי השוואת שיערוכו למידע האפיגנטי של הרצפים, ומראים כי המודל מסוגל לחזות את מיקומם בגנום של המעצמים ואת הרקמה בהם יופעלו, ללא חשיפה מוקדמת למידע אפיגנטי.
</div>
<div class="Standard">
<span lang="en"><p><br>
</p>
</span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--2"></a><span lang="en">Abstract</span>
</h1>
<div class="Standard">
<span lang="en">Enhancers are regulatory DNA sequences that, when bound to proteins called transcription factors, increase the likelihood of transcription of the enhancer target genes. Regulation of transcription is an important form of control of gene expression, and the activity of enhancers plays a significant role in the stage-specific and tissue-specific regulation of genes. It has been shown over the years that genetic variations within enhancer sequences might cause cell behavior modifications and diseases. The rules and nuances of enhancer structure is not fully understood yet, though it has been shown that transcription factors tend to attach to them at unique motifs called transcription factor binding sites, which are over-represented in enhancer sequences. Enhancer activity can be detected by the epigenetic data from the local environment around its position. The main indicators for an enhancer lay in the adjacent histone modifications, around which the flanks of the enhancer are wrapped. The enhancer itself tends to be spatial accessible for biochemical interactions between the DNA and the proteins around it. Though useful, the epigenetic data are often noisy and require a costly extraction process of specific cells out of a tissue sample, which is not necessarily practical for all cell types and their different stages. An alternative approach to enhancer detection is to observe the genetic content of its sequence, since it contains all the essential information for the DNA to act as an enhancer. Over the years, it was demonstrated <i>in vivo</i> that the cell requires no other mechanism than the genetic sequence in order to regulate its gene expression. With that idea in mind, we offer a computational approach for the detection of enhancers based on their sequences alone, and in an unsupervised manner. We created a higher-order positional weight matrix based hidden Markov model (HOP-HMM), with two kinds of states: one which emits transcription factor binding sites by using a positional weight matrix model, and one which emits single nucleotides with higher-order dependency on previously emitted nucleotides. Compared to a regular hidden Markov model, this model learns a more complex underlying structure of DNA sequences, containing both binding site motifs and higher-order distribution of nucleotides in between them. We’ll first review the biological background of enhancers, specifically in humans. Then we’ll review in depth the background of Markov and hidden Markov models, and discuss how to calculate the likelihood of a sequence given this model. We’ll describe our generalized model in detail and develop the expectation maximization and Viterbi algorithms for hidden Markov models, followed by the adjustments needed for our generalized model. These algorithms implementations are demonstrated by applying them to a synthetic dataset of enhancer-like sequences created by using the generative property of the generalized model. We simulate the model in a controlled way to evaluate its performance by inferring estimated parameters of the model and comparing them to the real parameters used to create the dataset. Finally, we apply the expectation maximization algorithm for training a HOP-HMM from human DNA enhancer sequences, selected by the epigenetic data of the Roadmap project. We demonstrate the capabilities of the model by comparing its estimation to the epigenetic tracks, showing it can predict the loci of enhancers and in which tissues they will be active, without exposure to epigenetic data. </span>
</div>
<div class="Standard">
<span lang="en"><p><br>
</p>
</span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--3"></a><span lang="en">Introduction</span>
</h1>
<div class="Standard">
<span lang="en">The genome of every living organism contains the inherited information which defines its complex structure and function. The genome is built out of deoxyribonucleic acid (DNA) molecules, a structure of two chains of nucleotides units forming a double helix shape. Nucleotides are built out of 4 different basic elements: cytosine, guanine, adenine or thymine or in short A,C,G and T. The nucleotides are organized in pairs called base pairs, with each of the paired nucleotides being complementary to the other and providing redundancy. </span>
</div>
<div class="Standard">
<span lang="en">Proteins are macromolecules, which ensure various roles and functions within organisms. They have the structure of a polymer built out of 20 different amino acids, whose order and structure are encoded in genes (genetic segments within the genome). Through transcription followed by translation processes, the genes are expressed and result in the formation of proteins. In the transcription process the gene is read and transcribed into a single strand sequence of RNA. Later, the formed RNA molecule, which at this stage is called messenger RNA (mRNA), is translated by a complex molecule called the ribosome. The mRNA sequence is built out of triplets of nucleotides called codons, which are read by the ribosome and instruct it how to generate a sequence of amino acids constituting the protein. </span>
</div>
<div class="Standard">
<span lang="en">Gene sequences are built out of fragmented introns and exons, where only the exons mature into mRNA molecules which are translated into proteins, while the introns are spliced away beforehand. Counter intuitively, even though the exons hold the recipe for the construction of the proteins of the organism, its complexity is not a product of their number or their length. For example, both humans and Caenorhabditis elegans roundworms have about 19,000 genes with roughly the same total exon length and number (<span class="bibcites">[<a class="bibliocite" name="cite-2" href="#biblio-2">2</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-20" href="#biblio-20">20</a>]</span>), even though the human body is much more diverse and complex. Although the genes are responsible for the variety of proteins a cell can produce, the source of organism complexity, with different cells performing different tasks while carrying the same genome, stems from the gene regulation mechanism. In the case of humans, the genome is 3.23 Gb long and it is estimated that the total length of gene regulation regions involves 10-20% of it (<span class="bibcites">[<a class="bibliocite" name="cite-48" href="#biblio-48">48</a>]</span>), compared to exon regions which involve only 1% (<span class="bibcites">[<a class="bibliocite" name="cite-46" href="#biblio-46">46</a>]</span>).</span>
</div>
<div class="Standard">
<span lang="en">Enhancers are non-coding regulatory DNA sequences which play a key role in the regulation transcription of genes. In humans, there are hundreds of thousands of enhancers scattered over the non-coding regions of the genome, usually of a length between 100-1000 base pairs (bp). When activated, the DNA folding draws the enhancer spatially closer to another type of regulatory element called promoter, resulting in the translation of the gene adjacent to the promoter (see figure <a class="Reference" href="#Transcription">1↓</a>). The gene expressed by this activation process is the enhancer’s target gene, and it can be located up to one megabase pair (Mb) upstream or downstream from its activating enhancer as enhancers generally function independently of orientation (<span class="bibcites">[<a class="bibliocite" name="cite-67" href="#biblio-67">67</a>]</span>). Moreover, the gene-enhancer connection is not exclusive, and it has been shown that the most common case is that each enhancer has several target genes and vice-versa (<span class="bibcites">[<a class="bibliocite" name="cite-22" href="#biblio-22">22</a>]</span>).</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Transcription"> </a><div class="figure">
<div class="left">
<span lang="en"><img class="embedded" src="Figures/Enhancer_gene_transcription.jpg" alt="figure Figures/Enhancer_gene_transcription.jpg">
<div class="caption">
Figure 1 <span lang="en"><b>A)</b> An enhancer and its distal target gene. <b>B)</b> The DNA folds and the attaches to transcription factors, which then draw other co-factor proteins that together form the transcription complex. <b>C)</b> The RNA Polymerase II is recruited and while moving along the gene, it generates a new RNA molecule which is transcribed off the gene. </span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<div class="left">
<span lang="en">An enhancer is described as being in an active status when it is causing the expression of its target gene, which does not occur evenly across different types of cells. The activity of the enhancer sequence plays a critical role in the resulting type of cells. In the VISTA Project (<span class="bibcites">[<a class="bibliocite" name="cite-64" href="#biblio-64">64</a>]</span>), fertilized mouse eggs were injected with enhancer sequences adjacent to a LacZ reporter gene, encoding an enzyme protein with a blue color. Since they were synthesized, the injected DNA sequences containing the enhancer and reporter genes bore no epigenetic information, and they were integrated into the mouse genome in an arbitral position. The enhancers in the injected DNA sequences originated from the human genome, and each enhancer was injected into a different embryo. When the transgenic embryos were photographed after 11.5 days some had a distinctive anatomical pattern, such as blue limbs or blue spine, depending on the injected DNA sequence. These results imply that for many DNA sequences, the DNA code possesses by itself the potential to become a specific tissue enhancer, despite the absence of epigenetic information.</span>
</div>

</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Mouse"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/f735.jpg" alt="figure Figures/f735.jpg">
<img class="embedded" src="Figures/experiment_process.png" alt="figure Figures/experiment_process.png">
<div class="caption">
Figure 2 <span lang="en">Transgenic mouse embryo on the 11.5 day. A fertilized egg was injected with a synthetic enhancer sequence known to be related to the dorsal root ganglia of spinal neurons. The enhancer became activated and caused the expression of the blue color marker gene that was coupled to it. Both images are taken from Vista Enhancer Browser, on the left is experiment hs-51 embryo 2.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">Transcription factors (TF) are proteins that bind to the DNA, and together with other cofactor proteins initiate the gene transcription process of the DNA sequence. TFs tend to bind to their transcription factor binding sites (TFBS), which are motifs of nucleotides in the DNA sequence. The average length of TFBS in humans is 12 bp (<span class="bibcites">[<a class="bibliocite" name="cite-38" href="#biblio-38">38</a>]</span>), and they are highly conserved between various species (<span class="bibcites">[<a class="bibliocite" name="cite-14" href="#biblio-14">14</a>]</span>). When analyzing a tissue sample for TF interaction density, a chromatin immunoprecipitation sequencing (ChIP-seq) method is used to probe the amount of TFs in affinity to the DNA strands. Briefly, this method involved applying antibodies on cross-linked DNA, which attach to the TFs linked to the DNA. This antibody attachment is followed by massive parallel sequencing of the short DNA sequences around the TF and the antibody. Genome-wide association studies (GWAS) of ChIP-seq found that different TFs have different and distinct distributions of TFBS (<span class="bibcites">[<a class="bibliocite" name="cite-35" href="#biblio-35">35</a>]</span>).</span>
</div>
<div class="Standard">
<span lang="en">The TFBSs in both enhancers and promoters are critical for their correct regulatory activity. Multiple studies have shown that genetic alterations in enhancer’s TFBSs can affect the expression of their target genes and are a major cause of various human diseases (<span class="bibcites">[<a class="bibliocite" name="cite-37" href="#biblio-37">37</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-45" href="#biblio-45">45</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-56" href="#biblio-56">56</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-55" href="#biblio-55">55</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-5" href="#biblio-5">5</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-17" href="#biblio-17">17</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-41" href="#biblio-41">41</a>]</span>). From the sequence aspect, enhancers and promoters have a similar structure: both have different nucleotide frequencies compared to other parts of the genome, and both contain TFBSs tiled inside background sequences.</span>
</div>
<div class="Standard">
<span lang="en">Folding of the DNA allows enhancer-promoter interactions, in which the TFs play a major part. Once bounded to the DNA, the TFs recruit other protein cofactors, and together they form a transcription preinitiation complex (PIC), consisting of a very large assembly of proteins. Out of the tens of proteins constructing the PIC, the sub-unit RNA polymerase (RNA pol II) has the important role of transcribing the adjacent gene. It slides along the double-stranded DNA and opens it until one strand of nucleotides is exposed and becomes a template for RNA synthesis.</span>
</div>
<div class="Standard">
<span lang="en">Though it is tempting to imagine each TF as having a corresponding TFBS with a single motif of nucleotides that fits it, modeling the kinetic and thermodynamic aspects involved in the DNA-protein interaction is far from simple (<span class="bibcites">[<a class="bibliocite" name="cite-68" href="#biblio-68">68</a>]</span>), and each sequence of nucleotides has the likelihood to form a bond, which is not simple to calculate analytically. In order to generate a simplistic yet statistically accurate model representing the TF binding potential of a DNA sequence, i.e. <span class="formula"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>n</i></sub>|<i>binding</i><span class="symbol">)</span></span>, we need to assume an independence between positions as well as a small range of influence of the sequence around the binding site. For samples of such distribution, the peaks of the ChIP-seq readings marking the TF binding are often used, from which a binding site “grammar” can be modeled. Position weight matrix (PWM), as introduced in <span class="bibcites">[<a class="bibliocite" name="cite-58" href="#biblio-58">58</a>]</span>, is the most commonly used probabilistic model to address this task. The underlying assumption of the PWM model is that every position in the DNA sequence has an independent probability to attach to the TF, and therefore the total binding probability is a multiplication of all the per-position probabilities in the motif:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>J</i></sub>|<i>binding</i><span class="symbol">)</span> = <span class="limits"><span class="limit">∏</span></span><sub><i>j</i> ∈ [<i>n</i>]</sub><i>P</i><span class="symbol">(</span><i>x</i><sub><i>j</i></sub>|<i>binding</i><span class="symbol">)</span>
</div>
Where <span class="formula"><i>J</i></span> is the length of the relevant sequences affected by the binding event, and is derived from the physical characteristics of the TF. Practically, this size is often estimated from the observed motifs in the TF’s ChIP-seq peaks. For each <span class="formula"><i>j</i></span>, <span class="formula"><i>P</i><span class="symbol">(</span><i>x</i><sub><i>j</i></sub>|<i>binding</i><span class="symbol">)</span></span> is estimated by counting the frequency of the nucleotides in the <span class="formula"><i>j</i></span>’th position of the observed binding sites which are situated in the ChIP-seq peaks. For a motif of length <span class="formula"><i>J</i></span>, the estimation of this probability is stored in a position probability matrix (PPM) W as followed: </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>W</i><sub><i>i</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>N</i></span><span class="ignored">)</span></span><span class="limits"><span class="limit">∑</span></span><sub><i>n</i> ∈ [<i>N</i>]</sub><b>1</b><span class="symbol">(</span><i>x</i><sub><i>j</i></sub><sup>(<i>n</i>)</sup> = <i>i</i><span class="symbol">)</span>
</div>
where <span class="formula"><i>x</i><sup>(<i>n</i>)</sup></span> is the n’th sequence of the found binding sites, <span class="formula"><i>j</i> ∈ [<i>J</i>]</span> the position in the motif and <span class="formula"><i>i</i> ∈ [4]</span> the nucleotide index of A,C,G and T. To enable comparison between the binding likelihood of TFBS of different lengths, the use of the normalized form of PPM, the PWM, is more convenient:<div class="formula">
<a class="eqnumber" name="PPM">(1) </a><span class="displaystyle"><i>M</i></span><sub><i>i</i>, <i>j</i></sub> = <span class="mathrm">log</span><span class="symbol">(</span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>W</i><sub><i>i</i>, <i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>b</i><sub><i>i</i></sub></span><span class="ignored">)</span></span><span class="symbol">)</span>
</div>
where <span class="formula"><i>b</i><sub><i>i</i></sub></span> is the prior background model, which is 0.25 in case of nucleotides. From a generative model point of view, the TFBS sequence is generated by an emission model of the PWM. When a convolution of <span class="formula"><i>M</i></span> is applied on the one-hot encoding of the sequence (see figure <a class="Reference" href="#PWM">3↓</a>), the result is the log likelihood of a TF binding to a sequence relative to a random sequence. In this work we’ll use the more familiar term PWMs though we actually used the unnormalized PPMs for the TFBS emission model, since we required the likelihood of a TF binding and not a length-independent comparison between TFs. </span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="PWM"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/pwm_mult.jpg" alt="figure Figures/pwm_mult.jpg">
<div class="caption">
Figure 3 <span lang="en">Sub-sequences out of the DNA are represented in a one-hot encoding, and multiplied entry-wise by a PWM. Then, the sum of the logs of the maximal values in each column of the resulting matrix is calculated, which represents the log likelihood of the TF binding to the sub-sequence. This log likelihood is calculated for each location in the sequence, in which locations with high values indicate a high likelihood of TF binding.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">Detection of enhancers and of the tissues in which they are active has been the subject of much research in the last few decades. Specifically, an enhancer detection method relying only on their sequences and without need for biological experimentation is an especially sought-after goal. Such biological experiments, some of which are mentioned in this work, involve cells whose enhancers activate their target genes during the experiment, which is usually an expensive and non-trivial requirement. All methods for detecting active enhancers “in the act” are inherently limited to the specific tissues we can extract and isolate in a lab. Furthermore, many enhancers are only active in specific cell types and at specific stages, and achieving a study of every cell type at every possible stage in complex organisms is not a practical requirement for the foreseeable future. On the other hand, the genome of organisms can be easily and inexpensively sequenced for later analysis <i>in silico</i>. The ultimate goal of an efficient computational method which would predict and explain the functional nature of an enhancer sequence has produced positive, yet far from sufficient results over the last years, as reviewed in (<span class="bibcites">[<a class="bibliocite" name="cite-36" href="#biblio-36">36</a>]</span>).</span>
</div>
<div class="Standard">
<span lang="en">As an alternative, a potential way of detecting enhancers only by addressing their sequences, would consist in finding non-coding regions which are conserved across species. Conserved non-coding elements (CNE) have a tendency to reside in clusters, which usually have low gene density but are located in vicinity to genes (<span class="bibcites">[<a class="bibliocite" name="cite-47" href="#biblio-47">47</a>]</span>). Evidently, the overlap between CNEs and enhancers is imprecise. Some verified enhancers are weakly (or not) conserved between species (<span class="bibcites">[<a class="bibliocite" name="cite-23" href="#biblio-23">23</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-54" href="#biblio-54">54</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-60" href="#biblio-60">60</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-42" href="#biblio-42">42</a>]</span>) and some highly conserved areas in the mouse genome are not associated to regulatory activity, but their deletion still yields viable mice (<span class="bibcites">[<a class="bibliocite" name="cite-1" href="#biblio-1">1</a>]</span>). Nevertheless, an assay of elements with 100% sequence identity of over 200 bp between human and mouse found that 50% showed enhancer activity in mice (<span class="bibcites">[<a class="bibliocite" name="cite-64" href="#biblio-64">64</a>]</span>). The ultra-conservation of 200 bp enhancer sequences containing TFBSs that are usually shorter than 15 bp raises the possibility that these conserved iter-TFBS parts play a role which it is not yet fully clear.</span>
</div>
<div class="Standard">
<span lang="en">Almost all cells in every organism contain their entire genomic payload, but only part of this genome is active in any specific cell. Essentially, cells of different type and state differ by gene expression patterns. The reason for this difference between cells lays in regulation components not included in the Watson and Crick model of the DNA sequence. The location and presence of TFBS, background nucleotides distribution and other sequence-related properties are not sufficient to explain the regulatory role of certain regions in the genome. </span>
</div>
<div class="Standard">
<span lang="en">Several epigenetic features, which do not involve the genetic code directly, correlate with enhancer regions in the genome: </span>
</div>
<ul>
<li>
<span lang="en">Accessibility</span>
</li>
<li>
<span lang="en">TF &amp; cofactors binding</span>
</li>
<li>
<span lang="en">Histone modifications</span>
</li>
<li>
<span lang="en">DNA methylation</span>
</li>

</ul>
<div class="Standard">
<span lang="en">These mechanisms have measurable features that can be added as a data layer, on top of the genome. Their combination is the main source of identification and prediction for enhancer regions in the genome. A single cell has its own epigenetic features, often in binary form, e.g. a specific element of the genome can be either accessible or not. When several cells epigenetic properties are measured, usually a frequency or count of the measured feature per DNA locus is calculated along the reference genome. The epigenetic data is commonly further processed by calculating its p-value compared to a local environment, to which peak boundaries are determined (peak calling) using algorithms such as MACS2 (<span class="bibcites">[<a class="bibliocite" name="cite-71" href="#biblio-71">71</a>]</span>).</span>
</div>
<div class="Standard">
<span lang="en">In eukaryotes, the DNA is packed around a structure of 8 histone proteins called a nucleosome, and they form together a chromatin complex. Similarly to the TFs, the nucleosome binding location in the DNA sequence is not arbitrary. Like them, it has a tendency for specific DNA binding sites (<span class="bibcites">[<a class="bibliocite" name="cite-11" href="#biblio-11">11</a>]</span>). The DNA wrapped around a nucleosome has a lesser likelihood for interaction with proteins, because it is physically inaccessible. Accessibility enables the TFs and other proteins to bind to the DNA molecule, hence the enhancer, the promoter and the gene all need to be accessible for a successful transcription to occur. DNase-I hypersensitive (DHS) sites are regions of the DNA which are sensitive to cleavage by the DNase-I enzyme. In these regions the DNA loses the nucleosome, and becomes accessible and therefore potentially active. Measurement of DHS cleavages is available through DNase-seq (<span class="bibcites">[<a class="bibliocite" name="cite-6" href="#biblio-6">6</a>]</span>), a high-throughput method for measuring the accessibility epigenetic data of the DNA, usually with a better resolution than histone modifications measurements. A faster and more sensitive technique for accessibility measurement is called ATAC-seq (<span class="bibcites">[<a class="bibliocite" name="cite-8" href="#biblio-8">8</a>]</span>), and is currently more commonly used. </span>
</div>
<div class="Standard">
<span lang="en">Histone modifications, also called histone marks and chromatin modifications, are chemical alterations which happen to the long tail-like section of the histone protein. Histones are numbered from 1 to 8, and for example, the acetylation of the lysine amino-acid situated in 14th position in the protein of the 3rd histone will be abbreviated as H3K14ac. Along many roles in the cell, such as DNA repair and mitosis, histone modifications have a function in the gene regulation processes. In the past 20 years, a substantial body of research has shown that histone modifications are predictive of enhancer position and activity status (<span class="bibcites">[<a class="bibliocite" name="cite-64" href="#biblio-64">64</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-28" href="#biblio-28">28</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-24" href="#biblio-24">24</a>]</span>). The histone modifications are considered to form a certain &ldquo;histone code” along the genome, which encodes complex information underlying the genomic code and is connected to transcription regulation and other aspects. Compared to other epigenetic information, chromatin modifications have a shorter time scale ranging from seconds to hours (<span class="bibcites">[<a class="bibliocite" name="cite-26" href="#biblio-26">26</a>]</span>), and are therefore considered related to the dynamic changes of the cell.</span>
</div>
<div class="Standard">
<span lang="en">Measurement of histone modifications is also performed using the ChIP-seq method, similarly to the TF binding detection described above. In histone ChIP-seq, antibodies attach to the modifications in the histone tails (and not to the TF proteins). H3K4me1 and H3K27ac are among the predominant histone modifications of active enhancers; H3K4me1 is enriched on transcribed genes and enhancers prior to activation (<span class="bibcites">[<a class="bibliocite" name="cite-58" href="#biblio-58">58</a>]</span>), and is thought to precede the H3K27ac modification (<span class="bibcites">[<a class="bibliocite" name="cite-59" href="#biblio-59">59</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-53" href="#biblio-53">53</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-70" href="#biblio-70">70</a>]</span>) which is known to occur during activation. Other histone modifications present on active enhancers and used for their detection are H3K9ac (<span class="bibcites">[<a class="bibliocite" name="cite-19" href="#biblio-19">19</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-33" href="#biblio-33">33</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-70" href="#biblio-70">70</a>]</span>) and H3K18ac (<span class="bibcites">[<a class="bibliocite" name="cite-30" href="#biblio-30">30</a>]</span>). Even though H3K27ac has been identified as an important mark for the differentiation of active enhancers from poised enhancers (<span class="bibcites">[<a class="bibliocite" name="cite-59" href="#biblio-59">59</a>]</span>), it is not sufficient by itself since when present alongside H3K4me3 it is also an indication for active promoters (<span class="bibcites">[<a class="bibliocite" name="cite-27" href="#biblio-27">27</a>]</span>). In contrast, absence of H3K27ac and enrichment of H3K4me1and H3K27me3 are typical of poised enhancers (<span class="bibcites">[<a class="bibliocite" name="cite-59" href="#biblio-59">59</a>]</span>).<br>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Enhancer"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/Enhancers_status.jpg" alt="figure Figures/Enhancers_status.jpg">
<div class="caption">
Figure 4 <span lang="en">The accessibility of an enhancer’s sequence and its surrounding histone modifications are connected to its regulatory activity state. The upper diagram shows an active enhancer sequence accessible to the protein interaction needed for transcription, whereas the lower one shows an inactive enhancer wrapped around a nucleosome and therefore inaccessible.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">DNA methylation of cytosine nucleotides and cytosine guanine nucleotides pairs (CpG) has been involved in long-term genome silencing in multiple processes (<span class="bibcites">[<a class="bibliocite" name="cite-31" href="#biblio-31">31</a>]</span>) and cell aging (<span class="bibcites">[<a class="bibliocite" name="cite-49" href="#biblio-49">49</a>]</span>). It has been documented as widely correlated with inhibition of gene expression when present in promoters (<span class="bibcites">[<a class="bibliocite" name="cite-61" href="#biblio-61">61</a>]</span>). In enhancer elements, an anti-correlation was found between DNA methylation density and enrichment of active enhancer histone modifications, and TF binding (<span class="bibcites">[<a class="bibliocite" name="cite-57" href="#biblio-57">57</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-62" href="#biblio-62">62</a>]</span>), although the cause and consequence relationships underlying these correlations is not yet clear. Currently, the most accurate method for the wide-scale prediction of the loci of enhancer sequences in a genome is the analysis of histone modifications, and TF and cofactors presence using ChIP-seq from a cell line or from a tissue, combined with DNase-I hypersensitivity (DHS). </span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="GenomeBrowser"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/genome_browser.png" alt="figure Figures/genome_browser.png">
<div class="caption">
Figure 5 <span lang="en">UCSC Genome Browser showing epigenetic features tracks, taken from the 10th chromosome of a H1-hESC cell line. Highlighted in light blue, the peaks of H3K27ac (1st green plot) and H3K4me1 (2nd green plot) histone modifications and the DNase-I hypersensitivity features (4th green plot), together with the absence of H3K27me3 (3rd green plot) signal indicate an active enhancer, as also marked by the ChromHMM classification (bottom). Note that the decrease between the two peaks of H3K27ac and H3K4me1 is located on top of the increase of the DNase-I hypersensitivity, which implies a cleavage in between two nucleosomes with modifications. Taken from <a class="FlexURL" href="https://genome-euro.ucsc.edu/cgi-bin/hgTracks">https://genome-euro.ucsc.edu/cgi-bin/hgTracks</a></span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--1"></a><span lang="en">Related Work</span>
</h3>
<div class="Standard">
<span lang="en">Several significant computational efforts were made in the last few years for predicting the epigenetic and regulatory properties of DNA elements based on the genetic sequence alone. DeepSEA (<span class="bibcites">[<a class="bibliocite" name="cite-72" href="#biblio-72">72</a>]</span>) uses a deep convolutional neural network (DCNN) which receives an input of 1000 bp sequence, and outputs a prediction vector of 919 binary features representing the chromatin modifications of 200 bp in the center of the input sequence. The training labels used are the chromatin modifications extracted from ENCODE and Roadmap epigenetic data releases. Basset (<span class="bibcites">[<a class="bibliocite" name="cite-35" href="#biblio-35">35</a>]</span>) also used DCNN on the same data, with known PWMs as weight initialization, to predict a binary vector representing accessibility in 164 cell types, based on 600 bp DNA sequences. In DeepBind (<span class="bibcites">[<a class="bibliocite" name="cite-3" href="#biblio-3">3</a>]</span>) a DCNN was used to predict binding of 538 TFs and 194 RNA binding proteins from DNA sequences of varying lengths. In gkm-SVM (<span class="bibcites">[<a class="bibliocite" name="cite-12" href="#biblio-12">12</a>]</span>), gapped <i>k</i>-mers presence indicator vectors were used as features for a SVM classifier in order to predict the role of DNA sequences of varying lengths. ChromHMM (<span class="bibcites">[<a class="bibliocite" name="cite-18" href="#biblio-18">18</a>]</span>) is a widely used software that tackles the problem of analyzing the epigenetic data to predict the role of fragments of genomic sequence. The algorithm converts to binary the chromatin modification values by whether or not it exceeded a threshold, which is then inserted as input to HMM that classifies the genome states. A disadvantage of these methods is their need for training data of known regulatory elements or epigenetic data which are commonly obtained from GWAS surveys, such as those that were done on 127 obtained human cell types in the Roadmap and ENCODE projects (<span class="bibcites">[<a class="bibliocite" name="cite-39" href="#biblio-39">39</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-19" href="#biblio-19">19</a>]</span>). </span>
</div>
<div class="Standard">
<span lang="en">When a DNA sequence is read from a tissue sample, it is often stored as a sequence of the characters A,C,G and T in FASTA format. For an algorithm to process it, these characters are mapped into a data structure of integers 1,2,3 and 4 respectively. For many algorithms, such as in DeepSEA, Basset, and our HOP-HMM, it is preferable to encode these sequences of integers as a sequence one-hot vectors (also called indicator vectors), as described in figure <a class="Reference" href="#PWM">3↑</a>. A commonly used feature extraction technique of DNA sequences is to represent them as vectors of their in-sequence k-mer frequencies as used in gkm-SVM. In this technique, the order of the k-mer is sacrificed for a more meaning-oriented, structured and fixed-length data encoding, similarly to the bag of words technique in text analysis and natural language processing. </span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--2"></a><span lang="en">Machine Learning Models</span>
</h3>
<div class="Standard">
<span lang="en">The goal of machine learning classification models is to arrive from the observed <span class="formula"><i>X</i></span> to its label <span class="formula"><i>Y</i></span>. In the DNA classification case discussed in this work, the goal is deciding its role label <span class="formula"><i>Y</i></span> for a given a DNA sequence <span class="formula"><i>X</i></span>. There are two main approaches to this goal: generative models and discriminative models. Both approaches assume observed variables <span class="formula"><i>X</i></span> and target variables <span class="formula"><i>Y</i></span>, also commonly referred to as data samples and labels. </span>
</div>
<ul>
<li>
<span lang="en">Generative models assume a joint probability <span class="formula"><i>P</i><span class="symbol">(</span><i>X</i>, <i>Y</i><span class="symbol">)</span></span>. Using dataset of <span class="formula"><span class="symbol">(</span><i>x</i>, <i>y</i><span class="symbol">)</span></span> pairs, one can estimate the distribution <span class="formula"><i>P</i><span class="symbol">(</span><i>X</i>, <i>Y</i><span class="symbol">)</span></span>, then estimate from it <span class="formula"><i>P</i><span class="symbol">(</span><i>Y</i>|<i>X</i><span class="symbol">)</span></span>. The distinctive feature of these models is their ability to generate random instances of the data, either as pairs of <span class="formula"><span class="symbol">(</span><i>x</i>, <i>y</i><span class="symbol">)</span></span> or as instances of <span class="formula"><i>x</i></span> given <span class="formula"><i>y</i></span>.</span>
</li>
<li>
<span lang="en">Discriminative models assume conditional probability <span class="formula"><i>P</i><span class="symbol">(</span><i>Y</i>|<i>X</i><span class="symbol">)</span></span>, which is estimated directly from the dataset.</span>
</li>

</ul>
<div class="Standard">
<span lang="en">Both models eventually base their classification upon the <span class="formula"><i>P</i><span class="symbol">(</span><i>Y</i>|<i>X</i><span class="symbol">)</span></span> estimation. Namely, classifying a data sample <span class="formula"><i>x</i></span> by the most likely label: </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>y</i><sub><i>est</i></sub> = <i>argmax</i><sub><i>y</i></sub><i>P</i><span class="symbol">(</span><i>Y</i> = <i>y</i>|<i>X</i> = <i>x</i><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Discriminative models are more widely used than generative models, they are often easier to use and build since they require fewer assumptions on the origin and generation of the data. For instance, the deep neural network (DNN) is a model that has gained much interest lately in the machine learning field, and was also used for the task of classifying the role of DNA sequences. As a discriminative model it assumes very little regarding the way the DNA sequence is generated based on its role, but finds instead features in the sequence that imply its role. Hence it is often difficult to use such a model for a later understanding of the nature of the data generation process, or to generate new data from it. </span>
</div>
<div class="Standard">
<span lang="en">Markov model (<span class="bibcites">[<a class="bibliocite" name="cite-44" href="#biblio-44">44</a>]</span>), named after the Russian mathematician Andrey Markov, is a stochastic model which is applied to a system that changes randomly, such as the weather or car traffic. This model is at one of <span class="formula"><i>m</i></span> states <span class="formula"><span class="symbol">{</span><i>S</i><sub>1</sub>, ..., <i>S</i><sub><i>m</i></sub><span class="symbol">}</span></span> at any time, with the first state being sampled from a distribution <span class="formula"><i>π</i><sub><i>i</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub>1</sub> = <i>S</i><sub><i>i</i></sub><span class="symbol">)</span></span> and the probability of transitions between the states being denoted by <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>S</i><sub><i>i</i></sub>|<i>y</i><sub><i>t</i> − 1</sub> = <i>S</i><sub><i>j</i></sub><span class="symbol">)</span></span>. The travel of the model over the states is named a Markov process, and the sequence of the states visited in the process is called a Markov chain. The likelihood of a Markov chain <span class="formula"><i>X</i></span> generated by a Markov Model <span class="formula"><i>θ</i> = {<i>π</i>, <i>T</i>}</span> is a joint probability of the first state and of all following transitions which, due to the independence between transition events, can be written as:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
ℒ(<i>θ</i>;<i>X</i>) = <i>P</i><sub><i>θ</i></sub>(<i>x</i><sub>0</sub>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>L</i></sub>) = <i>π</i><sub><i>x</i><sub>0</sub></sub>⋅<i>T</i><sub><i>x</i><sub>0</sub>, <i>x</i><sub>1</sub></sub>⋅<i>T</i><sub><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></sub>⋅...⋅<i>T</i><sub><i>x</i><sub><i>L</i> − 1</sub>, <i>x</i><sub><i>L</i></sub></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Markov"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/Markov_model.jpg" alt="figure Figures/Markov_model.jpg">
<div class="caption">
Figure 6 <span lang="en"><b>A)</b> Markov model with 3 states (a, b and c). <b>B,C)</b> The model starts with a state sampled from <span class="formula"><i>π</i></span>, and travels between the states with a transition distribution <span class="formula"><i>T</i></span>. <b>D)</b> The model can generate Markov chains of states, where the transition between the states is only conditioned by the previous state, causing the Markov process to be memoryless. </span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">The hidden Markov model (HMM) is a Markov model extension which models a system that travels over hidden states as a Markov process, and while doing so emits variables called observed variables. Like the Markov model, HMM is a generative model, and therefore assumes the existence of a joint probability <span class="formula"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> derived from the compact parameters <span class="formula"><i>θ</i></span>. HMM relies on the assumption that the observed DNA sequence <span class="formula"><i>X</i> = <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>L</i></sub></span> is generated by a parameterized model <span class="formula"><i>θ</i></span>, and has a hidden sequence <span class="formula"><i>Y</i> = <i>y</i><sub>1</sub>, ..., <i>y</i><sub><i>L</i></sub></span> that was generated alongside it. In this generation process, a single observed variable is emitted for every step of the model, and thus the observed sequence is generated with the same length as the hidden Markov chain. For an alphabet of variables <span class="formula"><span class="symbol">{</span><i>V</i><sub>1</sub>, ..., <i>V</i><sub><i>n</i></sub><span class="symbol">}</span>, </span> and hidden state space <span class="formula"><span class="symbol">{</span><i>S</i><sub>1</sub>, ..., <i>S</i><sub><i>m</i></sub><span class="symbol">}</span></span>, the observed variable <span class="formula"><i>x</i><sub><i>t</i></sub></span> is sampled from an emission distribution conditioned on the hidden state of the model <span class="formula"><i>E</i><sub><i>i</i>, <i>j</i></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub> = <i>V</i><sub><i>j</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>S</i><sub><i>i</i></sub><span class="symbol">)</span></span>. Similarly to the Markov model, the distribution to the first hidden state is marked as <span class="formula"><i>π</i></span> and the transition distribution is marked as <span class="formula"><i>T</i></span>.</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="HMM"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HMM_two_states.jpg" alt="figure Figures/HMM_two_states.jpg">
<div class="caption">
Figure 7 <span lang="en"><b>A)</b> HMM with 2 hidden states. <b>B)</b> The observed variables (dark blue) are emitted by the hidden state at their location, sampled from the discrete conditional distribution <span class="formula"><i>E</i></span>. <b>C,D)</b> The hidden states (yellow and green) behave as Markov model states with starting and transition probabilities <span class="formula"><i>π</i></span> and <span class="formula"><i>T</i></span>. <b>E)</b> The output of the model is an observable sequence with an underlying hidden sequence. The hidden sequence is a Markov chain, where on each step the hidden state emits a single observed variable.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">HMM is a very popular signal processing algorithm that has been adopted in the various fields of computational biology since the 1980’s. HMM was proposed by Leonard Baum (<span class="bibcites">[<a class="bibliocite" name="cite-4" href="#biblio-4">4</a>]</span>) and is used for modeling regions with alternating frequencies of patterns and symbols. In a non-biological context, it was used extensively in various engineering fields, especially in speech recognition (<span class="bibcites">[<a class="bibliocite" name="cite-51" href="#biblio-51">51</a>]</span>), handwriting recognition (<span class="bibcites">[<a class="bibliocite" name="cite-29" href="#biblio-29">29</a>]</span>) and digital communication (<span class="bibcites">[<a class="bibliocite" name="cite-63" href="#biblio-63">63</a>]</span>).</span>
</div>
<div class="Standard">
<span lang="en">For example, in the case where the observable sequence is made out of DNA, a simplistic model can assume that the DNA sequence is composed out of 4 states: genes, promoter enhancers and background regions. Each of these states will have a different nucleotide frequency, and we assume that the DNA sequence was generated by an HMM with underlying sequences of 4 hidden states, one for each region type. The emitted DNA sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> is determined by the underlying hidden sequence <span class="formula"><i>y</i><sub>1:<i>L</i></sub></span> that describes the “mode” of the sequence for each location.<br>
</span>
</div>
<div class="Standard">
<span lang="en">Having an HMM with <span class="formula"><i>θ</i></span> on hand and given an observed sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>, two questions arise:</span>
</div>
<ul>
<li>
<span lang="en">What is the likelihood that <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> was generated by the HMM with parameters <span class="formula"><i>θ</i></span> or <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>?</span>
</li>
<li>
<span lang="en">What is the probability of a hidden state at every location or <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>?</span>
</li>

</ul>
<div class="Standard">
<span lang="en">The two above-mentioned probabilities are named the likelihood function and the posterior probabilities of HMM. As in many generative models, HMM’s likelihood function <span class="formula">ℒ<span class="symbol">(</span><i>θ</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> relating to the first question can be split by the total probability law to the sum of all possible hidden sequences: </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="Likelihoods">(2) </a>ℒ<span class="symbol">(</span><i>θ</i>;<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">The probability <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> is called the incomplete-data likelihood function and the probability <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> is called the complete-data likelihood function. In the case of HMM with parameters <span class="formula"><i>θ</i></span>, the complete-data can be calculated by:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="Complete-Likelihood">(3) </a><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub>1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1</sub>|<i>y</i><sub>1</sub><span class="symbol">)</span>⋅<span class="limits"><span class="limit">∏</span></span><sub><i>i</i> = 2</sub><sup><i>N</i></sup><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>i</i></sub>|<i>y</i><sub><i>i</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>i</i></sub>|<i>y</i><sub><i>i</i></sub><span class="symbol">)</span> = <i>π</i><sub><i>y</i><sub>1</sub></sub><i>E</i><sub><i>y</i><sub>1</sub>, <i>x</i><sub>1</sub></sub><span class="limits"><span class="limit">∏</span></span><sub><i>i</i> = 2</sub><sup><i>L</i></sup><i>T</i><sub><i>y</i><sub><i>i</i> − 1</sub>, <i>y</i><sub><i>i</i></sub></sub><i>E</i><sub><i>y</i><sub><i>i</i></sub>, <i>x</i><sub><i>i</i></sub></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Although the computation of the complete-data likelihood of <span class="formula"><i>θ</i></span> in <a class="Reference" href="#Complete-Likelihood">(3↑)</a> is linear-by-L, naively computing the incomplete-data likelihood as in <a class="Reference" href="#Likelihoods">(2↑)</a> involves the summation of all possible hidden sequences, an impracticable exponential-by-L operation. A dynamic approach to overcome this gap uses the Markovian memorylessness of HMM, and answers both the likelihood and the posterior questions we raised above. This approach is called Forward-Backward algorithm: it was suggested as a step in the Baum-Welch algorithm (<span class="bibcites">[<a class="bibliocite" name="cite-4" href="#biblio-4">4</a>]</span>), which is an expectation maximization (EM) algorithm for finding the unknown <span class="formula"><i>θ</i></span> given an observed sequence, and will be described further in a later section. In the Forward-Backward algorithm, two matrices of size <span class="formula"><i>m</i>×<i>L</i></span> are dynamically calculated, holding the probabilities:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>
</div>
</span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--3"></a><span lang="en">Forward Algorithm</span>
</h3>
<div class="Standard">
<span lang="en">The forward probabilities matrix <span class="formula"><i>α</i></span> holds the probability that a sequence <span class="formula"><i>x</i><sub>1:<i>t</i></sub></span> was emitted and that the hidden sequence ended with the state j:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">It is calculated by the dynamic algorithm:</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-1"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 1 <span lang="en">Forward Algorithm</span>
</div>
</span><b><span lang="en">Input:</span></b><span lang="en">    \strikeout off\uuline off\uwave off <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> - Observed DNA sequence</span><b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">     <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">         <span class="formula"><i>α</i><sub><i>j</i>, 1</sub> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span></span><br>
<span lang="en">     <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]:</span></span><br>
<span lang="en">         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">             <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">The building of the table is based on the HMM basic assumptions that each hidden state <span class="formula"><i>y</i><sub><i>t</i></sub></span> is dependent only on the previous one <span class="formula"><i>y</i><sub><i>t</i> − 1</sub></span> and that each observed variable <span class="formula"><i>x</i><sub><i>t</i></sub></span> is dependent only on the hidden state that emitted it, <span class="formula"><i>y</i><sub><i>t</i></sub></span>.</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>y</i><sub><i>t</i> − 1</sub> = <i>j</i>’<span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i>’, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub>⋅<span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="ForwAlg"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HMM forward Algorithm.jpg" alt="figure Figures/HMM forward Algorithm.jpg">
<div class="caption">
Figure 8 <span lang="en">Forward algorithm dynamically calculates the probability stored in <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub></span> by using the previously calculated <span class="formula"><i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub></span> values.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--4"></a><span lang="en">Backward Algorithm</span>
</h3>
<div class="Standard">
<span lang="en">The backward probabilities matrix <span class="formula"><i>β</i></span> hold the probability that a sequence <span class="formula"><i>x</i><sub><i>t</i> + 1:<i>L</i></sub></span> was emitted given the hidden state at position <span class="formula"><i>t</i></span> had value j: </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">It is calculated by the dynamic algorithm:</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-2"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 2 <span lang="en">Backward Algorithm</span>
</div>
</span><b><span lang="en">Input:</span></b><span lang="en">    \strikeout off\uuline off\uwave offX - Observed DNA sequence</span><b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">     <span class="formula"><i>β</i><sub>1:<i>m</i>, <i>L</i></sub> = 1</span></span><br>
<span lang="en">     <span class="formula"><i>for</i> <i>t</i> = [<i>L</i> − 1, ..., 1]:</span></span><br>
<span lang="en">         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">             <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i></sub></sub></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">This matrix building process is similarly explained by:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’, <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> = 
</div>
<div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’<span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>|<i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’<span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i> + 1</sub></sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="BackAlg"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HMM backward Algorithm.jpg" alt="figure Figures/HMM backward Algorithm.jpg">
<div class="caption">
Figure 9 <span lang="en">Backward algorithm dynamically calculates the probability stored in <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub></span> by using the previously calculated <span class="formula"><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub></span> values</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">Once we obtain <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span> probabilities, the incomplete-data likelihood of HMM can be easily calculated:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="Incomplete-Likelihood">(4) </a><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>L</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>, <i>L</i></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">And so can the posterior probability:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Although HMM is simple and efficient, applying it on DNA sequences has a major disadvantage: the inherited Markovian lack-of-memory property. That is, the next state of the model always depends only on the previous state, without further historical consideration. For the task of emitting a TFBS motif where each position has a different emission distribution depending on the location in the motif, an HMM would need to differentiate multiple hidden states according to their positions in the motif. This means that for an HMM to be able to emit even a small number of short motifs, it needs to hold a large number of states which require learning a large number of parameters, e.g. for the ability to emit 50 motifs of length 5, an HMM would need to have over 60,000 parameters. Furthermore, the enhancer modeling task at hand is even more complex, since we would like to model multiple enhancers and backgrounds states, each having a different probability of emitting motifs and an unique k-order emission distribution when not in these motifs. For the prior assumption of our data structure, the required number of model parameters would have been about <span class="formula">10<sup>7</sup></span>, large enough to generate problems such as unfeasible memory complexity and overfitting. </span>
</div>
<div class="Standard">
<span lang="en">A common way to avoid overfitting the data when training machine learning models is to reduce the complexity of the model by fixing some of its parameters. Our proposed HOP-HMM addresses both the memory issue and the overfitting issue while remaining equivalent to a regular HMM with a large number of states having fixed parameters. Namely, most of the transition probabilities are fixed to zero and therefore never stored in the memory, and some of the emission probabilities are predetermined and remain fixed during the training. This allows us to train a model with the enhancer prior assumptions of motifs and higher order emission without overfitting, and with reasonable memory complexity. </span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--5"></a><span lang="en">Generalized HMM</span>
</h3>
<div class="Standard">
<span lang="en">In a generalized HMM (GHMM), the transition or the emission are sampled from a different distribution type assigned to each of the states in the model. Some of the states in the system may emit zero or multiple observable variables, sampled from custom emission models specifically tailored for the expected scenario. Such models were used for genes prediction in the 1990’s (<span class="bibcites">[<a class="bibliocite" name="cite-25" href="#biblio-25">25</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-7" href="#biblio-7">7</a>]</span>), in which specific exon states emitted codons instead of single nucleotides, and feed forward neural networks were used to evaluate the probability of certain transitions. </span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="GHMM"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/sHMM_two_states.jpg" alt="figure Figures/sHMM_two_states.jpg">
</span>
</div>
<div class="PlainVisible">
<span lang="en"><div class="caption">
Figure 10 <span lang="en"><b>A)</b> GHMM with a TF state which emits using a PWM. The model has one background hidden state (yellow) and one TF hidden state. <b>B,C,D)</b> Although the TF state emits motifs with 5 bp, the rest of the emissions, transitions and start probabilities remain the same as in a regular HMM. <b>E)</b> An example output generated from the model, showing the TFBS motif sampled in an arbitrary location inside a sequence.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">Another generalization made to the HMM and called higher order HMM uses conditional distribution by making the transition and emission dependent on previous hidden states (<span class="bibcites">[<a class="bibliocite" name="cite-21" href="#biblio-21">21</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-43" href="#biblio-43">43</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-16" href="#biblio-16">16</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-40" href="#biblio-40">40</a>]</span>). Although these HMM variants are capable of expressing a more complex structure of DNA sequence (different <i>k</i>-mers frequencies in the genomic regions), the number of parameters required for DNA analysis tends to rise with the increase of the assumed complexity of the DNA structure. The increase of hidden states needed may introduce overfitting in the learning process, when the data size is limited. </span>
</div>
<div class="Standard">
<span lang="en">Instead of higher order emission which depends on the previous hidden states, the less researched field of higher order emission depending on previously emitted observable variables was used. Such an HMM variant is better suited to the local-spannature of of the emission of k-mer structures, but it only requires <span class="formula"><i>O</i><span class="symbol">(</span><i>m</i><sup>2</sup> + 4<sup><i>k</i></sup><span class="symbol">)</span></span> compared to <span class="formula"><i>O</i></span> <span class="formula"><span class="symbol">(</span><i>m</i><sup><i>k</i></sup><span class="symbol">)</span></span> parameters that would have been required for holding a <i>k</i>-mer distribution in a regular HMM, where <span class="formula"><i>m</i></span> is the number of hidden states of the HOP-HMM, and <span class="formula"><i>k</i></span> is the number of previous states in the dependency. </span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--6"></a><span lang="en">HOP-HMM</span>
</h3>
<div class="Standard">
<span lang="en">HOP-HMM is a GHMM that is well fitted to the utilization of the structure of enhancers containing TFBSs, due to the TFBS emitting TF states which take part in the generation process of the sequence. In view of the assumed local physical nature of the TF binding of DNA sequences and of the success of HMM in gene prediction, we think the memorylessness of HMMs fits well the task of enhancer prediction. HOP-HMM balances between the Markovian memorylessness and the observed k-mer of the TFBS present in regulatory regions in the DNA. </span>
</div>
<div class="Standard">
<span lang="en">HOP-HMM extends the GHMM model of <span class="bibcites">[<a class="bibliocite" name="cite-32" href="#biblio-32">32</a>]</span>, where some of the hidden states emit TFBS sampled from PWMs to predict enhancer location in the genome. In HOP-HMM we added the higher order conditional emission probability on non-TF states. </span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="HOPHMM1"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HOP_HMM_two_states.jpg" alt="figure Figures/HOP_HMM_two_states.jpg">
<div class="caption">
Figure 11 <span lang="en"><b>A)</b> Small HOP-HMM with one background state and one TF state. <b>B)</b> The background state emits a single observable variable, and has 2-order emission, meaning it is conditioned on the previous observable variable. <b>C,D)</b> Unlike GHMM, in HOP-HMM TF state can transition into itself and cannot be the starting hidden state and the background state . <b>E)</b> The TF state emits multiple observable variables which represent a TFBS sampled from a PWM. </span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="TGCompact"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/Transition_repack.jpg" alt="figure Figures/Transition_repack.jpg">
<div class="caption">
Figure 12 <span lang="en">Instead of holding a single sparse 8<span class="formula"> × </span>8 transition matrix, an alternative compact form holds only the non-fixed transition probabilities, split into <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span> matrices. The non-fixed transition probabilities held in the compact form are those between background states, and between background states to their TF states (outlined with blue). The concatenation of a row in <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span> holds the probability of the next hidden state given the current background state. </span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="HOPHMM2"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HOP_HMM_multi_states.jpg" alt="figure Figures/HOP_HMM_multi_states.jpg">
<div class="caption">
Figure 13 <b><span lang="en">A)</span></b> A more complex HOP-HMM with two background states <span class="formula"><i>BG</i><sub>1</sub></span> and <span class="formula"><i>BG</i><sub>2</sub></span>, where each has 3 TF states. <b>B) </b>Each of the background states has its own 2-order emission distribution in a <span class="formula">4 × 4</span> matrix. <b>C)</b> The start hidden state distribution <span class="formula"><i>π</i></span> allows only background states to start the hidden sequence. <b>D)</b> The transition probability is held by matrices <span class="formula"><i>T</i></span> and G. <b>E)</b> The example-generated sequence is built out of two types of sequences, each with its own TFBS frequency and background nucleotide bigram frequency, representing two alternating types of enhancers. 
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">We use two indices to describe a hidden state in HOP-HMM: </span>
</div>
<ul>
<li>
<span lang="en">background states are indexed as <span class="formula">(<i>j</i>, 0)</span> where <span class="formula"><i>j</i> ∈ [<i>m</i>]</span> and <span class="formula"><i>m</i></span> is the number background states.</span>
</li>
<li>
<span lang="en">TF states are indexed as <span class="formula">(<i>j</i>, <i>l</i>)</span> where <span class="formula"><i>j</i> ∈ [<i>m</i>]</span>, <span class="formula"><i>l</i> ∈ [<i>k</i>]</span>. and <span class="formula"><i>k</i></span> is the number of TF states each of the background states has.</span>
</li>

</ul>
<div class="Standard">
<span lang="en">For example, in figure <a class="Reference" href="#HOPHMM2">13↑</a> we see a HOP-HMM with <span class="formula"><i>m</i> = 2</span> and <span class="formula"><i>k</i> = 3</span> and a total of 8 hidden-states (<span class="formula">2 + 3 × 2</span>). The TF state indexed <span class="formula">(<i>j</i>, <i>l</i>)</span> belongs to the <span class="formula">(<i>j</i>, 0)</span> background state (see figure <a class="Reference" href="#HOPHMM3">14↓</a>), and the only allowed transfer into <span class="formula">(<i>j</i>, <i>l</i>)</span> is from its background state <span class="formula">(<i>j</i>, 0)</span>. Note that we used a simpler <span class="formula"><i>BG</i><sub><i>j</i></sub></span> notation in figures <a class="Reference" href="#HOPHMM1">11↑</a> and <a class="Reference" href="#HOPHMM2">13↑</a> for readability.</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="HOPHMM3"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HOP_HMM_general_mk.jpg" alt="figure Figures/HOP_HMM_general_mk.jpg">
<div class="caption">
Figure 14 <i><i><span lang="en">General hidden states graph of HOP-HMM. Each row represents a sequence type, where each of the <span class="formula"><i>m</i></span> background states (yellow) has <span class="formula"><i>k</i></span></span></i></i> TF state<i><i>s (green). Not all transitions are possible, moving between the rows is possible only by a background state to background state transition.</i></i>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">While most background states <span class="formula">(<i>j</i>, 0)</span> represent an enhancer type, we also would also like to model true background regions in between the enhancers that carry no regulatory role and have no TFBSs. For To that end, we predefine one or more background states as non-enhancers by restricting their transfer probability into their TF states, as seen in the results section. </span>
</div>
<div class="Standard">
<span lang="en">HOP-HMM is defined with <span class="formula"><i>k</i></span> PWMs <span class="formula"><i>W</i><sub>1</sub>, <i>W</i><sub>2</sub>, ..., <i>W</i><sub><i>k</i></sub></span> that remain fixed during training. Each of the <span class="formula"><i>k</i></span> PWMs is shared with <span class="formula"><i>m</i></span> TF states, e.g. the PWM <span class="formula"><i>W</i><sub><i>l</i></sub></span>, where <span class="formula"><i>l</i> ∈ [<i>k</i>]</span>, is shared between subs-states <span class="formula">(1, <i>l</i>), (2, <i>l</i>), ..., (<i>m</i>, <i>l</i>)</span> and is used for the TF state emission sampling. The PWMs vary in their column amounts (as the different TFBSs vary in length), and each column represents a nucleotide distribution at that position. When the model enters a TF state, it emits a motif by sampling independently from a PWM column by column, as described in figure <a class="Reference" href="#GHMM">10↑</a>.</span>
</div>
<div class="Standard">
<span lang="en">The background states, denoted as <span class="formula">(1, 0), (2, 0), ..., (<i>m</i>, 0)</span>, are responsible for the emission of inter-TFBS parts of the enhancers lacking long motifs. Similarly to regular states in HMM, background states emit single nucleotides whose emission is conditional on the previous nucleotides emitted in the DNA sequence. The emission from background states is done by sampling a nucleotide from the distributions stored in <span class="formula"><i>E</i></span> tensor. <span class="formula"><i>E</i></span> dimension is <span class="formula"><i>o</i> + 1</span>, and its size is <span class="formula"><span class="text"> </span><i>m</i> × 4 × 4 × ... × 4</span> (with <span class="formula"><i>o</i></span> fours) and its values describe the emission probability <span class="formula"><i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i></sub></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span></span>, meaning that when <span class="formula"><i>x</i><sub><i>t</i></sub></span> is sampled by the model, the preceding <span class="formula"><i>o</i> − 1</span> observed variables are used as indices of the tensor for getting the emission probability vector <span class="formula"><i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub>, *</sub></span>.</span>
</div>
<div class="Standard">
<span lang="en">For the first variables emitted in the sequence, the missing dimensions of the preceding variables are summed to form the probability vector, e.g. if <span class="formula"><i>t</i> = <i>o</i> − 1</span>, a single variable is missing for emitting <span class="formula"><i>x</i><sub><i>t</i></sub></span> and the distribution used for emission sampling is <span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ [4]</sub><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>E</i><sub><i>j</i>, <i>i</i>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub></sub></span><span class="ignored">)/(</span><span class="denominator">4</span><span class="ignored">)</span></span></span>.<br>
</span>
</div>
<div class="Standard">
<span lang="en">In HOP-HMM, the first hidden state in a sequence can only be a background state. As in HMM, the first background state is chosen by sampling from <span class="formula"><i>π</i>, </span> a probability vector <span class="formula"><i>π</i><sub><i>j</i></sub> = <i>P</i>(<i>y</i><sub>1</sub> = (<i>j</i>, 0))</span>. Once in a background state, the model can only transit into a small subset of states, and since most of the possible transitions are not allowed, a single transition matrix from all states to all states would be sparse. Instead, as described in figure <a class="Reference" href="#TGCompact">12↑</a>, we only hold the possible transition probabilities in two matrices, representing the two types of allowed transitions: </span>
</div>
<ul>
<li>
<span lang="en">T for background state to background state transitions, a <span class="formula"><i>m</i> × <i>m</i></span> matrix where <span class="formula"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i><sub>2</sub>, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span></span>.</span>
</li>
<li>
<span lang="en">G for background state to TF state transitions a <span class="formula"><i>m</i> × <i>k</i></span> matrix where <span class="formula"><i>G</i><sub><i>j</i>, <i>l</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span>.</span>
</li>

</ul>
<div class="Standard">
<span lang="en">When in a background state, after the observable variable emission, the model samples its next hidden state from a probability vector which is the concatenation of a row in <span class="formula"><i>T</i></span> and a row in <span class="formula"><i>G</i></span>. If a TF state is chosen,,the model returns back to the background state after the TF state’s motif emission to emit another single observable variable and so on. </span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--4"></a><span lang="en">Methods</span>
</h1>
<div class="Standard">
<span lang="en">When fitting an HMM to a DNA sequence, we seek the parameters <span class="formula"><i>θ</i><sup>*</sup></span> that best explain the sequence via an algorithm called Baum-Welch algorithm, which is a special case of EM algorithm. Formally, given the observed DNA sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>, we would like to find the parameters that maximize the incomplete-likelihood: <div class="formula">
<i>θ</i><sup>*</sup> = <i>argmax</i><sub><i>θ</i></sub>ℒ<span class="symbol">(</span><i>θ</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Even though the incomplete-data likelihood of HMM in <a class="Reference" href="#Likelihoods">(2↑)</a> is derivable by <span class="formula"><i>θ</i></span>, optimizing it is as difficult as calculating it, and is therefore also impractical. Instead, the strategy of the EM algorithm is to iteratively optimize the expected value of the complete data log-likelihood <span class="formula"><i>log</i><span class="symbol">(</span><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub>|<i>θ</i><sup>’</sup><span class="symbol">)</span><span class="symbol">)</span></span> over all possible <span class="formula"><i>y</i><sub>1:<i>L</i></sub></span> where <span class="formula"><i>θ</i><sup>’</sup></span> is the model parameters from previous EM iteration (or guessed parameters in the first iteration) and while assuming a fixed observed <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>, as it is in the given DNA sequence. For this task we define our target function Q:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="Q">(5) </a><i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = <i>E</i><sub><i>Y</i></sub><span class="symbol">[</span><i>log</i><span class="symbol">(</span><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span><span class="symbol">)</span>|<i>x</i><sub>1:<i>L</i></sub>, <i>θ</i><sup>’</sup><span class="symbol">]</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><i>log</i><span class="symbol">(</span><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Here <span class="formula"><i>E</i></span> is expressing an expected value, not to be confused with the HMM emission probability. Every EM iteration is built out of two parts called the <span class="formula"><i>E</i></span> (expectation) step and the <span class="formula"><i>M</i></span> (maximization) step. In the E-step we calculate the probabilities needed for the maximization of <span class="formula"><i>Q</i></span> and in the M-step we infer the <span class="formula"><i>θ</i></span> that maximizes it. We will update the <span class="formula"><i>θ</i></span> for maximizing <span class="formula"><i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span></span> in every M-step of the EM algorithm until convergence. </span>
</div>
<div class="Standard">
<span lang="en">Using <a class="Reference" href="#Complete-Likelihood">(3↑)</a> we will split the Q function <a class="Reference" href="#Q">(5↑)</a> into three independent parts:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><i>log</i><i>π</i><sub><i>y</i><sub>1</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span> + 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 + <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logT</i><sub><i>y</i><sub><i>t</i> − 1</sub>, <i>y</i><sub><i>t</i></sub></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span> + <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>logE</i><sub><i>y</i><sub><i>t</i></sub>, <i>x</i><sub><i>t</i></sub></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Then by manipulating the summation, the exponential state sequence summation could be simplified to:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>log</i><i>π</i><sub><i>j</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i><span class="symbol">)</span> + 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 + <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span> + <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>logE</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Each of the three parts above is a set of constraint linear functions that could be derived and maximized independently using Lagrange multipliers, and under the following probability constraints: </span>
</div>
<ul>
<li>
<span lang="en"><span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>π</i><sub><i>j</i></sub> = 1</span></span>
</li>
<li>
<span lang="en"><span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = 1</span> for all <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span></span>
</li>
<li>
<span lang="en"><span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>b</i> ∈ [<i>n</i>]</sub><i>E</i><sub><i>j</i>, <i>b</i></sub> = 1</span> for all <span class="formula"><i>j</i> ∈ [<i>n</i>]</span></span>
</li>

</ul>
<div class="Standard">
<span lang="en">where <span class="formula"><i>m</i></span> is the number of different hidden states and <span class="formula"><i>n</i></span> is the number of different observed variables (4 in our case of DNA).</span>
</div>
<div class="Standard">
<span lang="en">First, we start with maximizing the first <span class="formula"><i>π</i></span> part using Lagrange multiplier <span class="formula"><i>λ</i></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>π</i><sub><i>j</i></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>log</i><i>π</i><sub><i>j</i>’</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i>’<span class="symbol">)</span> + <i>λ</i><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>π</i><sub><i>j</i>’</sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>
</span>
</div>
<div class="Standard">
<span lang="en">we derive the term and get <span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>π</i><sub><i>j</i></sub></span><span class="ignored">)</span></span> = <i>λ</i></span> for <span class="formula"><i>j</i> ∈ [<i>m</i>]</span>. Then we use these <span class="formula"><i>m</i></span> equations to get <span class="formula"><i>λ</i> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>, which yields the reestimated <span class="formula"><i>π</i><sub><i>j</i></sub></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="Pi-Update">(6) </a><i>π</i><sub><i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub>1</sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Then, we define a Lagrange multiplier <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub></span> for each <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span> for the <span class="formula"><i>T</i></span> part:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span> + <i>λ</i><sub><i>j</i><sub>1</sub></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i>’</sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>
</span>
</div>
<div class="Standard">
<span lang="en">which yields <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span></span> for <span class="formula"><i>j</i><sub>2</sub> ∈ [<i>m</i>]</span> </span>
</div>
<div class="Standard">
<span lang="en">and when all <span class="formula"><i>m</i></span> equations are summed, gives <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub><span class="symbol">)</span></span> </span>
</div>
<div class="Standard">
<span lang="en">Therefore the update of <span class="formula"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span> will be:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="T-Update">(7) </a><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Finally, we’ll define a Lagrange multiplier <span class="formula"><i>λ</i><sub><i>j</i></sub></span> for every <span class="formula"><i>j</i> ∈ [<i>m</i>]</span> for the <span class="formula"><i>E</i></span> part:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>E</i><sub><i>j</i>, <i>b</i></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>logE</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> + <i>λ</i><sub><i>j</i></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>b</i>’ ∈ [<i>n</i>]</sub><i>E</i><sub><i>j</i>, <i>b</i>’</sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>
</span>
</div>
<div class="Standard">
<span lang="en">This step is slightly trickier due to the derivation of <span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator">∂<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub></span><span class="ignored">)/(</span><span class="denominator">∂<i>E</i><sub><i>j</i>, <i>b</i></sub></span><span class="ignored">)</span></span> = <b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span> where <span class="formula"><b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>) = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
1 
</span>
<span class="case align-l">
<i>b</i> = <i>x</i><sub><i>t</i></sub> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
0 
</span>
<span class="case align-l">
<i>otherwise</i> 
</span>

</span>

</span>
</span>.</span>
</div>
<div class="Standard">
<span lang="en">We get <span class="formula"><i>λ</i><sub><i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><i>E</i><sub><i>j</i>, <i>b</i></sub></span><span class="ignored">)</span></span></span> for <span class="formula"><i>b</i> ∈ [<i>n</i>]</span> </span>
</div>
<div class="Standard">
<span lang="en">and when all <span class="formula"><i>n</i></span> equations are summed, gives <span class="formula"><i>λ</i><sub><i>j</i></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span> </span>
</div>
<div class="Standard">
<span lang="en">Therefore the update of <span class="formula"><i>E</i><sub><i>j</i>, <i>b</i></sub></span> will be:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="E-Update">(8) </a><i>E</i><sub><i>j</i>, <i>b</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span><b>⋅1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span><b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">For us to be able to calculate these reestimations of <span class="formula"><i>θ</i></span> as written in <a class="Reference" href="#Pi-Update">(6↑)</a>, <a class="Reference" href="#T-Update">(7↑)</a> and <a class="Reference" href="#E-Update">(8↑)</a>, \strikeout off\uuline off\uwave offwe still need to calculate the two probability terms they contain. To resemble the notations coined in <span class="bibcites">[<a class="bibliocite" name="cite-52" href="#biblio-52">52</a>]</span>, the first widely accepted HMM application, we’ll denote these as <span class="formula"><i>γ</i></span> and <span class="formula"><i>ξ</i></span></span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="gamma">(9) </a><i>γ</i><sub><i>t</i>, <i>j</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
 <div class="formula">
<a class="eqnumber" name="xi">(10) </a><i>ξ</i><sub><i>t</i>, <i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">We will use <a class="Reference" href="#Incomplete-Likelihood">(4↑)</a> and the output of the Forward-Backward algorithm <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span> for their calculation:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>γ</i><sub><i>t</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>, <i>L</i></sub></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>ξ</i><sub><i>t</i>, <i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i>]</sub> = <i>j</i><sub>2</sub>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub>|<i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i><sub>1</sub>, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, </sub>⋅<i>E</i><sub><i>j</i><sub>2</sub>, <i>x</i><sub><i>t</i></sub></sub>⋅<i>β</i><sub><i>j</i>’, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>, <i>L</i></sub></span><span class="ignored">)</span></span>
</div>
The calculation of <span class="formula"><i>α</i>, <i>β</i>, <i>γ</i></span> and <span class="formula"><i>ξ</i></span> matrices is considered the E-step of the Baum-Welch algorithm and allows us to update <span class="formula"><i>θ</i></span> and finish the EM iteration.</span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--7"></a><span lang="en">Baum-Welch Algorithm for HOP-HMM</span>
</h3>
<div class="Standard">
<span lang="en">The transition and emission mechanisms of HOP-HMM are different and therefore the complete data likelihood of HOP-HMM requires a different calculation for the Baum-Welch algorithm to hold. The Baum-Welch algorithm can be adjusted to infer the parameters of the HOP-HMM variant <span class="formula"><i>θ</i> = {<i>π</i>, <i>E</i>, <i>G</i>, <i>T</i>}</span> from a DNA sequence <span class="formula"><i>X</i></span>. As in the regular Baum-Welch algorithm covered in the previous section, given a sequence <span class="formula"><i>X</i></span> at each EM iteration we optimize the Q function in <a class="Reference" href="#Q">(5↑)</a>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>log</i><i>π</i><sub><i>j</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>], <i>l</i> ∈ [<i>k</i>]</sub><i>logG</i><sub><i>j</i>, <i>l</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>logE</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>logL</i><sub><i>W</i></sub>(<i>x</i><sub><i>t</i>:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| − 1</sub>)⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i>:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| − 1<i>S</i></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>
</span>

</span>
</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">where <span class="formula"><i>L</i><sub><i>W</i></sub>(<span class="overline"><i>x</i></span>)</span> is the likelihood of the TFBS <span class="formula"><span class="overline"><i>x</i></span></span> to be emitted by PWM <span class="formula"><i>W</i></span>: <span class="formula"><i>L</i><sub><i>M</i></sub>(<span class="overline"><i>x</i></span>) = <i>P</i>(<span class="overline"><i>x</i></span>|<i>W</i>) = <span class="unknown">\underset</span><i>i</i> ∈ {1, ..., |<span class="overline"><i>x</i></span>|}<span class="limits"><span class="limit">∏</span></span><i>W</i><sub><span class="overline"><i>x</i></span><sub><i>i</i></sub>, <i>i</i></sub></span>. </span>
</div>
<div class="Standard">
<span lang="en">Note that the last addition component, which holds the TFBS log likelihood, does not contain elements from  <span class="formula"><i>θ</i></span> since the PWMs are not learned in HOP-HMM and thus is not reestimated in the M-steps. </span>
</div>
<div class="Standard">
<span lang="en">The <span class="formula"><i>θ</i><sup>*</sup></span> which optimizes <span class="formula"><i>Q</i></span> here, <span class="formula"><i>θ</i><sup>*</sup> = <i>argmax</i><sub><i>θ</i></sub><i>Q</i>(<i>θ</i>, <i>θ</i>’)</span>, is achieved by optimizing its 3 independent parts simillarly to , each having its own constrain under which we optimize <span class="formula"><i>Q</i></span> are:</span>
</div>
<ul>
<li>
<span lang="en"><span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>π</i><sub><i>j</i></sub> = 1</span></span>
</li>
<li>
<span lang="en"><span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> + <span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub> = 1</span> for all <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span></span>
</li>
<li>
<span lang="en"><span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>b</i><sub><i>o</i></sub> ∈ [<i>n</i>]</sub><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = 1</span> for all <span class="formula"><i>j</i> ∈ [<i>n</i>]</span></span>
</li>

</ul>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--8"></a><span lang="en">M-step</span>
</h3>
<div class="Standard">
<span lang="en">The <span class="formula"><i>π</i></span> and <span class="formula"><i>E</i></span> conditions produce almost exact same maximization as in regular Baum-Welch <a class="Reference" href="#Pi-Update">(6↑)</a> and <a class="Reference" href="#E-Update">(8↑)</a>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="HOP-Pi-Update">(11) </a><i>π</i><sub><i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = (<i>j</i>, 0)|<i>θ</i><sup>’</sup><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>|<i>θ</i><sup>’</sup><span class="symbol">)</span></span><span class="ignored">)</span></span> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub>1</sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="HOP-E-Update">(12) </a><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span><b> 1</b><sub><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub>(<i>x</i><sub><i>t</i> − <i>o</i> + 1, ..., <i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">As for the second condition of <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span>, we will define the Lagrange multipliers <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub></span> for <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span> and derive the two terms that contain <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>T</i><sub><i>j</i><sub>1, </sub><i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span> + <i>λ</i><sub><i>j</i><sub>1</sub></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i>’</sub> − <span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>G</i><sub><i>j</i><sub>1</sub>, <i>l</i></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logG</i><sub><i>j</i><sub>1</sub>, <i>l</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, <i>l</i>)<span class="symbol">)</span> + <i>λ</i><sub><i>j</i><sub>1</sub></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i>’</sub> − <span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>
</span>
</div>
<div class="Standard">
<span lang="en">which yields <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span></span> and <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, <i>l</i>)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub></span><span class="ignored">)</span></span></span> for <span class="formula"><i>j</i><sub>2</sub> ∈ [<i>m</i>]</span> and <span class="formula"><i>l</i> ∈ [<i>k</i>]</span>. </span>
</div>
<div class="Standard">
<span lang="en">When the <span class="formula"><i>m</i> + <i>k</i></span> equations are summed we receive:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span> + <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, <i>l</i>)<span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">which gives us the updates </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="HOP-T-Update">(13) </a><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="HOP-G-Update">(14) </a><i>G</i><sub><i>j</i>, <i>l</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--9"></a><span lang="en">E-step</span>
</h3>
<div class="Standard">
<span lang="en">Preceding the M-step where we update components of <span class="formula"><i>θ</i></span> by <a class="Reference" href="#HOP-Pi-Update">(11↑)</a>, <a class="Reference" href="#HOP-E-Update">(12↑)</a>, <a class="Reference" href="#HOP-T-Update">(13↑)</a> and <a class="Reference" href="#HOP-G-Update">(14↑)</a>, we will calculate the three probability terms inside them in the E-step, denoted as <span class="formula"><i>γ</i>, </span> <span class="formula"><i>ξ</i></span> and <span class="formula"><i>η</i></span>:<br>
<br>
 <div class="formula">
<a class="eqnumber" name="HOP-gamma">(15) </a><i>γ</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
 <div class="formula">
<a class="eqnumber" name="HOP-xi">(16) </a><i>ξ</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, <i>t</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="HOP-eta">(17) </a><i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">For the calculation of these probabilities, we first need to calculate the forward and backward probabilities output from a HOP-HMM adjusted Forward-Backward algorithm. In this HOP-Forward-Backward algorithm, we will only build the probabilities for being in background states since the TF states probabilities are not needed in the later parts of the E-step.</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">The adjustments for the forward and backward algorithm are straight forward, as the summation is composed of two parts. We calculate <span class="formula"><i>α</i></span> of size <span class="formula"><i>m</i> × <i>L</i></span>, iterating over <span class="formula"><i>t</i> = 1, 2, ..., <i>L</i></span> as following:</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-3"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 3 <span lang="en">HOP Forward Algorithm</span>
</div>
</span><b><span lang="en">Input:</span></b><span lang="en">    \strikeout off\uuline off\uwave offX - Observed DNA sequence</span><b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">     <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">         <span class="formula"><i>α</i><sub><i>j</i>, 1</sub> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span></span><br>
<span lang="en">     <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]:</span></span><br>
<span lang="en">         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">             <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub> = <span class="unknown">\underset</span><span class="text">background-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub></span></span></span><br>
<span lang="en">                   <span class="formula"> + <span class="unknown">\underset</span><span class="text">TF-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>α</i><sub><i>j</i>, <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub></span></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">In the beginning of the sequence, when <span class="formula">1 ≤ <i>t</i> &lt; <i>o</i></span>, part of the preceding observable variables are missing. Since <span class="formula"><i>E</i></span> has <span class="formula"><i>o</i> + 1</span> dimensions, <span class="formula"><i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub></span> is not defined, so we define it here as: </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub> = <span class="unknown">\underset</span><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i> − <i>t</i></sub> ∈ {<i>A</i>, <i>C</i>, <i>G</i>, <i>T</i>}<span class="limits"><span class="limit">∑</span></span><span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">4<sup><i>o</i> − <i>t</i></sup></span><span class="ignored">)</span></span>⋅<i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, .., .<i>b</i><sub><i>o</i> − <i>t</i></sub>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>
</div>
 </span>
</div>
<div class="Standard">
<span lang="en">We used the fact that <span class="formula"><i>P</i>(<i>A</i>) = <span class="limits"><span class="limit">∑</span></span><sub><i>b</i> ∈ <i>B</i></sub><i>P</i>(<i>b</i>)⋅<i>P</i>(<i>A</i>|<i>b</i>)</span> and the assumption that the observable variables preceding the sequence came from a uniform distribution. Also, when summing the TF state transition part, PWMs <span class="formula"><i>W</i><sub><i>l</i></sub></span> with length equal or bigger than <span class="formula"><i>t</i> + 1</span> include out-of-sequence TFBS and are not part of the summation.</span>
</div>
<div class="Standard">
<span lang="en">For <span class="formula"><i>β</i></span> of size <span class="formula"><i>m</i> × <i>L</i></span>, we iterating over <span class="formula"><i>t</i> = <i>L</i>, <i>L</i> − 1, ..., 1</span> as following:</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-4"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 4 <span lang="en">HOP Backward Algorithm</span>
</div>
</span><b><span lang="en">Input:</span></b><span lang="en">    \strikeout off\uuline off\uwave offX - Observed DNA sequence</span><b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">     <span class="formula"><i>β</i><sub>1:<i>m</i>, <i>L</i></sub> = 1</span></span><br>
<span lang="en">     <span class="formula"><i>for</i> <i>t</i> = [<i>L</i> − 1, ..., 1]:</span></span><br>
<span lang="en">         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">             <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub> = <span class="unknown">\underset</span><span class="text">background-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + 1</sub></sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub></span></span></span><br>
<span lang="en">                   <span class="formula"> + <span class="unknown">\underset</span><span class="text">TF-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + |<i>W</i><sub><i>l</i></sub>| + 2</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub></span></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">Note that when <span class="formula"><i>t</i> &gt; <i>L</i> − |<i>W</i><sub><i>l</i></sub>|</span>, there are missing observable variables to fully calculate the TF state transition. In these situations this contribution of these component to the summation is zero, meaning our HOP-HMM has the behavior of avoiding a transition into a TF state when the PWM is too long to fit into the sequence <span class="formula"><i>X</i></span> length.</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Figure-15"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/HOP-EM forward Algorithm.jpg" alt="figure Figures/HOP-EM forward Algorithm.jpg">
<div class="caption">
Figure 15 <span lang="en">In HOP-HMM, the Forward-Backward algorithm dynamic tables <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span> cells are filled from both the adjacent background states transitions and the background states preceding or proceeding the motifs emitted by the TF states.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">We will now explain why the described dynamic calculation result with <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span></span> and <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span>, starting with the forward probabilities <span class="formula"><i>α</i></span>. From the law of total probability, the probability <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub></span> is the sum of probabilities of all the possible transition that ended in the background state (j,0):</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="unknown">\underset</span><span class="text">background-state transitions</span><span class="underbrace"><span class="unknown">\underset</span><i>j</i>’ ∈ [<i>m</i>]<span class="limits"><span class="limit">∑</span></span><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span></span> + <span class="unknown">\underset</span><span class="text">TF-state transitions</span><span class="underbrace"><span class="unknown">\underset</span><i>l</i> ∈ [<i>k</i>]<span class="limits"><span class="limit">∑</span></span><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">right-side term of a TF state transition can be split with the chain rule to:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub>|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub>, <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Since <span class="formula"><i>x</i><sub><i>t</i></sub></span> is dependent only on <span class="formula"><i>y</i><sub><i>t</i></sub></span> and <span class="formula"><i>x</i><sub><i>t</i> − <i>o</i>:<i>t</i> − 1</sub></span> and since <span class="formula"><i>y</i><sub><i>t</i></sub></span> is dependent on only <span class="formula"><i>y</i><sub><i>t</i> − 1</sub></span>, we can simplify the probabilities:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub>|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i>:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>α</i><sub><i>j</i>, <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">This process is similar to the background state transition. Using the chain rule:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">For the backward probabilities <span class="formula"><i>β</i>, </span> the explanation is similar. The main difference between the regular HMM backward probability is the condition on the <span class="formula"><i>o</i> − 1</span> preceding observable variables <span class="formula"><i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub></span>, which are necessary for the background state emission is conditional on them.</span>
</div>
<div class="Standard">
<span lang="en">Using the law of total probability:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="unknown">\underset</span><span class="text">background-state transition</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span></span> + <span class="unknown">\underset</span><span class="text">TF-state transition</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">For the background state transition term, we can use the chain rule and the Markovian independence of the transitions and emissions:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i> + 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 3:<i>t</i> + 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + 1</sub></sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">For the TF state transition term, we use once more the chain rule, followed the simplification using the conditional independencies of HMM:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 2:<i>L</i></sub>|<i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>, <i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>|<i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>, <i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>|<i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>|<i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>|<i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Using the forward and the backward probability matrices <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span>, we can calculate the auxiliary probabilities <a class="Reference" href="#HOP-gamma">(15↑)</a>, <a class="Reference" href="#HOP-xi">(16↑)</a> and <a class="Reference" href="#HOP-eta">(17↑)</a>. The first probability that will help us for that is <span class="formula"><i>ψ</i></span>, a matrix of size <span class="formula"><i>m</i> × <i>k</i> × <i>L</i></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>), <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>t</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>|<i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>⋅
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>|<i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span><span class="text"> ⋅</span><i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| − <i>o</i> + 3:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i>, </sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">The second probability is likelihood of the observed sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>]<span class="limits"><span class="limit">∑</span></span><span class="symbol">(</span><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub> + <span class="unknown">\underset</span><i>l</i> ∈ <span class="symbol">[</span><i>k</i><span class="symbol">]</span>,  <i>t</i>’ ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span><span class="limits"><span class="limit">∑</span></span><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i> − <i>s</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Now we can calculate probability <a class="Reference" href="#HOP-gamma">(15↑)</a> of the background state at a given position given the sequence <span class="formula"><i>X</i></span>, denoted as <span class="formula"><i>γ</i></span> of size <span class="formula"><i>m</i> × <i>L</i></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>γ</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>x</i><sub>1:<i>t</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>x</i><sub><i>t</i> − <i>o</i> + 1:<i>t</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">The probability <a class="Reference" href="#HOP-xi">(16↑)</a> is the background state to background state transition given the sequence <span class="formula"><i>X</i></span>, denoted as <span class="formula"><i>ξ</i></span> of size <span class="formula"><i>m</i> × <i>m</i> × <i>L</i></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>ξ</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>t</i> − 1</sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i>:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>t</i> − 1</sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i><sub>1</sub>, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>E</i><sub><i>j</i><sub>2</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>⋅<i>β</i><sub><i>j</i><sub>2</sub>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Finally, the probability <a class="Reference" href="#HOP-eta">(17↑)</a> is the background state to background state transition given the sequence <span class="formula"><i>X</i></span>, denoted as <span class="formula"><i>ψ</i></span> of size <span class="formula"><i>m</i> × <i>k</i> × <i>L</i></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Now with <a class="Reference" href="#HOP-gamma">(15↑)</a>, <a class="Reference" href="#HOP-xi">(16↑)</a> and <a class="Reference" href="#HOP-eta">(17↑)</a> at hand, we can complete the M-step and update <span class="formula"><i>θ</i></span> by assigning the updates of <a class="Reference" href="#HOP-Pi-Update">(11↑)</a>, <a class="Reference" href="#HOP-E-Update">(12↑)</a>, <a class="Reference" href="#HOP-T-Update">(13↑)</a> and <a class="Reference" href="#HOP-G-Update">(14↑)</a>.</span>
</div>
<div class="Standard">
<span lang="en">The Baum-Welch algorithm adaptation for HOP-HMM, as described in this section:</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-5"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 5 <span lang="en">HOP Baum-Welch</span>
</div>
</span><b><span lang="en">Input:</span></b><span lang="en">    \strikeout off\uuline off\uwave offX - Observed DNA sequence</span><b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">    for s=[1...MAX_EM_ITERATIONS]:</span><br>
<span lang="en">        <i># E-step</i></span><br>
<span lang="en">         <span class="formula"><i>α</i> = <span class="text">hop_forward_algorithm(x<sub>1:L</sub>) </span></span></span><br>
<span lang="en">         <span class="formula"><i>β</i> = <span class="text">hop_backward_algorithm(x<sub>1:L</sub>) </span></span></span><br>
<span lang="en">        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>l</i> = [1, ..., <i>k</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :</span><br>
<span lang="en">             <span class="formula"><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
<i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i>, </sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub> 
</span>
<span class="case align-l">
| <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1 ≤ <i>L</i> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
0 
</span>
<span class="case align-l">
| <i>otherwise</i> 
</span>

</span>

</span>
</span></span><br>
<span lang="en">         <span class="formula"><i>Px</i> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>]<span class="limits"><span class="limit">∑</span></span><i>α</i><sub><i>j</i>, <i>L</i></sub></span></span><br>
<span lang="en">        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :</span><br>
<span lang="en">             <span class="formula"><i>γ</i><sub><i>j</i>, <i>t</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>Px</i></span><span class="ignored">)</span></span></span></span><br>
<span lang="en">        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>l</i> = [1, ..., <i>k</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :</span><br>
<span lang="en">             <span class="formula"><i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>Px</i></span><span class="ignored">)</span></span></span></span><br>
<span lang="en">        for <span class="formula"><i>j</i><sub>1</sub> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>j</i><sub>2</sub> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :</span><br>
<span lang="en">             <span class="formula"><i>ξ</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, <i>t</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i><sub>1</sub>, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>E</i><sub><i>j</i><sub>2</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>⋅<i>β</i><sub><i>j</i><sub>2</sub>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>Px</i></span><span class="ignored">)</span></span></span></span><br>
<span lang="en">        <i># M-step</i></span><br>
<span lang="en">        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>:</span><br>
<span lang="en">             <span class="formula"><i>π</i><sub><i>j</i></sub> = <i>γ</i><sub><i>j</i>, 1</sub></span></span><br>
<span lang="en">            for <span class="formula"><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub> = [1, ..., 1]</span> <span class="formula">, ..., [4, ..., 4]</span>:</span><br>
<span lang="en">                 <span class="formula"><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, <i>b</i><sub>2</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>γ</i><sub><i>j</i>, <i>t</i></sub>⋅<b>1</b><sub><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub>(<i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>γ</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)</span></span></span></span><br>
<span lang="en">            for  <span class="formula"><i>l</i> = [1, ..., <i>k</i>]:</span></span><br>
<span lang="en">                 <span class="formula"><i>G</i><sub><i>j</i>, <i>l</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="unknown">\underset</span><i>t</i> ∈ 2, ..., <i>L</i><span class="limits"><span class="limit">∑</span></span><i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="unknown">\underset</span><i>t</i> ∈ 1, ..., <i>L</i> − 1<span class="limits"><span class="limit">∑</span></span><i>γ</i><sub><i>j</i><sub>1</sub>, <i>t</i></sub></span><span class="ignored">)</span></span></span></span><br>
<span lang="en">            for <span class="formula"><i>j</i><sub>2</sub> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">                 <span class="formula"><i>T</i><sub><i>j</i>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="unknown">\underset</span><i>t</i> ∈ 2, ..., <i>L</i><span class="limits"><span class="limit">∑</span></span><i>ξ</i><sub><i>j</i>, <i>j</i><sub>2</sub>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="unknown">\underset</span><i>t</i> ∈ 1, ..., <i>L</i> − 1<span class="limits"><span class="limit">∑</span></span><i>γ</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)</span></span></span></span><br>
<span lang="en">        If <span class="formula"><i>θ</i></span> converged, break EM for loop </span><br>
<span lang="en">    return <span class="formula"><i>θ</i></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">The algorithm is described with the input of a single sequence of observable variables <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>. In reality, we are faced with the task of learning <span class="formula"><i>θ</i></span> from multiple sequences at once. In HOP-HMM we can use the multi-sequence method as in <span class="bibcites">[<a class="bibliocite" name="cite-52" href="#biblio-52">52</a>]</span>, where the E-step probabilities are calculated separately for each sequence, and in the M-step all positions from all sequences are summed for the parameters update.</span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--10"></a><span lang="en">Sequence States Inference</span>
</h3>
<div class="Standard">
<span lang="en">Acquiring the maximal likelihood <span class="formula"><i>θ</i></span> opens the door to several needed inferences given a sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> :</span>
</div>
<ol>
<li>
<span lang="en">Most likely hidden state at any position in a sequence</span>
</li>
<li>
<span lang="en">Most likely hidden state sequence</span>
</li>
<li>
<span lang="en">Dominant hidden state in a short sequence</span>
</li>

</ol>
<div class="Standard">
<span lang="en"><span class="formula"><i>γ</i></span> <a class="Reference" href="#HOP-gamma">(15↑)</a> and <span class="formula"><i>η</i></span> <a class="Reference" href="#HOP-eta">(17↑)</a> can be used to solve inference 1 for HOP-HMM. We aim to maximize here a posterior probability in a specific position:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>y</i><sub><i>t</i></sub><sup>*</sup> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>], <i>l</i> ∈ [<i>k</i>]∪{0}<i>argmax</i><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">In regular HMM, we can approximate this by taking the state with the maximal posterior probability from <span class="formula"><i>γ</i></span> <a class="Reference" href="#gamma">(9↑)</a> built by a <span class="formula"><i>θ</i></span> that we obtained by the Baum-Welch algorithm. In HOP-HMM, <span class="formula"><i>γ</i></span> <a class="Reference" href="#HOP-gamma">(15↑)</a> is not sufficient since it only holds the probability of being in background state <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>. To calculate the posterior probability for TF states, <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> where <span class="formula"><i>l</i> &gt; 0</span> we sum all options of a TF state <span class="formula">(<i>j</i>, <i>l</i>)</span> that cover position <span class="formula"><i>t</i></span> as described in <a class="Reference" href="#PWM Posterior">(16↓)</a>. </span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − <i>i</i> + 1:<i>t</i> − <i>i</i> + |<i>W</i><sub><i>l</i></sub>|</sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = 
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − <i>i</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> − <i>i</i> + 1</sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>η</i><sub><i>t</i> − <i>i</i> + 1, <i>j</i>, <i>l</i></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">Choosing the maximum value over <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> and <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> will give us the most likely state of <span class="formula"><i>ŷ</i><sub><i>t</i></sub></span>:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="PosteriorEstimation">(18) </a><i>ŷ</i><sub><i>t</i></sub> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>], <i>l</i> ∈ [<i>k</i>]∪{0}<i>argmax</i><i>γ</i><sub><i>j</i>, <i>t</i></sub>∪<span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>η</i><sub><i>t</i> − <i>i</i> + 1, <i>j</i>, <i>l</i></sub>
</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="PWM Posterior"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/PWM_posterior_2.jpg" alt="figure Figures/PWM_posterior_2.jpg">
<div class="caption">
Figure 16 <span lang="en"><span class="formula"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>t</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> is the posterior probability to be in TF state <span class="formula">(<i>j</i>, <i>l</i>)</span> at position <span class="formula"><i>t</i></span>, marked in dark green. It is equal to the sum of probabilities of entering into the TF state before position <span class="formula"><i>t</i></span>. In this example, <span class="formula"><i>W</i><sub><i>l</i></sub></span> is a PWM of length 5, therefore it sums 5 different possible positions that include <span class="formula"><i>y</i><sub><i>t</i></sub></span>, marked in light green.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">Inference 2 aims to reach the most likely hidden sequence:</span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="Viterbi">(19) </a><i>y</i><sub>1:<i>L</i></sub><sup>*</sup> = <i>argmax</i><sub><i>y</i><sub>1:<i>L</i></sub></sub><i>P</i><span class="symbol">(</span><i>y</i><sub>1:<i>L</i></sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
</span>
</div>
<div class="Standard">
<span lang="en">The main difference with inference 1 is the consideration of the dependency between adjacent states. In inference 1, for example, two adjacent positions may be individually inferred states between which the transition probability equals 0. Even though each hidden state maximizes the likelihood at its position, as a sequence the result might not be the same states when accounting for the transitions. </span>
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--11"></a><span lang="en">HOP-Viterbi Algorithm</span>
</h3>
<div class="Standard">
<span lang="en">In HMM, deriving the maximal likelihood hidden sequence of <a class="Reference" href="#Viterbi">(19↑)</a> is done by the Viterbi algorithm, named after Andrew Viterbi who proposed it in <span class="bibcites">[<a class="bibliocite" name="cite-66" href="#biblio-66">66</a>]</span>. Viterbi algorithm resembles the Forward algorithm, with two main differences:</span>
</div>
<ol>
<li>
<span lang="en">Maximization replaces summation over the possible transitions.</span>
</li>
<li>
<span lang="en">Indices of the states with the maximal likelihood are kept in the dynamic filling of <span class="formula"><i>V</i><sup>2</sup></span>, and are eventually used to back-trace the chosen states in the most likely path. </span>
</li>

</ol>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-6"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 6 <span lang="en">Viterbi Algorithm</span>
</div>
</span><b><span lang="en">Input:</span></b><div class="PlainVisible">
<span lang="en">    <span class="formula"><i>θ</i></span>- HMM parameters <span class="formula">{<i>π</i>, <i>T</i>, <i>E</i>}</span></span><br>
<span lang="en">    \strikeout off\uuline off\uwave off<span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> - Observed DNA sequence</span>
</div>
<b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>1</sup> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span></span><br>
<span lang="en">        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>2</sup> = 0</span></span><br>
<span lang="en">    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]</span>:</span><br>
<span lang="en">        \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>1</sup> = <i>max</i><sub><i>j</i>’ ∈ [<i>m</i>]</sub><span class="symbol">(</span><i>V</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub><span class="symbol">)</span></span></span><br>
<span lang="en">             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>2</sup> = <i>argmax</i><sub><i>j</i>’ ∈ [<i>m</i>]</sub><span class="symbol">(</span><i>V</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub><span class="symbol">)</span></span></span><br>
<span lang="en">    <i># back tracing</i></span><br>
<span lang="en">     <span class="formula"><i>ŷ</i><sub><i>L</i></sub> = <i>argmax</i><sub><i>j</i></sub><i>V</i><sub><i>j</i>, <i>L</i></sub><sup>1</sup></span></span><br>
<span lang="en">    \strikeout off\uuline off\uwave offfor <span class="formula"><i>t</i> = [<i>L</i>, ..., 2]</span>:</span><br>
<span lang="en">        <span class="formula"><i>ŷ</i><sub><i>t</i> − 1</sub> = <i>V</i><sub><i>y</i><sub><i>t</i></sub>, <i>t</i></sub><sup>2</sup></span></span><br>
<span lang="en">    return <span class="formula"><i>ŷ</i><sub>1:<i>L</i></sub></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">For HOP-HMM, the Viterbi algorithm is adapted into a HOP-Viterbi algorithm in two ways: </span>
</div>
<ul>
<li>
<span lang="en">Maximization is done over two types of state transition probabilities: background to background and background to TF, held in A and B vectors.</span>
</li>
<li>
<span lang="en">The traces held in <span class="formula"><i>V</i><sup>2</sup></span> tables are two indices, since states in HOP-HMM are described by two indices.</span>
</li>

</ul>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Algorithm-7"> </a><div class="algorithm">
<span lang="en"><div class="caption">
Algorithm 7 <span lang="en">HOP-Viterbi Algorithm</span>
</div>
</span><b><span lang="en">Input:</span></b><div class="PlainVisible">
<span lang="en">    <span class="formula"><i>θ</i></span>- HOP-HMM parameters <span class="formula">{<i>π</i>, <i>T</i>, <i>G</i>, <i>E</i>}</span></span><br>
<span lang="en">    \strikeout off\uuline off\uwave off<span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> - Observed DNA sequence</span>
</div>
<b><span lang="en">Algorithm:</span></b><div class="PlainVisible">
<span lang="en">    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>1</sup> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span></span><br>
<span lang="en">        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>2</sup> = 0</span></span><br>
<span lang="en">    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]</span>:</span><br>
<span lang="en">        \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span></span><br>
<span lang="en">             <span class="formula"><i>A</i> = <span class="symbol">{</span><i>V</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>|<i>j</i>’ ∈ [<i>m</i>]<span class="symbol">}</span></span><i> # background state to background state</i></span><br>
<span lang="en">             <span class="formula"><i>B</i> = <span class="symbol">{</span><i>V</i><sub><i>j</i>, <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>|<i>l</i> ∈ [<i>k</i>]<span class="symbol">}</span></span> <i># background state to TF state</i></span><br>
<span lang="en">             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>1</sup> = <i>max</i><span class="symbol">(</span><i>A</i>∪<i>B</i><span class="symbol">)</span></span></span><br>
<span lang="en">             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>2</sup> = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
<span class="symbol">(</span><i>argmax</i>(<i>A</i>), 0<span class="symbol">)</span> 
</span>
<span class="case align-l">
<span class="ensuremath"><i>max</i>(<i>A</i>) &gt; <i>max</i>(<i>B</i>)</span> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
<span class="symbol">(</span><i>j</i>, <i>argmax</i>(<i>B</i>)<span class="symbol">)</span> 
</span>
<span class="case align-l">
<i>otherwise</i> 
</span>

</span>

</span>
</span></span><br>
<span lang="en">     <span class="formula"><i>ŷ</i><sub><i>L</i></sub> = <span class="symbol">(</span><i>argmax</i><sub><i>j</i></sub><i>V</i><sub><i>j</i>, <i>L</i></sub><sup>1</sup>, 0<span class="symbol">)</span></span> <i># mandatory background state at the end of the sequence</i></span><br>
<span lang="en">    \strikeout off\uuline off\uwave off<span class="formula"><i>t</i> = <i>L</i></span></span><br>
<span lang="en">    \strikeout off\uuline off\uwave offwhile <span class="formula"><i>t</i> &gt; 1</span>:</span><br>
<span lang="en">         <span class="formula"><span class="symbol">(</span><i>j</i>, <i>l</i><span class="symbol">)</span> = <i>V</i><sub><i>y</i><sub><i>t</i></sub>[0], <i>t</i></sub><sup>2</sup></span></span><br>
<span lang="en">        if <span class="formula"><i>l</i> = 0:</span><i> # if <span class="formula"><i>l</i> = 0</span> the hidden state at <span class="formula"><i>t</i> − 1</span> is a background state</i></span><br>
<span lang="en">             <span class="formula"><i>ŷ</i><sub><i>t</i> − 1</sub> = <span class="symbol">(</span><i>j</i>, 0<span class="symbol">)</span></span></span><br>
<span lang="en">             <span class="formula"><i>t</i> = <i>t</i> − 1</span></span><br>
<span lang="en">        else:</span><br>
<span lang="en">             <span class="formula"><i>ŷ</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = <span class="symbol">(</span><i>j</i>, <i>l</i><span class="symbol">)</span></span></span><br>
<span lang="en">             <span class="formula"><i>ŷ</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = <i>ŷ</i><sub><i>t</i></sub></span></span><br>
<span lang="en">             <span class="formula"><i>t</i> = <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</span></span><br>
<span lang="en">    return <span class="formula"><i>ŷ</i><sub>1:<i>L</i></sub></span></span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">The Viterbi paths of the DNA sequence can be used to evaluate the trained model by comparing it to the epigenetic data, as done in this work. In cases where the exact true boarders of the active element are unknown due to noisy data, short DNA sequences can be classified by their dominant states. We found this method useful in our preliminary evaluation of the algorithm, but did not include it in the results of this work. This simplistic classification is made by choosing the most abundant state in the estimated Viterbi path <span class="formula"><i>ŷ</i><sub>1:<i>L</i></sub>:</span></span>
</div>
<div class="Standard">
<span lang="en"><div class="formula">
<i>y</i><sub><i>class</i></sub> = <i>mode</i><sub><i>t</i> ∈ [<i>L</i>]</sub><i>ŷ</i><sub><i>t</i></sub>
</div>
</span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--5"></a><span lang="en">Results</span>
</h1>
<div class="Standard">
<span lang="en">In order to evaluate HOP-HMM, we first measured its capabilities on synthetic DNA data which were created in a controlled way. We could then experiment with HOP-HMM on real human DNA sequences. The evaluation process on synthetic data was performed through the following steps (see figure <a class="Reference" href="#Workflow">17↓</a>):</span>
</div>
<ol>
<li>
<span lang="en">We generated parameters for a HOP-HMM <span class="formula"><i>θ</i></span>, which were treated as the true <span class="formula"><i>θ</i></span>. <span class="formula"><i>θ</i></span> was sampled in the following way:</span><ol>
<li>
<span lang="en">Each <span class="formula"><i>T</i></span> cell was sampled from a uniform distribution<div class="formula">
<a class="eqnumber" name="minTmaxT">(20) </a><i>T</i><sub><i>i</i>, <i>j</i></sub> ~ <i>U</i><span class="symbol">(</span><i>minT</i><sub><i>i</i>, <i>j</i></sub>, <i>maxT</i><sub><i>i</i>, <i>j</i></sub><span class="symbol">)</span>
</div>
</span>
</li>
<li>
<span lang="en">Each cell <span class="formula"><i>G</i></span> cell was sampled both from a uniform and from a Bernoulli distribution <div class="formula">
<a class="eqnumber" name="noiseG">(21) </a><i>G</i><sub><i>i</i>, <i>j</i></sub> ~ <i>U</i><span class="symbol">(</span><i>minG</i>, <i>noiseG</i><span class="symbol">)</span> + <b>1</b><sub><span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span> ∈ <i>Reg</i></sub>⋅<i>Bern</i><span class="symbol">(</span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>k</i></span><span class="ignored">)/(</span><span class="denominator"><i>m</i></span><span class="ignored">)</span></span><span class="symbol">)</span>⋅<i>maxG</i>
</div>
</span><div class="Standard">
<span lang="en">where <div class="formula">
<b>1</b><sub><span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span> ∈ <i>ENH</i></sub> = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
1 
</span>
<span class="case align-l">
<span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span> ∈ <i>ENH</i> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
0 
</span>
<span class="case align-l">
<i>otherwise</i> 
</span>

</span>

</span>

</div>
<span class="formula"><i>ENH</i></span> is the set of “enhancer-mimicking” background states, which are predefined background states that have a high probability of transitioning into TF states. The rest of the background states will have a low probability to create TFBS, since we want some of the states to model sparse TFBSs (non-regulatory elements) surrounding the enhancers. In our experiments <span class="formula"><i>ENH</i></span> contained all but one state: <span class="formula"><span class="symbol">(</span><i>m</i>, 0<span class="symbol">)</span></span> meaning that one background state had almost no TFBS and the other <span class="formula"><i>m</i> − 1</span> background states did have TFBSs</span>
</div>

</li>
<li>
<span lang="en">After being sampled, <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span> cells were divided element-wise by the sum of their rows, so that the ensemble of every row of <span class="formula"><i>T</i></span> and its corresponding row of <span class="formula"><i>G</i></span> became a distribution:</span><div class="Standard">
<span lang="en"><div class="formula">
<a class="eqnumber" name="GT_normalization">(22) </a><span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>T</i><sub><i>i</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>T</i><sub><i>i</i>, <i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>i</i>, <i>j</i>’</sub> + <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>k</i>]</sub><i>G</i><sub><i>i</i>, <i>j</i>’</sub></span><span class="ignored">)</span></span>
</span>
<span class="arraycell align-l">

</span>
<span class="arraycell align-r">
<i>G</i><sub><i>i</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>G</i><sub><i>i</i>, <i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>i</i>, <i>j</i>’</sub> + <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>k</i>]</sub><i>G</i><sub><i>i</i>, <i>j</i>’</sub></span><span class="ignored">)</span></span>
</span>

</span>
</span>
</div>
</span>
</div>

</li>
<li>
<span lang="en"><span class="formula"><i>E</i></span> was sampled from a uniform distribution <span class="formula"><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> ~ <i>U</i><span class="symbol">(</span>0, 1<span class="symbol">)</span></span> and divided by the sum of its last index to become a distribution array, similar to (c):<div class="formula">
<i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>b</i>’ = [4]</sub><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i> − 1</sub>, <i>b</i>’</sub></span><span class="ignored">)</span></span>
</div>
</span>
</li>
<li>
<span lang="en">The start state distribution <span class="formula"><i>π</i></span> was non-random, and was set so that the first states were always one of the non-enhancer background states<div class="formula">
<i>π</i><sub><i>i</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><b>1</b><sub><span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span>∉<i>ENH</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>m</i> − |<i>ENH</i>|</span><span class="ignored">)</span></span>
</div>
</span>
</li>

</ol>

</li>
<li>
<span lang="en">2. Sequences were generated using the HOP-HMMs with the true <span class="formula"><i>θ</i></span>. Both the observed and the hidden sequences were used, denoted <span class="formula"><i>X</i></span> and <span class="formula"><i>Y</i></span>. We split the <span class="formula"><i>X</i></span> and <span class="formula"><i>Y</i></span> sequences into train and test for cross validation. </span>
</li>
<li>
<span lang="en">3. From the DNA sequences of <span class="formula"><i>X</i></span> train, we trained a <span class="formula"><i>θ̂</i></span> with the HOP Baum-Welch algorithm.</span>
</li>
<li>
<span lang="en">Using the trained parameters <span class="formula"><i>θ̂</i></span>, we estimated <span class="formula"><i>Ŷ</i></span> test from <span class="formula"><i>X</i></span> test and <span class="formula"><i>Ŷ</i></span> train from <span class="formula"><i>X</i></span> train by the HOP-Viterbi algorithm. We also calculated the posterior probability of <span class="formula"><i>P</i><sub><i>θ̂</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> from <span class="formula"><i>X</i></span> test and <span class="formula"><i>X</i></span> train. These results were then compared to the real <span class="formula"><i>Y</i></span> test and <span class="formula"><i>Y</i></span> train to check for accuracy. </span>
</li>

</ol>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="Workflow"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/Workflow.jpg" alt="figure Figures/Workflow.jpg">
<div class="caption">
Figure 17 <span lang="en">Workflow of the evaluation process. A <span class="formula"><i>θ</i></span> is sampled and a HOP-HMM model is created with which several fixed-length sequences are generated. A new model <span class="formula"><i>θ̂</i></span> is then fitted to the train section of the observed sequences, via a HOP-Baum-Welch algorithm. With <span class="formula"><i>θ̂</i>, </span> a hidden sequence is then estimated by a HOP-Viterbi algorithm, and a posterior probability estimation is calculated by <a class="Reference" href="#PosteriorEstimation">(18↑)</a>.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">The Baum-Welch algorithm ensures the increase of the likelihood for each step. However it does not ensure convergence to the optimal <span class="formula"><i>θ</i><sup>*</sup></span> (<span class="bibcites">[<a class="bibliocite" name="cite-52" href="#biblio-52">52</a>]</span>) since there is no known analytical way to reach it. As a consequence, Baum-Welch algorithm converges into a local maximum <span class="formula"><i>θ̂</i></span> which could be a relatively low likelihood estimation, depending on the initialization point of the first <span class="formula"><i>θ</i></span>. During the initial evaluation of the inference EM algorithm, many runs converged to local maxima which tended to overshoot the inter-states transition probability, resulting in a tendency to irregular Viterbi paths with frequent state changes. This resembles the known issue of HMM parameter overfitting on small training data. </span>
</div>
<div class="Standard">
<span lang="en">We therefore addressed this issue in two ways that had a significant positive impact on the convergence rate and solution quality:</span>
</div>
<div class="Standard">
<span lang="en">1. We used regularization for faster and better <span class="formula"><i>θ̂</i></span> convergence (see figure <a class="Reference" href="#Regularization">19↓</a>). Following each M-step update we drew the background states transition probabilities <span class="formula"><i>T</i></span> to remain between <span class="formula"><i>maxT</i></span> and <span class="formula"><i>minT</i></span> matrices from <a class="Reference" href="#minTmaxT">(20↑)</a>:</span>
</div>
<ul>
<li>
<span lang="en">If <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> &lt; <i>minT</i><sub><i>i</i>, <i>j</i></sub></span> then we set <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> = <i>minT</i><sub><i>i</i>, <i>j</i></sub></span></span>
</li>
<li>
<span lang="en">If <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> &gt; <i>maxT</i><sub><i>i</i>, <i>j</i></sub></span> then we set <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> = <i>maxT</i><sub><i>i</i>, <i>j</i></sub></span></span>
</li>
<li>
<span lang="en"><span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span> cells were divided by the sum of their rows so that the ensemble of their rows remained a distribution as in <a class="Reference" href="#GT_normalization">(22↑)</a></span>
</li>

</ul>
<div class="Standard">
<span lang="en">2. Since Baum-Welch seeks local maxima, running it multiple times with different initializations would cause convergence for different <span class="formula"><i>θ̂</i></span> results. As could be expected, we observed throughout multiple initializations that the higher the log likelihood of final <span class="formula"><i>θ̂</i></span> the lower its root mean square error (RMSE) compared to the true <span class="formula"><i>θ</i></span> (see figure <a class="Reference" href="#LikelihoodVsErr">18↓</a>). This is important since on observed real sequences only the estimated <span class="formula"><i>θ̂</i></span> likelihood is known, while the true <span class="formula"><i>θ</i></span> is unknown. This correlation implies that in order to obtain an estimated <span class="formula"><i>θ̂</i></span> as close as possible to the true <span class="formula"><i>θ</i></span>, one should redo several EM runs and choose the <span class="formula"><i>θ̂</i></span> with the highest likelihood. </span>
</div>
<div class="Standard">
<span lang="en">The experiment was done on 500 synthetic sequences (85% train, 15% test), 1500 bp-long. The trained model had 6 hidden background states with an emission order of 3, and each background state had 25 TF states. The background-state precision was 98.5% and the recall of 97.6%. </span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="LikelihoodVsErr"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg" alt="figure Figures/rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg">
<div class="caption">
Figure 18 <span lang="en">Over multiple runs of HOP-Baum-Welch, higher sequences likelihood for the estimated <span class="formula"><i>θ</i></span> resulted in lower errors compared to the true <span class="formula"><i>θ</i></span>. </span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en"><p><br>
</p>
<div class="float">
<a class="Label" name="Regularization"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/dec_likelihood.jpg" alt="figure Figures/dec_likelihood.jpg">
</span>
</div>
<div class="PlainVisible">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/dec_theta_error.jpg" alt="figure Figures/dec_theta_error.jpg">
</span>
</div>

</div>
<div class="PlainVisible">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/dec_theta_error_scatter.jpg" alt="figure Figures/dec_theta_error_scatter.jpg">
</span>
</div>

</div>
<div class="PlainVisible">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/dec_viterbi.jpg" alt="figure Figures/dec_viterbi.jpg">
<div class="caption">
Figure 19 <span lang="en"><b>A)</b> EM iterations mostly draw the estimated <span class="formula"><i>θ</i></span> values closer to the true value of <span class="formula"><i>θ</i></span>. <b>B)</b> The error between true and estimated <span class="formula"><i>θ</i></span> decreases, and after a few iterations they converge to the same path regardless of the initialization. <b>C)</b> During EM iterations, the learned <span class="formula"><i>θ</i></span> values yield a more accurate Viterbi estimation of the hidden states. Note that not even the true <span class="formula"><i>θ</i></span> could produce a Viterbi path that is a perfect match to the true hidden sequence. <b>D)</b> The mean log likelihood of the sequences increases during the EM iterations.</span>
</div>
</span>
</div>

</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="PostiriorProbability"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/synthetic_posterior_with_tfs.jpg" alt="figure Figures/synthetic_posterior_with_tfs.jpg">
<div class="caption">
Figure 20 <span lang="en">Posterior probability of sequences, estimated by a trained HOP-HMM <span class="formula"><i>θ̂</i></span> on test sequences that were synthetically generated by a HOP-HMM <span class="formula"><i>θ</i></span>. The Viterbi hidden path by <span class="formula"><i>θ̂</i></span> and the true hidden states of each sequence are shown at the bottom of each posterior probability. The black TFBS is the sum of all the probabilities of being in any of the TF states. </span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="ConfutionMatrix"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/confusion_matrix.jpg" alt="figure Figures/confusion_matrix.jpg">
<div class="caption">
Figure 21 <span lang="en">Confusion matrix of true and estimated states by the Viterbi algorithm of HOP-HMM synthetic sequences. Rows are normalized so their sum is equal to 1. The majority of predictions are in the background states <span class="formula">(1, 0)</span>, <span class="formula">(2, 0)</span>, <span class="formula">(3, 0)</span>, <span class="formula">(4, 0)</span> and <span class="formula">(5, 0)</span>, where TF states are sometimes misclassified as their background state state.</span>
</div>
</span>
</div>

</div>

</div>
</span>
</div>
<div class="Standard">
<span lang="en">For the testing of HOP-HMM on human genetic data, we sought to assess if HOP-HMM could distinguish and detect enhancers active in two human tissues.</span>
</div>
<div class="Standard">
<span lang="en">We created a dataset of enhancer sequences based on epigenetic data collected from 57 tissues by the Roadmap project. To choose the location of the enhancer elements, we manipulated the Roadmap project Bed files with BEDTools (<span class="bibcites">[<a class="bibliocite" name="cite-50" href="#biblio-50">50</a>]</span>). We chose the intersection of DNase-I, H3K27ac and H3K4me1 peaks, while avoiding peaks of H3K27me3 and H3K4me3, and sequences within 5000 bp from known genes. The sequences chosen where 5000 bp-long sequences from the hg19 assembly, centered around their DNase-I peak to ensure the flanks of the enhancer. Among these enhancers, we chose only sequences of tissue-specific enhancers in one of two types of tissues, while choosing the two tissues out of the 57 tissues. After some trial and error, we chose the somewhat arbitrary cutoff of the top 40% strongest DNase-seq peaks, which yielded enough sequences (around 500 sequences per tissue sample on average) with distinguishable distributions between the tissues. We added sequences with no known role from random locations in the genome, distant from genes or enhancers background sequences. </span>
</div>
<div class="Standard">
<span lang="en">A HOP-HMM was trained by the HOP-Baum-Welch algorithm on the collected sequences. The trained model was then used to produce a Viterbi estimated hidden states sequence and posterior probability, which could be compared to the epigenetic tracks. </span>
</div>
<div class="Standard">
<span lang="en">For the set of PWMs used by the TF states of the HOP-HMM, we used a JASPAR dataset of 519 vertebrates PWMs, out of which we selected 50 PWMs for a practical run-time. The selected PWMs were chosen by 3 methods, each method being responsible for one third of these 50 PWMs: </span>
</div>
<ul>
<li>
<span lang="en">PWMs of TFs relatively expressed for one tissue compared to the other, according to the Roadmap RNA-seq data. This method does not depend on the sequences themselves, but on the epigenetic properties of the tissues.</span>
</li>
<li>
<span lang="en">PWMs which are abundant in the sequences, i.e. PWMs with the highest mean likelihood to attach to sequences. The average likelihood of PWM <span class="formula"><i>W</i></span> to bind to a sequence <span class="formula"><i>x</i></span> was simplified as the mean of the 3 highest binding likelihoods in the sequence, as described in figure <a class="Reference" href="#PWM">3↑</a>. Note that in order to compare between PWM likelihoods we used here the PWM form as in <a class="Reference" href="#PPM">(1↑)</a>, and not the PPM form. </span>
</li>
<li>
<span lang="en">PWMs that had strong presence in sequences from one tissue compared to the other. Specifically, the PWMs with sequence binding likelihoods (as defined in the previous method) that can best distinguish between the sequences from one tissue and the sequences of the other tissues in terms of AUC-ROC. </span>
</li>

</ul>
<div class="Standard">
<span lang="en">In our experiment, posterior probability of some sequences had a good resemblance to the DNase-seq track, causing a good overlap between the Viterbi-path and the ChromeHMM classifications (see figure <a class="Reference" href="#fig:RealSequences">22↓</a>), though such similarity did not always occur.</span>
</div>
<div class="Standard">
<span lang="en"><p><br>
</p>
</span>
</div>
<div class="Standard">
<span lang="en"><div class="float">
<a class="Label" name="fig:RealSequences"> </a><div class="figure">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/realSeq1.jpg" alt="figure Figures/realSeq1.jpg">
</span>
</div>
<div class="PlainVisible">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/realSeq2.jpg" alt="figure Figures/realSeq2.jpg">
</span>
</div>

</div>
<div class="PlainVisible">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/realSeq3.jpg" alt="figure Figures/realSeq3.jpg">
</span>
</div>

</div>
<div class="PlainVisible">
<div class="center">
<span lang="en"><img class="embedded" src="Figures/realSeqLegend.jpg" alt="figure Figures/realSeqLegend.jpg">
<div class="caption">
Figure 22 <span lang="en">Examples of HOP-HMM classification of 5000pb long tissue specific enhancer sequences from the human genome. Each of the 3 graphs is the output of a different HOP-HMM with three background states (two enhancer states and one non-enhancer state) and 50 TF states, and each was trained on enhancers from the two chosen tissues. H3K27ac and DNase-I measurements are in <span class="formula"> − <i>log</i><sub>10</sub>(<i>p</i> − <i>value</i>)</span> units.</span>
</div>
</span>
</div>

</div>

</div>

</div>
</span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--6"></a><span lang="en">Discussion and Conclusions</span>
</h1>
<div class="Standard">
<span lang="en">In this work I aimed to develop a generalized HMM, HOP-HMM, tailored for the enhancer structure. I developed the mathematical adjustments to the different parts of the EM algorithm and provided reasoning for the correctness of inferring the altered model from data. I also implemented a model and an algorithm in Matlab code for the evaluation on real or synthetic data, as described in the results. During the algorithm implementation, I overcame a few difficulties originating from the scale of the data, such as caching the costly response of the PWMs to the sequences during the Forward Backward algorithms, and splitting sequences into batches in order to hold and manipulate the large <span class="formula"><i>η</i></span> <a class="Reference" href="#HOP-eta">(17↑)</a> matrix in the memory. The implementation also included a code for generating DNA sequences from a randomly selected HOP-HMM to which a different model can be fitted and compared. Naturally, in the synthetic data experiment, the larger the generated dataset that is used to fit the model the better the performance of the fitting. Overall, the generated DNA sequences experiment results were positive and provided evidence for the ability of the algorithm to train successfully on DNA sequences created under the HOP-HMM assumptions.</span>
</div>
<div class="Standard">
<span lang="en">In order to apply the EM algorithm to real data, I designed an experiment to assess the ability of the model to detect real human enhancers whose locations were deducted from epigenetic data of the Roadmap project. This experiment was based on a dataset we created and which contained tissue-specific enhancers from two tissues and non-regulatory “background” sequences. Though some of these sequences were correctly classified, no tested pair of tissues had an HOP-HMM classification with consistent similarity to its epigenetic data. This might be caused by one of two reasons: the EM algorithm didn’t converge toward good enough parameters, or no such parameters exist.</span>
</div>
<div class="Standard">
<span lang="en">As for the former possibility, the experiments done with our synthetic data showed a tradeoff between the amount of data provided to the EM algorithm and its ability to converge toward parameters that are able to detect the difference between background states holding similar emission distributions (<span class="formula"><i>E</i></span> and <span class="formula"><i>G</i></span>) in the generating HOP-HMM parameters. In other words, convergence of the EM to low quality local maxima mainly occurred when the emission distributions in the generating parameters were not significantly different. This tradeoff is common in the machine learning field, as the ability of many models to distinguish between similar classes depends on the amount of relevant samples in the training dataset (<span class="bibcites">[<a class="bibliocite" name="cite-15" href="#biblio-15">15</a>]</span>). In our dataset of human enhancers, most tissues had only several hundreds of enhancer sequences, which might have been insufficient for a high quality convergence of the EM algorithm. </span>
</div>
<div class="Standard">
<span lang="en">As for the latter possibility, this could mean that the spanned solution space of the HOP-HMM assumption do not match our human enhancers dataset. This could stem from several reasons: wrong PWMs selection as hyperparameters, too small or noisy dataset building from the Roadmap data, and even a more complex enhancer structure than assumed by the HOP-HMM hypothesis. </span>
</div>
<div class="Standard">
<span lang="en">In further research, the use of updated data with cleaner experiments and/or more tissue diversity would likely provide better results. Improvements to HOP-HMM which should be tried in the future are the introduction of learning to the PWMs preceding or during EM iterations, or the entire replacement of the PWMs emission by a different TFBS modeling method. </span>
</div>
<div class="Standard">
<span lang="en"><p><br>
</p>
</span>
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--7"></a><span lang="en">Appendix: Source Code</span>
</h1>
<div class="Standard">
<span lang="en">The code for this research was written in Matlab, and can be found in <a class="FlexURL" href="https://github.com/David-Taub/HOP-HMM">https://github.com/David-Taub/HOP-HMM</a>.</span>
</div>
<div class="Standard">
<span lang="en"><table>
<tr>
<td align="left" valign="top">
<span lang="en">Variable</span>
</td>
<td align="left" valign="top" style="width: 10cm;">
<span lang="en">Meaning</span>
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span lang="en"><span class="code"><div class="PlainVisible">
<span lang="en">L</span>
</div>
</span></span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
<span lang="en">DNA sequences length</span>
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span lang="en"><span class="code"><div class="PlainVisible">
<span lang="en">N</span>
</div>
</span></span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
<span lang="en">Number of DNA sequences</span>
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span lang="en"><span class="code"><div class="PlainVisible">
<span lang="en">m</span>
</div>
</span></span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
<span lang="en">Number of background states</span>
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span lang="en"><span class="code"><div class="PlainVisible">
<span lang="en">k</span>
</div>
</span></span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
<span lang="en">Number of TF states of each background state</span>
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span lang="en"><span class="code"><div class="PlainVisible">
<span lang="en">order</span>
</div>
</span></span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
<div class="PlainVisible">
<span lang="en">Dependency order of the emission of the background states done by <span class="formula"><i>E</i></span>. For example, if <span class="code"><div class="PlainVisible">
<span lang="en">order</span>
</div>
</span> equals 3, then the emission is conditional on 2 previous observable variables. </span>
</div>

</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span lang="en"><span class="code"><div class="PlainVisible">
<span lang="en">backgroundAmount</span>
</div>
</span></span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;" colspan="1">
<span lang="en">Number of background states which are non-enhancers by having low transition probability into TF states</span>
</td>

</tr>

</table>
</span>
</div>
<div class="Standard">
<span lang="en">The prominent code files in the project:</span>
</div>
<ul>
<li>
<b><span lang="en">HOP-HMM/data/peaks/scripts/download_and_process_all.sh</span></b><div class="Standard">
<span lang="en">Linux bash script which downloads data files of epigenetic from Roadmap website, JASPAR PWMs and hg19 genome. After downloading, the data is per-processed with Bedtools and bigWigToBedGraph. The only part in this project that requires Linux is the bigWigToBedGraph.</span>
</div>

</li>
<li>
<b><span lang="en">HOP-HMM/src/+peaks/minimizeMergePeak.m</span></b><div class="Standard">
<span lang="en">Reads downloaded bed files, processes them and saves them into MAT-file v7.3. </span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound); </span></span></span><br>
<span lang="en"><span class="code"><span lang="en">mergedPeaksMin = minimizeMergePeak(params, L)</span></span>;</span>
</blockquote>
<div class="Standard">
<span lang="en">where <span class="code"><span lang="en">doGTBound</span></span> indicates whether or not to apply regularization on <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span> transition probabilities and <span class="code"><span lang="en">doESharing</span></span> indicates whether or not to force <span class="formula"><i>E</i></span> to share the emission across all background states </span>
</div>

</li>
<li>
<b><span lang="en">HOP-HMM/src/misc/genSyntheticMergedPeaksMin.m</span></b><div class="Standard">
<span lang="en">Generates DNA sequences <span class="formula"><i>X</i></span> and hidden variables <span class="formula"><i>Y</i></span> out of a random <span class="formula"><i>θ</i></span>, which was sampled by genTheta.m</span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);</span></span> <span class="code"><span lang="en">mergedPeaksMin = genSyntheticMergedPeaksMin(N, L, params, startWithBackground, backgroundGNoise);</span></span></span>
</blockquote>
<div class="Standard">
<span lang="en">where <span class="code"><span lang="en">startWithBackground</span></span> indicates whether or not to force <span class="formula"><i>π</i></span> to allow starting only from non-enhancer background states and <span class="code"><span lang="en">backgroundGNoise</span></span> is the background rate of background state to TF state transition, marked as <span class="formula"><i>noiseG</i></span> in <a class="Reference" href="#noiseG">(21↑)</a></span>
</div>

</li>
<li>
<b><span lang="en">HOP-HMM/src/misc/genTheta.m</span></b><div class="Standard">
<span lang="en">Generates a random <span class="formula"><i>θ</i></span>, with options to sample a total random <span class="formula"><i>T</i></span> and a total random <span class="formula"><i>π</i></span>. Note that <span class="formula"><i>π</i></span> is called <span class="code"><span lang="en">theta.startT</span></span> throughout the code.</span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound); </span></span></span><br>
<span lang="en"><span class="code"><span lang="en">theta = genTheta(params, false, false);</span></span></span>
</blockquote>

</li>
<li>
<b><span lang="en">HOP-HMM/src/mainRealData.m</span></b><div class="Standard">
<span lang="en">Entry point of the code, reads data from the human genome, trains HOP-HMMs model and compares posterior probability to real epigenetic data. Execution of mainRealData will produce figures similar to figure <a class="Reference" href="#RealData">↓</a></span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">mainRealData();</span></span></span>
</blockquote>

</li>
<li>
<b><span lang="en">HOP-HMM/src/mainPosterior.m</span></b><div class="Standard">
<span lang="en">Entry point of the code, follows the workflow of figure <a class="Reference" href="#Workflow">17↑</a>. Execution of mainPosterior plots random set of sequences with their Viterbi sequences and posterior probabilities similar to figure <a class="Reference" href="#PostiriorProbability">20↑</a>, and a confusion matrix similar to figure <a class="Reference" href="#ConfutionMatrix">21↑</a>.</span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">mainPosterior();</span></span></span>
</blockquote>

</li>
<li>
<b><span lang="en">HOP-HMM/src/mainDecErrorPlot.m</span></b><div class="Standard">
<span lang="en">Entry point of the code, follows the workflow of figure <a class="Reference" href="#Workflow">17↑</a>, and at each iteration of the EM, likelihood and errors are collected to form plots similar to figure <a class="Reference" href="#Regularization">19↑</a>.</span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">mainDecErrorPlot();</span></span></span>
</blockquote>

</li>
<li>
<b><span lang="en">HOP-HMM/src/+EM/EM.m</span></b><div class="Standard">
<span lang="en">The function actually trains the HOP-HMM model from a given DNA sequence is the EM(). The neighboring code files residing in the +EM folder which contains it, are the implementations of the E and M steps described in the introduction part of this work.</span>
</div>
<blockquote class="Quote">
<span lang="en"><span class="code"><span lang="en">[test, train] = misc.crossValidationSplit(params, mergedPeaksMin, testTrainRatio);</span></span></span><br>
<span lang="en"><span class="code"><span lang="en">[bestTheta, bestLikelihood, bestThetas] = EM(train, params, maxIter, patience, repeat);</span></span></span>
</blockquote>
<div class="Standard">
<span lang="en">where <span class="code"><span lang="en">maxIter</span></span> is the maximal number of iterations allowed in a run, <span class="code"><span lang="en">parience</span></span> is the number of iterations without likelihood increase allowed in a run and <span class="code"><span lang="en">repeat</span></span> is the number of different runs with different initializations which are tried.</span>
</div>

</li>

</ul>
<div class="Standard">
<span lang="en"><p><br>
</p>
</span>
</div>
<a class="toc" name="References"></a><h1 class="biblio">
References
</h1>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-1">1</a>] </span> Ahituv, N., Zhu, Y., Visel, A., Holt, A., Afzal, V., Pennacchio, L. A., &amp; Rubin, E. M. (2007). Deletion of ultraconserved elements yields viable mice. PLoS biology, 5(9), e234.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-2">2</a>] </span> Ainscough, R., Bardill, S., Barlow, K., Basham, V., Baynes, C., Beard, L., ... &amp; Burrows, C. (1998). Genome sequence of the nematode C. elegans: a platform for investigating biology. Science, 282(5396), 2012-2018.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-3">3</a>] </span> Alipanahi, B., Delong, A., Weirauch, M. T., &amp; Frey, B. J. (2015). Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning. Nature biotechnology, 33(8), 831.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-4">4</a>] </span> Baum, L. E., &amp; Petrie, T. (1966). Statistical inference for probabilistic functions of finite state Markov chains. The annals of mathematical statistics, 37(6), 1554-1563.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-5">5</a>] </span> Benko, S., Fantes, J. A., Amiel, J., Kleinjan, D., Thomas, S., Ramsay, J., et al. (2009). Highly conserved non. Nature Genetics 64(2), p. 10-12.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-6">6</a>] </span> Boyle, A. P., Davis, S., Shulha, H. P., Meltzer, P., Margulies, E. H., Weng, Z., ... &amp; Crawford, G. E. (2008). High-resolution mapping and characterization of open chromatin across the genome. Cell, 132(2), 311-322.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-7">7</a>] </span> Burge, C., &amp; Karlin, S. (1997). Prediction of complete gene structures in human genomic DNA. Journal of molecular biology, 268(1), 78-94.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-8">8</a>] </span> Buenrostro, J. D., Giresi, P. G., Zaba, L. C., Chang, H. Y., &amp; Greenleaf, W. J. (2013). Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nature methods, 10(12), 1213.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-9">9</a>] </span> Calo, E., &amp; Wysocka, J. (2013). Modification of enhancer chromatin: what, how, and why?. Molecular cell, 49(5), 825-837.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-10">10</a>] </span> Creyghton, M. P., Cheng, A. W., Welstead, G. G., Kooistra, T., Carey, B. W., Steine, E. J., ... &amp; Boyer, L. A. (2010). Histone H3K27ac separates active from poised enhancers and predicts developmental state. Proceedings of the National Academy of Sciences, 107(50), 21931-21936.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-11">11</a>] </span> Cutter, A. R., &amp; Hayes, J. J. (2015). A brief review of nucleosome structure. FEBS letters, 589(20), 2914-2922.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-12">12</a>] </span> De Beer, Z. W., Duong, T. A., Barnes, I., Wingfield, B. D., &amp; Wingfield, M. J. (2014). Redefining Ceratocystis and allied genera. Studies in Mycology, 79, 187-219.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-13">13</a>] </span> Diehl, A. D., Meehan, T. F., Bradford, Y. M., Brush, M. H., Dahdul, W. M., Dougall, D. S., ... &amp; Van Slyke, C. E. (2016). The Cell Ontology 2016: enhanced content, modularization, and ontology interoperability. Journal of biomedical semantics, 7(1), 44.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-14">14</a>] </span> Doniger, S. W., Huh, J., &amp; Fay, J. C. (2005). Identification of functional transcription factor binding sites using closely related Saccharomyces species. Genome research, 15(5), 701-709.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-15">15</a>] </span> Dupin, M., Reynaud, P., Jarošík, V., Baker, R., Brunel, S., Eyre, D., ... &amp; Makowski, D. (2011). Effects of the training dataset characteristics on the performance of nine species distribution models: application to Diabrotica virgifera virgifera. PLoS One, 6(6).</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-16">16</a>] </span> Du Preez, J. A. (1998). Efficient training of higher-order hidden Markov models using first-order representations. Computer speech &amp; language, 12(1), 23-39.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-17">17</a>] </span> Emison, E. S., McCallion, A. S., Kashuk, C. S., Bush, R. T., Grice, E., Lin, S., ... &amp; Chakravarti, A. (2005). A common sex-dependent mutation in a RET enhancer underlies Hirschsprung disease risk. Nature, 434(7035), 857.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-18">18</a>] </span> Ernst, J., &amp; Kellis, M. (2012). ChromHMM: automating chromatin-state discovery and characterization. Nature methods, 9(3), 215.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-19">19</a>] </span> Ernst, J., Kheradpour, P., Mikkelsen, T. S., Shoresh, N., Ward, L. D., Epstein, C. B., ... &amp; Ku, M. (2011). Mapping and analysis of chromatin state dynamics in nine human cell types. Nature, 473(7345), 43.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-20">20</a>] </span> Ezkurdia, I., Juan, D., Rodriguez, J. M., Frankish, A., Diekhans, M., Harrow, J., ... &amp; Tress, M. L. (2014). Multiple evidence strands suggest that there may be as few as 19 000 human protein-coding genes. Human molecular genetics, 23(22), 5866-5878.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-21">21</a>] </span> Ferguson, J. D. (1980). pp. 143–179, Variable duration models for speech. In Proc. of the Symposium on the applications of hidden Markov models to text and speech, JD Ferguson, Ed. Princeton: IDA-CRD.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-22">22</a>] </span> Fishilevich, S., Nudel, R., Rappaport, N., Hadar, R., Plaschkes, I., Iny Stein, T., ... &amp; Lancet, D. (2017). GeneHancer: genome-wide integration of enhancers and target genes in GeneCards. Database, 2017.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-23">23</a>] </span> Friedli, M., Barde, I., Arcangeli, M., Verp, S., Quazzola, A., Zakany, J., ... &amp; Duboule, D. (2010). A systematic enhancer screen using lentivector transgenesis identifies conserved and non-conserved functional elements at the Olig1 and Olig2 locus. PLoS One, 5(12), e15741. </span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-24">24</a>] </span> Galperin, M. Y., &amp; Fernández-Suarez, X. M. (2011). The 2012 nucleic acids research database issue and the online molecular biology database collection. Nucleic acids research, 40(D1), D1-D8.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-25">25</a>] </span> Haussler, D. K. D., &amp; Eeckman, M. G. R. F. H. (1996). A generalized hidden Markov model for the recognition of human genes in DNA. In Proc. int. conf. on intelligent systems for molecular biology, st. louis (pp. 134-142).</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-26">26</a>] </span> Hayashi-Takanaka, Y., Yamagata, K., Wakayama, T., Stasevich, T. J., Kainuma, T., Tsurimoto, T., ... &amp; Kimura, H. (2011). Tracking epigenetic histone modifications in single cells using Fab-based live endogenous modification labeling. Nucleic acids research, 39(15), 6475-6488.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-27">27</a>] </span> Heintzman, N. D., Stuart, R. K., Hon, G., Fu, Y., Ching, C. W., Hawkins, R. D., ... &amp; Wang, W. (2007). Distinct and predictive chromatin signatures of transcriptional promoters and enhancers in the human genome. Nature genetics, 39(3), 311.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-28">28</a>] </span> Heintzman, N. D., Hon, G. C., Hawkins, R. D., Kheradpour, P., Stark, A., Harp, L. F., ... &amp; Ching, K. A. (2009). Histone modifications at human enhancers reflect global cell-type-specific gene expression. Nature, 459(7243), 108.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-29">29</a>] </span> Hu, J., Brown, M. K., &amp; Turin, W. (1996). HMM based online handwriting recognition. IEEE Transactions on pattern analysis and machine intelligence, 18(10), 1039-1045.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-30">30</a>] </span> Jin Q, Yu L-R, Wang L, Zhang Z, Kasper LH, Lee J-E, Wang C, Brindle PK, Dent SYR, Ge K. 2011. Distinct roles of GCN5/PCAF-mediated H3K9ac and CBP/p300-mediated H3K18/27ac in nuclear receptor transactivation. The EMBO Journal 30:249–262.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-31">31</a>] </span> Jones, P. A. (2012). Functions of DNA methylation: islands, start sites, gene bodies and beyond. Nature Reviews Genetics, 13(7), 484.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-32">32</a>] </span> Kaplan, T., &amp; Biggin, M. D. (2012). Quantitative models of the mechanisms that control genome-wide patterns of animal transcription factor binding. In Methods in cell biology (Vol. 110, pp. 263-283). Academic Press.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-33">33</a>] </span> Karmodiya, K., Krebs, A. R., Oulad-Abdelghani, M., Kimura, H., &amp; Tora, L. (2012). H3K9 and H3K14 acetylation co-occur at many gene regulatory elements, while H3K14ac marks a subset of inactive inducible promoters in mouse embryonic stem cells. BMC genomics, 13(1), 424.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-34">34</a>] </span> Kelley, D. R., Snoek, J., &amp; Rinn, J. L. (2016). Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks. Genome research, 26(7), 990-999.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-35">35</a>] </span> Khan, A., Fornes, O., Stigliani, A., Gheorghe, M., Castro-Mondragon, J. A., van der Lee, R., ... &amp; Baranasic, D. (2017). JASPAR 2018: update of the open-access database of transcription factor binding profiles and its web framework. Nucleic acids research, 46(D1), D260-D266.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-36">36</a>] </span> Kleftogiannis, D., Kalnis, P., Arner, E., &amp; Bajic, V. B. (2016). Discriminative identification of transcriptional responses of promoters and enhancers after stimulus. Nucleic acids research, 45(4), e25-e25.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-37">37</a>] </span> Kreimer, A., Zeng, H., Edwards, M. D., Guo, Y., Tian, K., Shin, S., ... &amp; Li, Y. (2017). Predicting gene expression in massively parallel reporter assays: a comparative study. Human mutation, 38(9), 1240-1250.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-38">38</a>] </span> Kulakovskiy, I. V., Belostotsky, A. A., Kasianov, A. S., Esipova, N. G., Medvedeva, Y. A., Eliseeva, I. A., &amp; Makeev, V. J. (2011). A deeper look into transcription regulatory code by preferred pair distance templates for transcription factor binding sites. Bioinformatics, 27(19), 2621-2624.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-39">39</a>] </span> Kundaje, A., Meuleman, W., Ernst, J., Bilenky, M., Yen, A., Heravi-Moussavi, A., ... &amp; Amin, V. (2015). Integrative analysis of 111 reference human epigenomes. Nature, 518(7539), 317.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-40">40</a>] </span> Lee, L. M., &amp; Lee, J. C. (2006, June). A study on higher-order hidden Markov models and applications to speech recognition. In International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems (pp. 682-690). Springer, Berlin, Heidelberg.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-41">41</a>] </span> Lettice, L. A., Heaney, S. J., Purdie, L. A., Li, L., de Beer, P., Oostra, B. A., ... &amp; de Graaff, E. (2003). A long-range Shh enhancer regulates expression in the developing limb and fin and is associated with preaxial polydactyly. Human molecular genetics, 12(14), 1725-1735.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-42">42</a>] </span> Lindblad-Toh, K., Garber, M., Zuk, O., Lin, M. F., Parker, B. J., Washietl, S., ... &amp; Ward, L. D. (2011). A high-resolution map of human evolutionary constraint using 29 mammals. Nature, 478(7370), 476.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-43">43</a>] </span> Mari, J. F., Haton, J. P., &amp; Kriouile, A. (1997). Automatic word recognition based on second-order hidden Markov models. IEEE Transactions on speech and Audio Processing, 5(1), 22-25.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-44">44</a>] </span> Markov, A. A. (1906). Extension of the law of large numbers to dependent quantities. Izv. Fiz.-Matem. Obsch. Kazan Univ.(2nd Ser), 15, 135-156.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-45">45</a>] </span> Miguel-Escalada, I., Pasquali, L., &amp; Ferrer, J. (2015). Transcriptional enhancers: functional insights and role in human disease. Current opinion in genetics &amp; development, 33, 71-76.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-46">46</a>] </span> Ng, S. B., Turner, E. H., Robertson, P. D., Flygare, S. D., Bigham, A. W., Lee, C., ... &amp; Bamshad, M. (2009). Targeted capture and massively parallel sequencing of 12 human exomes. Nature, 461(7261), 272.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-47">47</a>] </span> Pennacchio, L. A., Ahituv, N., Moses, A. M., Prabhakar, S., Nobrega, M. A., Shoukry, M., ... &amp; Plajzer-Frick, I. (2006). In vivo enhancer analysis of human conserved non-coding sequences. Nature, 444(7118), 499-502.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-48">48</a>] </span> Pennacchio, L. A., Bickmore, W., Dean, A., Nobrega, M. A., &amp; Bejerano, G. (2013). Enhancers: five essential questions. Nature Reviews Genetics, 14(4), 288.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-49">49</a>] </span> Przybilla, J., Galle, J., &amp; Rohlf, T. (2012). Is adult stem cell aging driven by conflicting modes of chromatin remodeling?. Bioessays, 34(10), 841-848.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-50">50</a>] </span> Quinlan, A. R., &amp; Hall, I. M. (2010). BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26(6), 841-842.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-51">51</a>] </span> Rabiner, L., &amp; Juang, B. H. (1993). Fundamentals of speech processing. Prantice Hall.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-52">52</a>] </span> Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-53">53</a>] </span> Rada-Iglesias, A., Bajpai, R., Swigut, T., Brugmann, S. A., Flynn, R. A., &amp; Wysocka, J. (2011). A unique chromatin signature uncovers early developmental enhancers in humans. Nature, 470(7333), 279.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-54">54</a>] </span> Rosin, J. M., Abassah-Oppong, S., &amp; Cobb, J. (2013). Comparative transgenic analysis of enhancers from the human SHOX and mouse Shox2 genomic regions. Human molecular genetics, 22(15), 3063-3076.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-55">55</a>] </span> Smemo, S., Campos, L. C., Moskowitz, I. P., Krieger, J. E., Pereira, A. C., &amp; Nobrega, M. A. (2012). Regulatory variation in a TBX5 enhancer leads to isolated congenital heart disease. Human molecular genetics, 21(14), 3255-3263.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-56">56</a>] </span> Soldner, F., Stelzer, Y., Shivalila, C. S., Abraham, B. J., Latourelle, J. C., Barrasa, M. I., ... &amp; Jaenisch, R. (2016). Parkinson-associated risk variant in distal enhancer of <span class="formula"><i>α</i></span>-synuclein modulates target gene expression. Nature, 533(7601), 95.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-57">57</a>] </span> Stadler, M. B., Murr, R., Burger, L., Ivanek, R., Lienert, F., Schöler, A., ... &amp; Tiwari, V. K. (2011). DNA-binding factors shape the mouse methylome at distal regulatory regions. Nature, 480(7378), 490. </span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-58">58</a>] </span> Stormo, G. D., Schneider, T. D., Gold, L., &amp; Ehrenfeucht, A. (1982). Use of the ‘Perceptron’algorithm to distinguish translational initiation sites in E. coli. Nucleic acids research, 10(9), 2997-3011.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-59">59</a>] </span> Staden, R. (1984). Computer methods to locate signals in nucleic acid sequences.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-60">60</a>] </span> Taher, L., McGaughey, D. M., Maragh, S., Aneas, I., Bessling, S. L., Miller, W., ... &amp; Ovcharenko, I. (2011). Genome-wide identification of conserved regulatory function in diverged sequences. Genome research, 21(7), 1139-1149.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-61">61</a>] </span> Tate, P. H., &amp; Bird, A. P. (1993). Effects of DNA methylation on DNA-binding proteins and gene expression. Current opinion in genetics &amp; development, 3(2), 226-231.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-62">62</a>] </span> Thurman, R. E., Rynes, E., Humbert, R., Vierstra, J., Maurano, M. T., Haugen, E., ... &amp; Garg, K. (2012). The accessible chromatin landscape of the human genome. Nature, 489(7414), 75.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-63">63</a>] </span> Turin, W., &amp; Sondhi, M. M. (1993). Modeling error sources in digital channels. IEEE Journal on Selected Areas in Communications, 11(3), 340-347.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-64">64</a>] </span> Visel, A., Minovitsky, S., Dubchak, I., &amp; Pennacchio, L. A. (2007). VISTA Enhancer Browser—a database of tissue-specific human enhancers. Nucleic Acids Research, 35(Database issue), D88.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-65">65</a>] </span> Visel, A., Blow, M. J., Li, Z., Zhang, T., Akiyama, J. A., Holt, A., ... &amp; Afzal, V. (2009). ChIP-seq accurately predicts tissue-specific activity of enhancers. Nature, 457(7231), 854.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-66">66</a>] </span> Viterbi, A. (1967). Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE transactions on Information Theory, 13(2), 260-269.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-67">67</a>] </span> Williamson, I., Hill, R. E., &amp; Bickmore, W. A. (2011). Enhancers: from developmental genetics to the genetics of common human disease. Developmental cell, 21(1), 17-19.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-68">68</a>] </span> Winter, R. B., Berg, O. G., &amp; Von Hippel, P. H. (1981). Diffusion-driven mechanisms of protein translocation on nucleic acids. 3. The Escherichia coli lac repressor-operator interaction: kinetic measurements and conclusions. Biochemistry, 20(24), 6961-6977.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-69">69</a>] </span>Yang, F., Balakrishnan, S., &amp; Wainwright, M. J. (2015, December). Statistical and computational guarantees for the Baum-Welch algorithm. In 2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton) (pp. 658-665). IEEE.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-70">70</a>] </span> Zentner, G. E., Tesar, P. J., &amp; Scacheri, P. C. (2011). Epigenetic signatures distinguish multiple classes of enhancers with distinct cellular functions. Genome research, 21(8), 1273-1283.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-71">71</a>] </span> Zhang, Y., Liu, T., Meyer, C. A., Eeckhoute, J., Johnson, D. S., Bernstein, B. E., ... &amp; Liu, X. S. (2008). Model-based analysis of ChIP-Seq (MACS). Genome biology, 9(9), R137.</span>
</p>
<p class="biblio">
<span lang="en"><span class="entry">[<a class="biblioentry" name="biblio-72">72</a>] </span> Zhou, J., &amp; Troyanskaya, O. G. (2015). Predicting effects of noncoding variants with deep learning–based sequence model. Nature methods, 12(10), 931.</span>
</p>

</div>
</body>
</html>
