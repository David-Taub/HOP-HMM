<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="http://www.nongnu.org/elyxer/">
<meta name="create-date" content="2020-04-16">
<link rel="stylesheet" href="http://elyxer.nongnu.org/lyx.css" type="text/css" media="all">
<title>Converted document</title>
</head>
<body>
<div id="globalWrapper">
<div class="Standard">
<div class="center">
<span class="larger"> </span><span class="huge"><br>
</span><span class="larger"> </span><span class="huge"><br>
Classification of Regulatory Sequences <br>
in the Human Genome Using Higher-Order <br>
PWM Based Hidden Markov Model <br>
</span><span class="larger"> </span><span class="huge"><br>
</span><span class="larger"> </span><span class="huge"><br>
</span>
</div>

</div>
<div class="Standard">
<div class="center">
by<br>
<span class="larger">David Taub</span>
</div>

</div>
<div class="Standard">
<div class="center">
<span class="larger"> </span>
</div>

</div>
<div class="Standard">
<div class="center">
Supervised by<br>
<span class="larger">Prof. Tommy Kaplan<br>
  </span><span class="huge"><br>
</span><span class="larger"> </span><span class="huge"><br>
</span>
</div>

</div>
<div class="Standard">
<div class="center">
A thesis submitted in partial fulfillment of the requirements for the<br>
degree of Master of Science in Computer Science
</div>

</div>
<div class="Standard">
<div class="center">
<span class="large">April 2020<br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span><span class="larger"> </span><span class="large"><br>
</span>
</div>

</div>
<div class="Standard">
<div class="center">
<span class="larger">The Faculty of Computer Science and Engineering<br>
The Hebrew University of Jerusalem, Israel</span>
</div>

</div>
<div class="Standard">
<p><br>
</p>

</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--1"></a>Abstract
</h1>
<div class="Standard">
Enhancers are regulatory DNA sequences that, when bound to proteins called transcription factors, increase the likelihood of transcription of the enhancer target genes. Regulation of transcription is an important form of control of gene expression, and the activity of enhancers plays a significant role in the stage-specific and tissue-specific regulation of genes. It has been shown over the years that genetic variations within enhancer sequences might cause cell behavior modifications and diseases. The rules and nuances of enhancer structure is not fully understood yet, though it has been shown that transcription factors tend to attach to them at unique motifs called transcription factor binding sites, which are over-represented in enhancer sequences. Enhancer activity can be detected by the epigenetic data from the local environment around its position. The main indicators for an enhancer lay in the adjacent histone modifications, around which the flanks of the enhancer are wrapped. The enhancer itself tends to be spatial accessible for biochemical interactions between the DNA and the proteins around it. Though useful, the epigenetic data are often noisy and require a costly extraction process of specific cells out of a tissue sample, which is not necessarily practical for all cell types and their different stages. An alternative approach to enhancer detection is to observe the genetic content of its sequence, since it contains all the essential information for the DNA to act as an enhancer. Over the years, it was demonstrated <i>in vivo</i> that the cell requires no other mechanism than the sequence in order to regulate its gene expression. With that idea in mind, we offer a computational approach for the detection of enhancers based on their sequences alone, and in an unsupervised manner. We created a higher-order positional weight matrix based hidden Markov model (HOP-HMM), with two kinds of states: one which emits transcription factor binding sites by using a positional weight matrix model, and one which emits single nucleotides with higher-order dependency on previously emitted nucleotides. Compared to a regular hidden Markov model, this model learns a more complex underlying structure of DNA sequences, containing both binding site motifs and higher-order distribution of nucleotides in between them. We’ll first review the biological background of enhancers, specifically in humans. Then we’ll review in depth the background of Markov and hidden Markov models, and discuss how to calculate the likelihood of a sequence given this model. We’ll describe our generalized model in detail and develop the expectation maximization and Viterbi algorithms for hidden Markov models, followed by the adjustments needed for our generalized model. These algorithms implementations are demonstrated by applying them to a synthetic dataset of enhancer-like sequences created by using the generative property of the generalized model. We simulate the model in a controlled way to evaluate its performance by inferring estimated parameters of the model and comparing them to the real parameters used to create the dataset. Finally, we apply the expectation maximization algorithm for training a HOP-HMM from human DNA enhancer sequences, selected by the epigenetic data of the Roadmap project. We demonstrate the capabilities of the model by comparing its estimation to the epigenetic tracks, showing it can predict the loci of enhancers and in which tissues they will be active, without exposure to epigenetic data. 
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--2"></a>Introduction
</h1>
<div class="Standard">
The genome of every living organism contains the inherited information which defines its complex structure and function. The genome is built out of deoxyribonucleic acid (DNA) molecules, a structure of two chains of nucleotides units forming a double helix shape. Nucleotides are built out of 4 different basic elements: cytosine, guanine, adenine or thymine or in short A,C,G and T. The nucleotides are organized in pairs called base pairs, with each of the paired nucleotides being complementary to the other and providing redundancy. 
</div>
<div class="Standard">
Proteins are macromolecules, which ensure various roles and functions within organisms. They have the structure of a polymer built out of 20 different amino acids, whose order and structure are encoded in genes (genetic segments within the genome). Through transcription followed by translation processes, the genes are expressed and result in the formation of proteins. In the transcription process the gene is read and transcribed into a single strand sequence of RNA. Later, the formed RNA molecule, which at this stage is called messenger RNA (mRNA), is translated by a complex molecule called the ribosome. The mRNA sequence is built out of triplets of nucleotides called codons, which are read by the ribosome and instruct it how to generate a sequence of amino acids constituting the protein. 
</div>
<div class="Standard">
Gene sequences are built out of fragmented introns and exons, where only the exons mature into mRNA molecules which are translated into proteins, while the introns are spliced away beforehand. Counter intuitively, even though the exons hold the recipe for the construction of the proteins of the organism, its complexity is not a product of their number or their length. For example, both humans and Caenorhabditis elegans roundworms have about 19,000 genes with roughly the same total exon length and number (<span class="bibcites">[<a class="bibliocite" name="cite-2" href="#biblio-2">2</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-19" href="#biblio-19">19</a>]</span>), even though the human body is much more diverse and complex. Although the genes are responsible for the variety of proteins a cell can produce, the source of organism complexity, with different cells performing different tasks while carrying the same genome, stems from the gene regulation mechanism. In the case of humans, the genome is 3.23 Gb long and it is estimated that the total length of gene regulation regions involves 10-20% of it (<span class="bibcites">[<a class="bibliocite" name="cite-47" href="#biblio-47">47</a>]</span>), compared to exon regions which involve only 1% (<span class="bibcites">[<a class="bibliocite" name="cite-45" href="#biblio-45">45</a>]</span>).
</div>
<div class="Standard">
Enhancers are non-coding regulatory DNA sequences which play a key role in the regulation transcription of genes. In humans, there are hundreds of thousands of enhancers scattered over the non-coding regions of the genome, usually of a length between 100-1000 base pairs (bp). When activated, the DNA folding draws the enhancer spatially closer to another type of regulatory element called promoter, resulting in the translation of the gene adjacent to the promoter (see figure <a class="Reference" href="#Transcription">1↓</a>). The gene expressed by this activation process is the enhancer’s target gene, and it can be located up to one megabase pair (Mb) upstream or downstream from its activating enhancer as enhancers generally function independently of orientation (<span class="bibcites">[<a class="bibliocite" name="cite-66" href="#biblio-66">66</a>]</span>). Moreover, the gene-enhancer connection is not exclusive, and it has been shown that the most common case is that each enhancer has several target genes and vice-versa (<span class="bibcites">[<a class="bibliocite" name="cite-21" href="#biblio-21">21</a>]</span>).
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Transcription"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/Enhancer_gene_transcription.jpg" alt="figure Figures/Enhancer_gene_transcription.jpg">
<div class="caption">
Figure 1 <b>A)</b> An enhancer and its distal target gene. <b>B)</b> The DNA folds and the attaches to transcription factors, which then draw other co-factor proteins that together form the transcription complex. <b>C)</b> The RNA Polymerase II is recruited and while moving along the gene, it generates a new RNA molecule which is transcribed off the gene. 
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
An enhancer is described as being in an active status when it is causing the expression of its target gene, which does not occur evenly across different types of cells. The activity of the enhancer sequence plays a critical role in the resulting type of cells. In the VISTA Project (<span class="bibcites">[<a class="bibliocite" name="cite-63" href="#biblio-63">63</a>]</span>), fertilized mouse eggs were injected with enhancer sequences adjacent to a LacZ reporter gene, encoding an enzyme protein with a blue color. Since they were synthesized, the injected DNA sequences containing the enhancer and reporter genes bore no epigenetic information, and they were integrated into the mouse genome in an arbitral position. The enhancers in the injected DNA sequences originated from the human genome, and each enhancer was injected into a different embryo. When the transgenic embryos were photographed after 11.5 days some had a distinctive anatomical pattern, such as blue limbs or blue spine, depending on the injected DNA sequence. These results imply that for many DNA sequences, the DNA code possesses by itself the potential to become a specific tissue enhancer, despite the absence of epigenetic information. <div class="float">
<a class="Label" name="Mouse"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/f735.jpg" alt="figure Figures/f735.jpg">
<img class="embedded" src="Figures/experiment_process.png" alt="figure Figures/experiment_process.png">
<div class="caption">
Figure 2 Transgenic mouse embryo on the 11.5 day. A fertilized egg was injected with a synthetic enhancer sequence known to be related to the dorsal root ganglia of spinal neurons. The enhancer became activated and caused the expression of the blue color marker gene that was coupled to it. Both images are taken from Vista Enhancer Browser, on the left is experiment hs-51 embryo 2.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
Transcription factors (TF) are proteins that bind to the DNA, and together with other cofactor proteins initiate the gene transcription process of the DNA sequence. TFs tend to bind to their transcription factor binding sites (TFBS), which are motifs of nucleotides in the DNA sequence. The average length of TFBS in humans is 12 bp (<span class="bibcites">[<a class="bibliocite" name="cite-37" href="#biblio-37">37</a>]</span>), and they are highly conserved between various species (<span class="bibcites">[<a class="bibliocite" name="cite-14" href="#biblio-14">14</a>]</span>). When analyzing a tissue sample for TF interaction density, a chromatin immunoprecipitation sequencing (ChIP-seq) method is used to probe the amount of TFs in affinity to the DNA strands. Briefly, this method involved applying antibodies on cross-linked DNA, which attach to the TFs linked to the DNA. This antibody attachment is followed by massive parallel sequencing of the short DNA sequences around the TF and the antibody. Genome-wide association studies (GWAS) of ChIP-seq found that different TFs have different and distinct distributions of TFBS (<span class="bibcites">[<a class="bibliocite" name="cite-34" href="#biblio-34">34</a>]</span>).
</div>
<div class="Standard">
The TFBSs in both enhancers and promoters are critical for their correct regulatory activity. Multiple studies have shown that genetic alterations in enhancer’s TFBSs can affect the expression of their target genes and are a major cause of various human diseases (<span class="bibcites">[<a class="bibliocite" name="cite-36" href="#biblio-36">36</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-44" href="#biblio-44">44</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-55" href="#biblio-55">55</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-54" href="#biblio-54">54</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-5" href="#biblio-5">5</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-16" href="#biblio-16">16</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-40" href="#biblio-40">40</a>]</span>). From the sequence aspect, enhancers and promoters have a similar structure: both have different nucleotide frequencies compared to other parts of the genome, and both contain TFBSs tiled inside background sequences.
</div>
<div class="Standard">
Folding of the DNA allows enhancer-promoter interactions, in which the TFs play a major part. Once bounded to the DNA, the TFs recruit other protein cofactors, and together they form a transcription preinitiation complex (PIC), consisting of a very large assembly of proteins. Out of the tens of proteins constructing the PIC, the sub-unit RNA polymerase (RNA pol II) has the important role of transcribing the adjacent gene. It slides along the double-stranded DNA and opens it until one strand of nucleotides is exposed and becomes a template for RNA synthesis.
</div>
<div class="Standard">
Though it is tempting to imagine each TF as having a corresponding TFBS with a single motif of nucleotides that fits it, modeling the kinetic and thermodynamic aspects involved in the DNA-protein interaction is far from simple (<span class="bibcites">[<a class="bibliocite" name="cite-67" href="#biblio-67">67</a>]</span>), and each sequence of nucleotides has the likelihood to form a bond, which is not simple to calculate analytically. In order to generate a simplistic yet statistically accurate model representing the TF binding potential of a DNA sequence, i.e. <span class="formula"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>n</i></sub>|<i>binding</i><span class="symbol">)</span></span>, we need to assume an independence between positions as well as a small range of influence of the sequence around the binding site. For samples of such distribution, the peaks of the ChIP-seq readings marking the TF binding are often used, from which a binding site “grammar” can be modeled. Position weight matrix (PWM), as introduced in <span class="bibcites">[<a class="bibliocite" name="cite-57" href="#biblio-57">57</a>]</span>, is the most commonly used probabilistic model to address this task. The underlying assumption of the PWM model is that every position in the DNA sequence has an independent probability to attach to the TF, and therefore the total binding probability is a multiplication of all the per-position probabilities in the motif:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>J</i></sub>|<i>binding</i><span class="symbol">)</span> = <span class="limits"><span class="limit">∏</span></span><sub><i>j</i> ∈ [<i>n</i>]</sub><i>P</i><span class="symbol">(</span><i>x</i><sub><i>j</i></sub>|<i>binding</i><span class="symbol">)</span>
</div>
Where J is the length of the relevant sequences affected by the binding event, and is derived from the physical characteristics of the TF. Practically, this size is often estimated from the observed motifs in the TF’s ChIP-seq peaks. For each j, <span class="formula"><i>P</i><span class="symbol">(</span><i>x</i><sub><i>j</i></sub>|<i>binding</i><span class="symbol">)</span></span> is estimated by counting the frequency of the nucleotides in the j’th position of the observed binding sites which are situated in the ChIP-seq peaks. For a motif of length J, the estimation of this probability is stored in a position probability matrix (PPM) W as followed: 
</div>
<div class="Standard">
<div class="formula">
<i>W</i><sub><i>i</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator"><i>N</i></span><span class="ignored">)</span></span><span class="limits"><span class="limit">∑</span></span><sub><i>n</i> ∈ [<i>N</i>]</sub><b>1</b><span class="symbol">(</span><i>x</i><sub><i>j</i></sub><sup>(<i>n</i>)</sup> = <i>i</i><span class="symbol">)</span>
</div>
where <span class="formula"><i>x</i><sup>(<i>n</i>)</sup></span> is the n’th sequence of the found binding sites, <span class="formula"><i>j</i> ∈ [<i>J</i>]</span> the position in the motif and <span class="formula"><i>i</i> ∈ [4]</span> the nucleotide index of A,C,G and T. To enable comparison between the binding likelihood of TFBS of different lengths, the use of the normalized form of PPM, the PWM, is more convenient:<div class="formula">
<a class="eqnumber" name="PPM">(1) </a><span class="displaystyle"><i>M</i></span><sub><i>i</i>, <i>j</i></sub> = <span class="mathrm">log</span><span class="symbol">(</span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>W</i><sub><i>i</i>, <i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>b</i><sub><i>i</i></sub></span><span class="ignored">)</span></span><span class="symbol">)</span>
</div>
where <span class="formula"><i>b</i><sub><i>i</i></sub></span> is the prior background model, which is 0.25 in case of nucleotides. From a generative model point of view, the TFBS sequence is generated by an emission model of the PWM. When a convolution of M is applied on the one-hot encoding of the sequence (see figure <a class="Reference" href="#PWM">3↓</a>), the result is the log likelihood of a TF binding to a sequence relative to a random sequence. In this work we’ll use the more familiar term PWMs though we actually used the unnormalized PPMs for the TFBS emission model, since we required the likelihood of a TF binding and not a length-independent comparison between TFs. 
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="PWM"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/pwm_mult.jpg" alt="figure Figures/pwm_mult.jpg">
<div class="caption">
Figure 3 Sub-sequences out of the DNA are represented in a one-hot encoding, and multiplied entry-wise by a PWM. Then, the sum of the logs of the maximal values in each column of the resulting matrix is calculated, which represents the log likelihood of the TF binding to the sub-sequence. This log likelihood is calculated for each location in the sequence, in which locations with high values indicate a high likelihood of TF binding.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
Detection of enhancers and of the tissues in which they are active has been the subject of much research in the last few decades. Specifically, an enhancer detection method relying only on their sequences and without need for biological experimentation is an especially sought-after goal. Such biological experiments, some of which are mentioned in this work, involve cells whose enhancers activate their target genes during the experiment, which is usually an expensive and non-trivial requirement. All methods for detecting active enhancers “in the act” are inherently limited to the specific tissues we can extract and isolate in a lab. Furthermore, many enhancers are only active in specific cell types and at specific stages, and achieving a study of every cell type at every possible stage in complex organisms is not a practical requirement for the foreseeable future. On the other hand, the genome of organisms can be easily and inexpensively sequenced for later analysis in-silico. The ultimate goal of an efficient computational method which would predict and explain the functional nature of an enhancer sequence has produced positive, yet far from sufficient results over the last years, as reviewed in (<span class="bibcites">[<a class="bibliocite" name="cite-35" href="#biblio-35">35</a>]</span>).
</div>
<div class="Standard">
As an alternative, a potential way of detecting enhancers only by addressing their sequences, would consist in finding non-coding regions which are conserved across species. Conserved non-coding elements (CNE) have a tendency to reside in clusters, which usually have low gene density but are located in vicinity to genes (<span class="bibcites">[<a class="bibliocite" name="cite-46" href="#biblio-46">46</a>]</span>). Evidently, the overlap between CNEs and enhancers is imprecise. Some verified enhancers are weakly (or not) conserved between species (<span class="bibcites">[<a class="bibliocite" name="cite-22" href="#biblio-22">22</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-53" href="#biblio-53">53</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-59" href="#biblio-59">59</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-41" href="#biblio-41">41</a>]</span>) and some highly conserved areas in the mouse genome are not associated to regulatory activity, but their deletion still yields viable mice (<span class="bibcites">[<a class="bibliocite" name="cite-1" href="#biblio-1">1</a>]</span>). Nevertheless, an assay of elements with 100% sequence identity of over 200 bp between human and mouse found that 50% showed enhancer activity in mice (<span class="bibcites">[<a class="bibliocite" name="cite-63" href="#biblio-63">63</a>]</span>). The ultra-conservation of 200 bp enhancer sequences containing TFBSs that are usually shorter than 15 bp raises the possibility that these conserved iter-TFBS parts play a role which it is not yet fully clear.
</div>
<div class="Standard">
Almost all cells in every organism contain their entire genomic payload, but only part of this genome is active in any specific cell. Essentially, cells of different type and state differ by gene expression patterns. The reason for this difference between cells lays in regulation components not included in the Watson and Crick model of the DNA sequence. The location and presence of TFBS, background nucleotides distribution and other sequence-related properties are not sufficient to explain the regulatory role of certain regions in the genome. 
</div>
<div class="Standard">
Several epigenetic features, which do not involve the nucleotide sequences themselves, correlate with enhancer regions in the genome: 
</div>
<ul>
<li>
Accessibility
</li>
<li>
TF &amp; cofactors binding
</li>
<li>
Histone modifications
</li>
<li>
DNA methylation
</li>

</ul>
<div class="Standard">
These mechanisms have measurable features that can be added as a data layer, on top of the genome. Their combination is the main source of identification and prediction for enhancer regions in the genome. A single cell has its own epigenetic features, often in binary form, e.g. a specific element of the genome can be either accessible or not. When several cells epigenetic properties are measured, usually a frequency or count of the measured feature per DNA locus is calculated along the reference genome. The epigenetic data is commonly further processed by calculating its p-value compared to a local environment, to which peak boundaries are determined (peak calling) using algorithms such as MACS2 (<span class="bibcites">[<a class="bibliocite" name="cite-70" href="#biblio-70">70</a>]</span>).
</div>
<div class="Standard">
In eukaryotes, the DNA is packed around a structure of 8 histone proteins called a nucleosome, and they form together a chromatin complex. Similarly to the TFs, the nucleosome binding location in the DNA sequence is not arbitrary. Like them, it has a tendency for specific DNA binding sites (<span class="bibcites">[<a class="bibliocite" name="cite-11" href="#biblio-11">11</a>]</span>). The DNA wrapped around a nucleosome has a lesser likelihood for interaction with proteins, because it is physically inaccessible. Accessibility enables the TFs and other proteins to bind to the DNA molecule, hence the enhancer, the promoter and the gene all need to be accessible for a successful transcription to occur. DNase-I hypersensitive (DHS) sites are regions of the DNA which are sensitive to cleavage by the DNase-I enzyme. In these regions the DNA loses the nucleosome, and becomes accessible and therefore potentially active. Measurement of DHS cleavages is available through DNase-seq (<span class="bibcites">[<a class="bibliocite" name="cite-6" href="#biblio-6">6</a>]</span>), a high-throughput method for measuring the accessibility epigenetic data of the DNA, usually with a better resolution than histone modifications measurements. A faster and more sensitive technique for accessibility measurement is called ATAC-seq (<span class="bibcites">[<a class="bibliocite" name="cite-8" href="#biblio-8">8</a>]</span>), and is currently more commonly used. 
</div>
<div class="Standard">
Histone modifications, also called histone marks and chromatin modifications, are chemical alterations which happen to the long tail-like section of the histone protein. Histones are numbered from 1 to 8, and for example, the acetylation of the lysine amino-acid situated in 14th position in the protein of the 3rd histone will be abbreviated as H3K14ac. Along many roles in the cell, such as DNA repair and mitosis, histone modifications have a function in the gene regulation processes. In the past 20 years, a substantial body of research has shown that histone modifications are predictive of enhancer position and activity status (<span class="bibcites">[<a class="bibliocite" name="cite-63" href="#biblio-63">63</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-27" href="#biblio-27">27</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-23" href="#biblio-23">23</a>]</span>). The histone modifications are considered to form a certain “histone code” along the genome, which encodes complex information underlying the genomic code and is connected to transcription regulation and other aspects. Compared to other epigenetic information, chromatin modifications have a shorter time scale ranging from seconds to hours (<span class="bibcites">[<a class="bibliocite" name="cite-25" href="#biblio-25">25</a>]</span>), and are therefore considered related to the dynamic changes of the cell.
</div>
<div class="Standard">
Measurement of histone modifications is also performed using the ChIP-seq method, similarly to the TF binding detection described above. In histone ChIP-seq, antibodies attach to the modifications in the histone tails (and not to the TF proteins). H3K4me1 and H3K27ac are among the predominant histone modifications of active enhancers; H3K4me1 is enriched on transcribed genes and enhancers prior to activation (<span class="bibcites">[<a class="bibliocite" name="cite-57" href="#biblio-57">57</a>]</span>), and is thought to precede the H3K27ac modification (<span class="bibcites">[<a class="bibliocite" name="cite-58" href="#biblio-58">58</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-52" href="#biblio-52">52</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-69" href="#biblio-69">69</a>]</span>) which is known to occur during activation. Other histone modifications present on active enhancers and used for their detection are H3K9ac (<span class="bibcites">[<a class="bibliocite" name="cite-18" href="#biblio-18">18</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-32" href="#biblio-32">32</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-69" href="#biblio-69">69</a>]</span>) and H3K18ac (<span class="bibcites">[<a class="bibliocite" name="cite-29" href="#biblio-29">29</a>]</span>). Even though H3K27ac has been identified as an important mark for the differentiation of active enhancers from poised enhancers (<span class="bibcites">[<a class="bibliocite" name="cite-58" href="#biblio-58">58</a>]</span>), it is not sufficient by itself since when present alongside H3K4me3 it is also an indication for active promoters (<span class="bibcites">[<a class="bibliocite" name="cite-26" href="#biblio-26">26</a>]</span>). In contrast, absence of H3K27ac and enrichment of H3K4me1and H3K27me3 are typical of poised enhancers (<span class="bibcites">[<a class="bibliocite" name="cite-58" href="#biblio-58">58</a>]</span>).<br>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Enhancer"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/Enhancers_status.jpg" alt="figure Figures/Enhancers_status.jpg">
<div class="caption">
Figure 4 The accessibility of an enhancer’s sequence and its surrounding histone modifications are connected to its regulatory activity state. The upper diagram shows an active enhancer sequence accessible to the protein interaction needed for transcription, whereas the lower one shows an inactive enhancer wrapped around a nucleosome and therefore inaccessible.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
DNA methylation of cytosine nucleotides and cytosine guanine nucleotides pairs (CpG) has been involved in long-term genome silencing in multiple processes (<span class="bibcites">[<a class="bibliocite" name="cite-30" href="#biblio-30">30</a>]</span>) and cell aging (<span class="bibcites">[<a class="bibliocite" name="cite-48" href="#biblio-48">48</a>]</span>). It has been documented as widely correlated with inhibition of gene expression when present in promoters (<span class="bibcites">[<a class="bibliocite" name="cite-60" href="#biblio-60">60</a>]</span>). In enhancer elements, an anti-correlation was found between DNA methylation density and enrichment of active enhancer histone modifications, and TF binding (<span class="bibcites">[<a class="bibliocite" name="cite-56" href="#biblio-56">56</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-61" href="#biblio-61">61</a>]</span>), although the cause and consequence relationships underlying these correlations is not yet clear. Currently, the most accurate method for the wide-scale prediction of the loci of enhancer sequences in a genome is the analysis of histone modifications, and TF and cofactors presence using ChIP-seq from a cell line or from a tissue, combined with DNase-I hypersensitivity (DHS). 
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="GenomeBrowser"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/genome_browser.png" alt="figure Figures/genome_browser.png">
<div class="caption">
Figure 5 UCSC Genome Browser showing epigenetic features tracks, taken from the 10th chromosome of a H1-hESC cell line. Highlighted in light blue, the peaks of H3K27ac (1st green plot) and H3K4me1 (2nd green plot) histone modifications and the DNase-I hypersensitivity features (4th green plot), together with the absence of H3K27me3 (3rd green plot) signal indicate an active enhancer, as also marked by the ChromHMM classification (bottom). Note that the decrease between the two peaks of H3K27ac and H3K4me1 is located on top of the increase of the DNase-I hypersensitivity, which implies a cleavage in between two nucleosomes with modifications. Taken from <a class="FlexURL" href="https://genome-euro.ucsc.edu/cgi-bin/hgTracks">https://genome-euro.ucsc.edu/cgi-bin/hgTracks</a>
</div>

</div>

</div>

</div>

</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--1"></a>Related Work
</h3>
<div class="Standard">
Several significant computational efforts were made in the last few years for predicting the epigenetic and regulatory properties of DNA elements based on the genetic sequence alone. DeepSEA (<span class="bibcites">[<a class="bibliocite" name="cite-71" href="#biblio-71">71</a>]</span>) uses a deep convolutional neural network (DCNN) which receives an input of 1000 bp sequence, and outputs a prediction vector of 919 binary features representing the chromatin modifications of 200 bp in the center of the input sequence. The training labels used are the chromatin modifications extracted from ENCODE and Roadmap epigenetic data releases. Basset (<span class="bibcites">[<a class="bibliocite" name="cite-34" href="#biblio-34">34</a>]</span>) also used DCNN on the same data, with known PWMs as weight initialization, to predict a binary vector representing accessibility in 164 cell types, based on 600 bp DNA sequences. In DeepBind (<span class="bibcites">[<a class="bibliocite" name="cite-3" href="#biblio-3">3</a>]</span>) a DCNN was used to predict binding of 538 TFs and 194 RNA binding proteins from DNA sequences of varying lengths. In gkm-SVM (<span class="bibcites">[<a class="bibliocite" name="cite-12" href="#biblio-12">12</a>]</span>), gapped <i>k</i>-mers presence indicator vectors were used as features for a SVM classifier in order to predict the role of DNA sequences of varying lengths. ChromHMM (<span class="bibcites">[<a class="bibliocite" name="cite-17" href="#biblio-17">17</a>]</span>) is a widely used software that tackles the problem of analyzing the epigenetic data to predict the role of fragments of genomic sequence. The algorithm converts to binary the chromatin modification values by whether or not it exceeded a threshold, which is then inserted as input to HMM that classifies the genome states. A disadvantage of these methods is their need for training data of known regulatory elements or epigenetic data which are commonly obtained from GWAS surveys, such as those that were done on 127 obtained human cell types in the Roadmap and ENCODE projects (<span class="bibcites">[<a class="bibliocite" name="cite-38" href="#biblio-38">38</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-18" href="#biblio-18">18</a>]</span>). 
</div>
<div class="Standard">
When a DNA sequence is read from a tissue sample, it is often stored as a sequence of the characters A,C,G and T in FASTA format. For an algorithm to process it, these characters are mapped into a data structure of integers 1,2,3 and 4 respectively. For many algorithms, such as in DeepSEA, Basset, and our HOP-HMM, it is preferable to encode these sequences of integers as a sequence one-hot vectors (also called indicator vectors), as described in figure <a class="Reference" href="#PWM">3↑</a>. A commonly used feature extraction technique of DNA sequences is to represent them as vectors of their in-sequence k-mer frequencies as used in gkm-SVM. In this technique, the order of the k-mer is sacrificed for a more meaning-oriented, structured and fixed-length data encoding, similarly to the bag of words technique in text analysis and natural language processing. 
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--2"></a>Machine Learning Models
</h3>
<div class="Standard">
The goal of machine learning classification models is to arrive from the observed <span class="formula"><i>X</i></span> to its label <span class="formula"><i>Y</i></span>. In the DNA classification case discussed in this work, the goal is deciding its role label <span class="formula"><i>Y</i></span> for a given a DNA sequence X. There are two main approaches to this goal: generative models and discriminative models. Both approaches assume observed variables <span class="formula"><i>X</i></span> and target variables <span class="formula"><i>Y</i></span>, also commonly referred to as data samples and labels. 
</div>
<ul>
<li>
Generative models assume a joint probability <span class="formula"><i>P</i><span class="symbol">(</span><i>X</i>, <i>Y</i><span class="symbol">)</span></span>. Using dataset of <span class="formula"><span class="symbol">(</span><i>x</i>, <i>y</i><span class="symbol">)</span></span> pairs, one can estimate the distribution <span class="formula"><i>P</i><span class="symbol">(</span><i>X</i>, <i>Y</i><span class="symbol">)</span></span>, then estimate from it <span class="formula"><i>P</i><span class="symbol">(</span><i>Y</i>|<i>X</i><span class="symbol">)</span></span>. The distinctive feature of these models is their ability to generate random instances of the data, either as pairs of <span class="formula"><span class="symbol">(</span><i>x</i>, <i>y</i><span class="symbol">)</span></span> or as instances of <span class="formula"><i>x</i></span> given <span class="formula"><i>y</i></span>.
</li>
<li>
Discriminative models assume conditional probability <span class="formula"><i>P</i><span class="symbol">(</span><i>Y</i>|<i>X</i><span class="symbol">)</span></span>, which is estimated directly from the dataset.
</li>

</ul>
<div class="Standard">
Both models eventually base their classification upon the <span class="formula"><i>P</i><span class="symbol">(</span><i>Y</i>|<i>X</i><span class="symbol">)</span></span> estimation. Namely, classifying a data sample <span class="formula"><i>x</i></span> by the most likely label: 
</div>
<div class="Standard">
<div class="formula">
<i>y</i><sub><i>est</i></sub> = <i>argmax</i><sub><i>y</i></sub><i>P</i><span class="symbol">(</span><i>Y</i> = <i>y</i>|<i>X</i> = <i>x</i><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
Discriminative models are more widely used than generative models, they are often easier to use and build since they require fewer assumptions on the origin and generation of the data. For instance, the deep neural network (DNN) is a model that has gained much interest lately in the machine learning field, and was also used for the task of classifying the role of DNA sequences. As a discriminative model it assumes very little regarding the way the DNA sequence is generated based on its role, but finds instead features in the sequence that imply its role. Hence it is often difficult to use such a model for a later understanding of the nature of the data generation process, or to generate new data from it. 
</div>
<div class="Standard">
Markov model (<span class="bibcites">[<a class="bibliocite" name="cite-43" href="#biblio-43">43</a>]</span>), named after the Russian mathematician Andrey Markov, is a stochastic model which is applied to a system that changes randomly, such as the weather or car traffic. This model is at one of m states <span class="formula"><span class="symbol">{</span><i>S</i><sub>1</sub>, ..., <i>S</i><sub><i>m</i></sub><span class="symbol">}</span></span> at any time, with the first state being sampled from a distribution <span class="formula"><i>π</i><sub><i>i</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub>1</sub> = <i>S</i><sub><i>i</i></sub><span class="symbol">)</span></span> and the probability of transitions between the states being denoted by <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>S</i><sub><i>i</i></sub>|<i>y</i><sub><i>t</i> − 1</sub> = <i>S</i><sub><i>j</i></sub><span class="symbol">)</span></span>. The travel of the model over the states is named a Markov process, and the sequence of the states visited in the process is called a Markov chain. The likelihood of a Markov chain <span class="formula"><i>X</i></span> generated by a Markov Model <span class="formula"><i>θ</i> = {<i>π</i>, <i>T</i>}</span> is a joint probability of the first state and of all following transitions which, due to the independence between transition events, can be written as:
</div>
<div class="Standard">
<div class="formula">
ℒ(<i>θ</i>;<i>X</i>) = <i>P</i><sub><i>θ</i></sub>(<i>x</i><sub>0</sub>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>L</i></sub>) = <i>π</i><sub><i>x</i><sub>0</sub></sub>⋅<i>T</i><sub><i>x</i><sub>0</sub>, <i>x</i><sub>1</sub></sub>⋅<i>T</i><sub><i>x</i><sub>1</sub>, <i>x</i><sub>2</sub></sub>⋅...⋅<i>T</i><sub><i>x</i><sub><i>L</i> − 1</sub>, <i>x</i><sub><i>L</i></sub></sub>
</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Markov"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/Markov_model.jpg" alt="figure Figures/Markov_model.jpg">
<div class="caption">
Figure 6 <b>A)</b> Markov model with 3 states (a,b and c). <b>B,C)</b> The model starts with a state sampled from π, and travels between the states with a transition distribution T. <b>D)</b> The model can generate Markov chains of states, where the transition between the states is only conditioned by the previous state, causing the Markov process to be memoryless. 
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
The hidden Markov model (HMM) is a Markov model extension which models a system that travels over hidden states as a Markov process, and while doing so emits variables called observed variables. Like the Markov model, HMM is a generative model, and therefore assumes the existence of a joint probability <span class="formula"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> derived from the compact parameters <span class="formula"><i>θ</i></span>. HMM relies on the assumption that the observed DNA sequence <span class="formula"><i>X</i> = <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>L</i></sub></span> is generated by a parameterized model <span class="formula"><i>θ</i></span>, and has a hidden sequence <span class="formula"><i>Y</i> = <i>y</i><sub>1</sub>, ..., <i>y</i><sub><i>L</i></sub></span> that was generated alongside it. In this generation process, a single observed variable is emitted for every step of the model, and thus the observed sequence is generated with the same length as the hidden Markov chain. For an alphabet of variables <span class="formula"><span class="symbol">{</span><i>V</i><sub>1</sub>, ..., <i>V</i><sub><i>n</i></sub><span class="symbol">}</span>, </span> and hidden state space <span class="formula"><span class="symbol">{</span><i>S</i><sub>1</sub>, ..., <i>S</i><sub><i>m</i></sub><span class="symbol">}</span></span>, the observed variable <span class="formula"><i>x</i><sub><i>t</i></sub></span> is sampled from an emission distribution conditioned on the hidden state of the model <span class="formula"><i>E</i><sub><i>i</i>, <i>j</i></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub> = <i>V</i><sub><i>j</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>S</i><sub><i>i</i></sub><span class="symbol">)</span></span>. Similarly to the Markov model, the distribution to the first hidden state is marked as <span class="formula"><i>π</i></span> and the transition distribution is marked as <span class="formula"><i>T</i></span>.
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="HMM"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HMM_two_states.jpg" alt="figure Figures/HMM_two_states.jpg">
<div class="caption">
Figure 7 <b>A)</b> HMM with 2 hidden states. <b>B)</b> The observed variables (dark blue) are emitted by the hidden state at their location, sampled from the discrete conditional distribution E. <b>C,D)</b> The hidden states (yellow and green) behave as Markov model states with starting and transition probabilities <span class="formula"><i>π</i></span> and <span class="formula"><i>T</i></span>. <b>E)</b> The output of the model is an observable sequence with an underlying hidden sequence. The hidden sequence is a Markov chain, where on each step the hidden state emits a single observed variable.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
HMM is a very popular signal processing algorithm that has been adopted in the various fields of computational biology since the 1980’s. HMM was proposed by Leonard Baum (<span class="bibcites">[<a class="bibliocite" name="cite-4" href="#biblio-4">4</a>]</span>) and is used for modeling regions with alternating frequencies of patterns and symbols. In a non-biological context, it was used extensively in various engineering fields, especially in speech recognition (<span class="bibcites">[<a class="bibliocite" name="cite-50" href="#biblio-50">50</a>]</span>), handwriting recognition (<span class="bibcites">[<a class="bibliocite" name="cite-28" href="#biblio-28">28</a>]</span>) and digital communication (<span class="bibcites">[<a class="bibliocite" name="cite-62" href="#biblio-62">62</a>]</span>).
</div>
<div class="Standard">
For example, in the case where the observable sequence is made out of DNA, a simplistic model can assume that the DNA sequence is composed out of 4 states: genes, promoter enhancers and background regions. Each of these states will have a different nucleotide frequency, and we assume that the DNA sequence was generated by a HMM with underlying sequences of 4 hidden states, one for each region type. The emitted DNA sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> is determined by the underlying hidden sequence y1:L that describes the “mode” of the sequence for each location.<br>

</div>
<div class="Standard">
Having a HMM with <span class="formula"><i>θ</i></span> on hand and given an observed sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>, two questions arise: :
</div>
<ul>
<li>
What is the likelihood that <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> was generated by the HMM with parameters <span class="formula"><i>θ</i></span> or <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>?
</li>
<li>
What is the probability of a hidden state at every location or <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>?
</li>

</ul>
<div class="Standard">
The two above-mentioned probabilities are named the likelihood function and the posterior probabilities of HMM. As in many generative models, HMM’s likelihood function <span class="formula">ℒ<span class="symbol">(</span><i>θ</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> relating to the first question can be split by the total probability law to the sum of all possible hidden sequences: 
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="Likelihoods">(2) </a>ℒ<span class="symbol">(</span><i>θ</i>;<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
The probability <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> is called the incomplete-data likelihood function and the probability <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> is called the complete-data likelihood function. In the case of HMM with parameters <span class="formula"><i>θ</i></span>, the complete-data can be calculated by:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="Complete-Likelihood">(3) </a><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub>1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1</sub>|<i>y</i><sub>1</sub><span class="symbol">)</span>⋅<span class="limits"><span class="limit">∏</span></span><sub><i>i</i> = 2</sub><sup><i>N</i></sup><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>i</i></sub>|<i>y</i><sub><i>i</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>i</i></sub>|<i>y</i><sub><i>i</i></sub><span class="symbol">)</span> = <i>π</i><sub><i>y</i><sub>1</sub></sub><i>E</i><sub><i>y</i><sub>1</sub>, <i>x</i><sub>1</sub></sub><span class="limits"><span class="limit">∏</span></span><sub><i>i</i> = 2</sub><sup><i>L</i></sup><i>T</i><sub><i>y</i><sub><i>i</i> − 1</sub>, <i>y</i><sub><i>i</i></sub></sub><i>E</i><sub><i>y</i><sub><i>i</i></sub>, <i>x</i><sub><i>i</i></sub></sub>
</div>

</div>
<div class="Standard">
Although the computation of the complete-data likelihood of <span class="formula"><i>θ</i></span> in <a class="Reference" href="#Complete-Likelihood">(3↑)</a> is linear-by-L, naively computing the incomplete-data likelihood as in <a class="Reference" href="#Likelihoods">(2↑)</a> involves the summation of all possible hidden sequences, an impracticable exponential-by-L operation. A dynamic approach to overcome this gap uses the Markovian memorylessness of HMM, and answers both the likelihood and the posterior questions we raised above. This approach is called Forward-Backward algorithm: it was suggested as a step in the Baum-Welch algorithm (<span class="bibcites">[<a class="bibliocite" name="cite-4" href="#biblio-4">4</a>]</span>), which is an expectation maximization (EM) algorithm for finding the unknown θ given an observed sequence, and will be described further in a later section. In the Forward-Backward algorithm, two matrices of size <span class="formula"><i>m</i>×<i>L</i></span> are dynamically calculated, holding the probabilities:
</div>
<div class="Standard">
<div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
<div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>
</div>

</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--3"></a>Forward Algorithm
</h3>
<div class="Standard">
The forward probabilities matrix <span class="formula"><i>α</i></span> holds the probability that a sequence <span class="formula"><i>x</i><sub>1:<i>t</i></sub></span> was emitted and that the hidden sequence ended with the state j:
</div>
<div class="Standard">
<div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
It is calculated by the dynamic algorithm:
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-1"> </a><div class="algorithm">
<div class="caption">
Algorithm 1 Forward Algorithm
</div>
<b>Input:</b>    \strikeout off\uuline off\uwave off <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> - Observed DNA sequence<b>Algorithm:</b>     <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span><div class="PlainVisible">
         <span class="formula"><i>α</i><sub><i>j</i>, 1</sub> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span>
</div>
<div class="PlainVisible">
     <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]:</span>
</div>
<div class="PlainVisible">
         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub></span>
</div>

</div>

</div>

</div>
<div class="Standard">
The building of the table is based on the HMM basic assumptions that each hidden state <span class="formula"><i>y</i><sub><i>t</i></sub></span> is dependent only on the previous one <span class="formula"><i>y</i><sub><i>t</i> − 1</sub></span> and that each observed variable <span class="formula"><i>x</i><sub><i>t</i></sub></span> is dependent only on the hidden state that emitted it, <span class="formula"><i>y</i><sub><i>t</i></sub></span>.
</div>
<div class="Standard">
<div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>y</i><sub><i>t</i> − 1</sub> = <i>j</i>’<span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i>’, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub>⋅<span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>
</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="ForwAlg"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HMM forward Algorithm.jpg" alt="figure Figures/HMM forward Algorithm.jpg">
<div class="caption">
Figure 8 Forward algorithm dynamically calculates the probability stored in <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub></span> by using the previously calculated <span class="formula"><i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub></span> values.
</div>

</div>

</div>

</div>

</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--4"></a>Backward Algorithm
</h3>
<div class="Standard">
The backward probabilities matrix <span class="formula"><i>β</i></span> hold the probability that a sequence <span class="formula"><i>x</i><sub><i>t</i> + 1:<i>L</i></sub></span> was emitted given the hidden state at position t had value j: 
</div>
<div class="Standard">
<div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
It is calculated by the dynamic algorithm:
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-2"> </a><div class="algorithm">
<div class="caption">
Algorithm 2 Backward Algorithm
</div>
<b>Input:</b>    \strikeout off\uuline off\uwave offX - Observed DNA sequence<b>Algorithm:</b>     <span class="formula"><i>β</i><sub>1:<i>m</i>, <i>L</i></sub> = 1</span><div class="PlainVisible">
     <span class="formula"><i>for</i> <i>t</i> = [<i>L</i> − 1, ..., 1]:</span>
</div>
<div class="PlainVisible">
         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i></sub></sub></span>
</div>

</div>

</div>

</div>
<div class="Standard">
This matrix building process is similarly explained by:
</div>
<div class="Standard">
<div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’, <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> = 
</div>
<div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’<span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>|<i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’<span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = <i>j</i>’|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i> + 1</sub></sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub>
</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="BackAlg"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HMM backward Algorithm.jpg" alt="figure Figures/HMM backward Algorithm.jpg">
<div class="caption">
Figure 9 Backward algorithm dynamically calculates the probability stored in <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub></span> by using the previously calculated <span class="formula"><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub></span> values
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
Once we obtain <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span> probabilities, the incomplete-data likelihood of HMM can be easily calculated:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="Incomplete-Likelihood">(4) </a><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>L</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>, <i>L</i></sub>
</div>

</div>
<div class="Standard">
And so can the posterior probability:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
Although HMM is simple and efficient, applying it on DNA sequences has a major disadvantage: the inherited Markovian lack-of-memory property. That is, the next state of the model always depends only on the previous state, without further historical consideration. For the task of emitting a TFBS motif where each position has a different emission distribution depending on the location in the motif, an HMM would need to differentiate multiple hidden states according to their positions in the motif. This means that for an HMM to be able to emit even a small number of short motifs, it needs to hold a large number of states which require learning a large number of parameters, e.g. for the ability to emit 50 motifs of length 5, an HMM would need to have over 60,000 parameters. Furthermore, the enhancer modeling task at hand is even more complex, since we would like to model multiple enhancers and backgrounds states, each having a different probability of emitting motifs and an unique k-order emission distribution when not in these motifs. For the prior assumption of our data structure, the required number of model parameters would have been about <span class="formula">10<sup>7</sup></span>, large enough to generate problems such as unfeasible memory complexity and overfitting. 
</div>
<div class="Standard">
A common way to avoid overfitting the data when training machine learning models is to reduce the complexity of the model by fixing some of its parameters. Our proposed HOP-HMM addresses both the memory issue and the overfitting issue while remaining equivalent to a regular HMM with a large number of states having fixed parameters. Namely, most of the transition probabilities are fixed to zero and therefore never stored in the memory, and some of the emission probabilities are predetermined and remain fixed during the training. This allows us to train a model with the enhancer prior assumptions of motifs and higher order emission without overfitting, and with reasonable memory complexity. 
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--5"></a>Generalized HMM
</h3>
<div class="Standard">
In a generalized HMM (GHMM), the transition or the emission are sampled from a different distribution type assigned to each of the states in the model. Some of the states in the system may emit zero or multiple observable variables, sampled from custom emission models specifically tailored for the expected scenario. Such models were used for genes prediction in the 1990’s (<span class="bibcites">[<a class="bibliocite" name="cite-24" href="#biblio-24">24</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-7" href="#biblio-7">7</a>]</span>), in which specific exon states emitted codons instead of single nucleotides, and feed forward neural networks were used to evaluate the probability of certain transitions. 
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="GHMM"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/sHMM_two_states.jpg" alt="figure Figures/sHMM_two_states.jpg">

</div>
<div class="caption">
Figure 10 <b>A)</b> GHMM with a TF state which emits using a PWM. The model has one background hidden state (yellow) and one TF hidden state. <b>B,C,D)</b> Although the TF state emits motifs with 5 bp, the rest of the emissions, transitions and start probabilities remain the same as in a regular HMM. <b>E)</b> An example output generated from the model, showing the TFBS motif sampled in an arbitrary location inside a sequence.
</div>

</div>

</div>

</div>
<div class="Standard">
Another generalization made to the HMM and called higher order HMM uses conditional distribution by making the transition and emission dependent on previous hidden states (<span class="bibcites">[<a class="bibliocite" name="cite-20" href="#biblio-20">20</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-42" href="#biblio-42">42</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-15" href="#biblio-15">15</a>]</span>; <span class="bibcites">[<a class="bibliocite" name="cite-39" href="#biblio-39">39</a>]</span>). Although these HMM variants are capable of expressing a more complex structure of DNA sequence (different <i>k</i>-mers frequencies in the genomic regions), the number of parameters required for DNA analysis tends to rise with the increase of the assumed complexity of the DNA structure. The increase of hidden states needed may introduce overfitting in the learning process, when the data size is limited. 
</div>
<div class="Standard">
Instead of higher order emission which depends on the previous hidden states, the less researched field of higher order emission depending on previously emitted observable variables was used. Such an HMM variant is better suited to the local-spannature of of the emission of k-mer structures, but it only requires <span class="formula"><i>O</i><span class="symbol">(</span><i>m</i><sup>2</sup> + 4<sup><i>k</i></sup><span class="symbol">)</span></span> compared to <span class="formula"><i>O</i></span> <span class="formula"><span class="symbol">(</span><i>m</i><sup><i>k</i></sup><span class="symbol">)</span></span> parameters that would have been required for holding a <i>k</i>-mer distribution in a regular HMM, where m is the number of hidden states of the HOP-HMM, and <span class="formula"><i>k</i></span> is the number of previous states in the dependency. 
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--6"></a>HOP-HMM
</h3>
<div class="Standard">
HOP-HMM is a GHMM that is well fitted to the utilization of the structure of enhancers containing TFBSs, due to the TFBS emitting TF states which take part in the generation process of the sequence. In view of the assumed local physical nature of the TF binding of DNA sequences and of the success of HMM in gene prediction, we think the memorylessness of HMMs fits well the task of enhancer prediction. HOP-HMM balances between the Markovian memorylessness and the observed k-mer of the TFBS present in regulatory regions in the DNA. 
</div>
<div class="Standard">
HOP-HMM extends the GHMM model of <span class="bibcites">[<a class="bibliocite" name="cite-31" href="#biblio-31">31</a>]</span>, where some of the hidden states emit TFBS sampled from PWMs to predict enhancer location in the genome. In HOP-HMM we added the higher order conditional emission probability on non-TF states. 
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="HOPHMM1"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HOP_HMM_two_states.jpg" alt="figure Figures/HOP_HMM_two_states.jpg">
<div class="caption">
Figure 11 <b>A)</b> Small HOP-HMM with one background state and one TF state. <b>B)</b> The background state emits a single observable variable, and has 2-order emission, meaning it is conditioned on the previous observable variable. <b>C,D)</b> Unlike GHMM, in HOP-HMM TF state can transition into itself and cannot be the starting hidden state and the background state . <b>E)</b> The TF state emits multiple observable variables which represent a TFBS sampled from a PWM. 
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="TGCompact"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/Transition_repack.jpg" alt="figure Figures/Transition_repack.jpg">
<div class="caption">
Figure 12 Instead of holding a single sparse 8<span class="formula"> × </span>8 transition matrix, an alternative compact form holds only the non-fixed transition probabilities, split into T and G matrices. The non-fixed transition probabilities held in the compact form are those between background states, and between background states to their TF states (outlined with blue). The concatenation of a row in T and G holds the probability of the next hidden state given the current background state. 
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="HOPHMM2"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HOP_HMM_multi_states.jpg" alt="figure Figures/HOP_HMM_multi_states.jpg">
<div class="caption">
Figure 13 <b>A)</b> A more complex HOP-HMM with two background states <span class="formula"><i>BG</i><sub>1</sub></span> and <span class="formula"><i>BG</i><sub>2</sub></span>, where each has 3 TF states. <b>B) </b>Each of the background states has its own 2-order emission distribution in a <span class="formula">4 × 4</span> matrix. <b>C)</b> The start hidden state distribution <span class="formula"><i>π</i></span> allows only background states to start the hidden sequence. <b>D)</b> The transition probability is held by matrices <span class="formula"><i>T</i></span> and G. <b>E)</b> The example-generated sequence is built out of two types of sequences, each with its own TFBS frequency and background nucleotide bigram frequency, representing two alternating types of enhancers. 
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
We use two indices to describe a hidden state in HOP-HMM: 
</div>
<ul>
<li>
background states are indexed as <span class="formula">(<i>j</i>, 0)</span> where <span class="formula"><i>j</i> ∈ [<i>m</i>]</span> and <span class="formula"><i>m</i></span> is the number background states.
</li>
<li>
TF states are indexed as <span class="formula">(<i>j</i>, <i>l</i>)</span> where <span class="formula"><i>j</i> ∈ [<i>m</i>]</span>, <span class="formula"><i>l</i> ∈ [<i>k</i>]</span>. and <span class="formula"><i>k</i></span> is the number of TF states each of the background states has.
</li>

</ul>
<div class="Standard">
For example, in figure <a class="Reference" href="#HOPHMM2">13↑</a> we see a HOP-HMM with <span class="formula"><i>m</i> = 2</span> and <span class="formula"><i>k</i> = 3</span> and a total of 8 hidden-states (<span class="formula">2 + 3 × 2</span>). The TF state indexed <span class="formula">(<i>j</i>, <i>l</i>)</span> belongs to the <span class="formula">(<i>j</i>, 0)</span> background state (see figure <a class="Reference" href="#HOPHMM3">14↓</a>), and the only allowed transfer into <span class="formula">(<i>j</i>, <i>l</i>)</span> is from its background state <span class="formula">(<i>j</i>, 0)</span>. Note that we used a simpler <span class="formula"><i>BG</i><sub><i>j</i></sub></span> notation in figures <a class="Reference" href="#HOPHMM1">11↑</a> and <a class="Reference" href="#HOPHMM2">13↑</a> for readability.
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="HOPHMM3"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HOP_HMM_general_mk.jpg" alt="figure Figures/HOP_HMM_general_mk.jpg">
<div class="caption">
Figure 14 <i><i>General hidden states graph of HOP-HMM. Each row represents a sequence type, where each of the <span class="formula"><i>m</i></span> background states (yellow) has <span class="formula"><i>k</i></span></i></i> TF state<i><i>s (green). Not all transitions are possible, moving between the rows is possible only by a background state to background state transition.</i></i>
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
While most background states <span class="formula">(<i>j</i>, 0)</span> represent an enhancer type, we also would also like to model true background regions in between the enhancers that carry no regulatory role and have no TFBSs. For To that end, we predefine one or more background states as non-enhancers by restricting their transfer probability into their TF states, as seen in the results section. 
</div>
<div class="Standard">
HOP-HMM is defined with k PWMs <span class="formula"><i>W</i><sub>1</sub>, <i>W</i><sub>2</sub>, ..., <i>W</i><sub><i>k</i></sub></span> that remain fixed during training. Each of the k PWMs is shared with m TF states, e.g. the PWM <span class="formula"><i>W</i><sub><i>l</i></sub></span>, where <span class="formula"><i>l</i> ∈ [<i>k</i>]</span>, is shared between subs-states <span class="formula">(1, <i>l</i>), (2, <i>l</i>), ..., (<i>m</i>, <i>l</i>)</span> and is used for the TF state emission sampling. The PWMs vary in their column amounts (as the different TFBSs vary in length), and each column represents a nucleotide distribution at that position. When the model enters a TF state, it emits a motif by sampling independently from a PWM column by column, as described in figure e <a class="Reference" href="#GHMM">10↑</a>.
</div>
<div class="Standard">
The background states, denoted as <span class="formula">(1, 0), (2, 0), ..., (<i>m</i>, 0)</span>, are responsible for the emission of inter-TFBS parts of the enhancers lacking long motifs. Similarly to regular states in HMM, background states emit single nucleotides whose emission is conditional on the previous nucleotides emitted in the DNA sequence. The emission from background states is done by sampling a nucleotide from the distributions stored in <span class="formula"><i>E</i></span> tensor. <span class="formula"><i>E</i></span> dimension is <span class="formula"><i>o</i> + 1</span>, and its size is <span class="formula"><span class="text"> </span><i>m</i> × 4 × 4 × ... × 4</span> (with <span class="formula"><i>o</i></span> fours) and its values describe the emission probability <span class="formula"><i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i></sub></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span></span>, meaning that when <span class="formula"><i>x</i><sub><i>t</i></sub></span> is sampled by the model, the preceding <span class="formula"><i>o</i> − 1</span> observed variables are used as indices of the tensor for getting the emission probability vector <span class="formula"><i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub>, *</sub></span>.
</div>
<div class="Standard">
For the first variables emitted in the sequence, the missing dimensions of the preceding variables are summed to form the probability vector, e.g. if <span class="formula"><i>t</i> = <i>o</i> − 1</span>, a single variable is missing for emitting <span class="formula"><i>x</i><sub><i>t</i></sub></span> and the distribution used for emission sampling is <span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ [4]</sub><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>E</i><sub><i>j</i>, <i>i</i>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub></sub></span><span class="ignored">)/(</span><span class="denominator">4</span><span class="ignored">)</span></span></span>.<br>

</div>
<div class="Standard">
In HOP-HMM, the first hidden state in a sequence can only be a background state. As in HMM, the first background state is chosen by sampling from <span class="formula"><i>π</i>, </span> a probability vector <span class="formula"><i>π</i><sub><i>j</i></sub> = <i>P</i>(<i>y</i><sub>1</sub> = (<i>j</i>, 0))</span>. Once in a background state, the model can only transit into a small subset of states, and since most of the possible transitions are not allowed, a single transition matrix from all states to all states would be sparse. Instead, as described in figure <a class="Reference" href="#TGCompact">12↑</a>, we only hold the possible transition probabilities in two matrices, representing the two types of allowed transitions: 
</div>
<ul>
<li>
T for background state to background state transitions, a <span class="formula"><i>m</i> × <i>m</i></span> matrix where <span class="formula"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i><sub>2</sub>, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span></span>.
</li>
<li>
G for background state to TF state transitions a <span class="formula"><i>m</i> × <i>k</i></span> matrix where <span class="formula"><i>G</i><sub><i>j</i>, <i>l</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span>.
</li>

</ul>
<div class="Standard">
When in a background state, after the observable variable emission, the model samples its next hidden state from a probability vector which is the concatenation of a row in T and a row in G. If a TF state is chosen,,the model returns back to the background state after the TF state’s motif emission to emit another single observable variable and so on. 
</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--3"></a>Methods
</h1>
<div class="Standard">
When fitting a HMM to a DNA sequence, we seek the parameters <span class="formula"><i>θ</i><sup>*</sup></span> that best explain the sequence via a algorithm called Baum-Welch algorithm, which is a special case of EM algorithm. Formally, given the observed DNA sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>, we would like to find the parameters that maximize the incomplete-likelihood: <div class="formula">
<i>θ</i><sup>*</sup> = <i>argmax</i><sub><i>θ</i></sub>ℒ<span class="symbol">(</span><i>θ</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
Even though the incomplete-data likelihood of HMM in <a class="Reference" href="#Likelihoods">(2↑)</a> is derivable by <span class="formula"><i>θ</i></span>, optimizing it is as difficult as calculating it and therefore is also impractical. Instead, the strategy of the EM algorithm is to optimize the expected value of the complete-data log-likelihood <span class="formula"><i>log</i><span class="symbol">(</span><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub>|<i>θ</i><sup>’</sup><span class="symbol">)</span><span class="symbol">)</span></span> over all possible <span class="formula"><i>y</i><sub>1:<i>L</i></sub></span> where <span class="formula"><i>θ</i><sup>’</sup></span> is the model’s parameters from previous EM iteration (or guessed parameters in the first iteration) and while assuming a fixed observed <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>, as it is the given DNA sequence. For this task we define our target function Q:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="Q">(5) </a><i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = <i>E</i><sub><i>Y</i></sub><span class="symbol">[</span><i>log</i><span class="symbol">(</span><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span><span class="symbol">)</span>|<i>x</i><sub>1:<i>L</i></sub>, <i>θ</i><sup>’</sup><span class="symbol">]</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><i>log</i><span class="symbol">(</span><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
Here E is expressing an expected value, not to be confused with the HMM emission probability. Every EM iteration is built out of two parts called the E (expectation) step and the M (maximization) step. In the E-step we calculate the probabilities needed for the maximization of Q and in the M-step we infer the <span class="formula"><i>θ</i></span> that maximizes it. We will update the <span class="formula"><i>θ</i></span> for maximizing <span class="formula"><i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span></span> in every M-step of the EM algorithm until convergence. 
</div>
<div class="Standard">
Using <a class="Reference" href="#Complete-Likelihood">(3↑)</a> we will split the Q function <a class="Reference" href="#Q">(5↑)</a> into three independent parts:
</div>
<div class="Standard">
<div class="formula">
<span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><i>log</i><i>π</i><sub><i>y</i><sub>1</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logT</i><sub><i>y</i><sub><i>t</i> − 1</sub>, <i>y</i><sub><i>t</i></sub></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>y</i><sub>1:<i>L</i></sub> ∈ <span class="symbol">[</span><i>m</i><span class="symbol">]</span><sup><i>L</i></sup></sub><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>logE</i><sub><i>y</i><sub><i>t</i></sub>, <i>x</i><sub><i>t</i></sub></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</span>

</span>
</span>
</div>

</div>
<div class="Standard">
then by manipulating the summation, the exponential state sequence summation could be simplified to:
</div>
<div class="Standard">
<div class="formula">
<span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>log</i><i>π</i><sub><i>j</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i><span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>logE</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>
</span>

</span>
</span>
</div>

</div>
<div class="Standard">
Each of the three parts above is a set of constraint linear functions that could be derived and maximized independently using a Lagrange multipliers, under the following probability constrains:
</div>
<ul>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>π</i><sub><i>j</i></sub> = 1</span>
</li>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = 1</span> for all <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span>
</li>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>b</i> ∈ [<i>n</i>]</sub><i>E</i><sub><i>j</i>, <i>b</i></sub> = 1</span> for all <span class="formula"><i>j</i> ∈ [<i>n</i>]</span>
</li>

</ul>
<div class="Standard">
where <span class="formula"><i>m</i></span> is the number of different hidden states and <span class="formula"><i>n</i></span> is the number of different observed variables (4 in our case of DNA).
</div>
<div class="Standard">
First, we start with maximizing the first <span class="formula"><i>π</i></span> part using Lagrange multiplier <span class="formula"><i>λ</i></span>:
</div>
<div class="Standard">
<div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>π</i><sub><i>j</i></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>log</i><i>π</i><sub><i>j</i>’</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i>’<span class="symbol">)</span> + <i>λ</i><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>π</i><sub><i>j</i>’</sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>

</div>
<div class="Standard">
we derive the term and get <span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>π</i><sub><i>j</i></sub></span><span class="ignored">)</span></span> = <i>λ</i></span> for <span class="formula"><i>j</i> ∈ [<i>m</i>]</span>. Then we use these m equations to get <span class="formula"><i>λ</i> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>, which yields the reestimated <span class="formula"><i>π</i><sub><i>j</i></sub></span>:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="Pi-Update">(6) </a><i>π</i><sub><i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub>1</sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
Second, we define a Lagrange multipliers <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub></span> for each <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span> for the <span class="formula"><i>T</i></span> part:
</div>
<div class="Standard">
<div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span> + <i>λ</i><sub><i>j</i><sub>1</sub></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i>’</sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>

</div>
<div class="Standard">
which yields <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span></span> for <span class="formula"><i>j</i><sub>2</sub> ∈ [<i>m</i>]</span> 
</div>
<div class="Standard">
when the m equations are summed, gives <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub><span class="symbol">)</span></span> 
</div>
<div class="Standard">
therefore the update of <span class="formula"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span> will be:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="T-Update">(7) </a><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
Finally, we’ll define multiplier <span class="formula"><i>λ</i><sub><i>j</i></sub></span> for every <span class="formula"><i>j</i> ∈ [<i>m</i>]</span> for the <span class="formula"><i>E</i></span> part:
</div>
<div class="Standard">
<div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>E</i><sub><i>j</i>, <i>b</i></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>logE</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span> + <i>λ</i><sub><i>j</i></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>b</i>’ ∈ [<i>n</i>]</sub><i>E</i><sub><i>j</i>, <i>b</i>’</sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>

</div>
<div class="Standard">
this step is slightly trickier due to the derivation of <span class="formula"><span class="fraction"><span class="ignored">(</span><span class="numerator">∂<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub></span><span class="ignored">)/(</span><span class="denominator">∂<i>E</i><sub><i>j</i>, <i>b</i></sub></span><span class="ignored">)</span></span> = <b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span> where <span class="formula"><b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>) = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
1 
</span>
<span class="case align-l">
<i>b</i> = <i>x</i><sub><i>t</i></sub> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
0 
</span>
<span class="case align-l">
<i>otherwise</i> 
</span>

</span>

</span>
</span>.
</div>
<div class="Standard">
we get <span class="formula"><i>λ</i><sub><i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><i>E</i><sub><i>j</i>, <i>b</i></sub></span><span class="ignored">)</span></span></span> for <span class="formula"><i>b</i> ∈ [<i>n</i>]</span> 
</div>
<div class="Standard">
when all n equations are summed, gives <span class="formula"><i>λ</i><sub><i>j</i></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span> 
</div>
<div class="Standard">
therefore the update of <span class="formula"><i>E</i><sub><i>j</i>, <i>b</i></sub></span> will be:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="E-Update">(8) </a><i>E</i><sub><i>j</i>, <i>b</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span><b>⋅1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span><b>1</b><sub><i>b</i></sub>(<i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
For us to be able to calculate these reestimation of <span class="formula"><i>θ</i></span> as written in <a class="Reference" href="#Pi-Update">(6↑)</a>, <a class="Reference" href="#T-Update">(7↑)</a> and <a class="Reference" href="#E-Update">(8↑)</a>, we are still left with the calculation of the two probabilities terms inside them. \strikeout off\uuline off\uwave offTo resemble the notations coined in <span class="bibcites">[<a class="bibliocite" name="cite-51" href="#biblio-51">51</a>]</span>, the first widely accepted HMM application, we’ll denote these as <span class="formula"><i>γ</i></span> and <span class="formula"><i>ξ</i></span>
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="gamma">(9) </a><i>γ</i><sub><i>t</i>, <i>j</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
 <div class="formula">
<a class="eqnumber" name="xi">(10) </a><i>ξ</i><sub><i>t</i>, <i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
We will use <a class="Reference" href="#Incomplete-Likelihood">(4↑)</a> and the output of the Forward-Backward algorithm <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span> for their calculation:
</div>
<div class="Standard">
<div class="formula">
<i>γ</i><sub><i>t</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i>, <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>, <i>L</i></sub></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
<div class="formula">
<i>ξ</i><sub><i>t</i>, <i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>y</i><sub><i>t</i>]</sub> = <i>j</i><sub>2</sub>, <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub>, <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub>|<i>y</i><sub><i>t</i> − 1</sub> = <i>j</i><sub>1</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = <i>j</i><sub>2</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i><sub>1</sub>, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, </sub>⋅<i>E</i><sub><i>j</i><sub>2</sub>, <i>x</i><sub><i>t</i></sub></sub>⋅<i>β</i><sub><i>j</i>’, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>, <i>L</i></sub></span><span class="ignored">)</span></span>
</div>
The calculation of <span class="formula"><i>α</i>, <i>β</i>, <i>γ</i></span> and <span class="formula"><i>ξ</i></span> matrices is considered the E-step of Baum-Welch algorithm, and they allow us to update <span class="formula"><i>θ</i></span> and finish the EM iteration.
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--7"></a>Baum-Welch Algorithm for HOP-HMM
</h3>
<div class="Standard">
The transitions and emissions mechanisms of HOP-HMM are different, and therefore the complete-data likelihood of HOP-HMM requires different calculation for the Baum-Welch algorithm to hold. The Baum-Welch algorithm can be adjusted to infer the parameters of the HOP-HMM variant <span class="formula"><i>θ</i> = {<i>π</i>, <i>E</i>, <i>G</i>, <i>T</i>}</span> from a DNA sequence <span class="formula"><i>X</i></span>. As in the regular Baum-Welch algorithm covered in the previous section, given a sequence <span class="formula"><i>X</i></span> at each EM iteration we optimize the Q function in <a class="Reference" href="#Q">(5↑)</a>:
</div>
<div class="Standard">
<div class="formula">
<span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>Q</i><span class="symbol">(</span><i>θ</i>, <i>θ</i><sup>’</sup><span class="symbol">)</span> = 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>log</i><i>π</i><sub><i>j</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>], <i>l</i> ∈ [<i>k</i>]</sub><i>logG</i><sub><i>j</i>, <i>l</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>logE</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 
</span>
<span class="arraycell align-l">
 
</span>

</span>
<span class="arrayrow">
<span class="arraycell align-r">
 + 
</span>
<span class="arraycell align-l">
<span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ [<i>L</i>]</sub><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>logL</i><sub><i>W</i></sub>(<i>x</i><sub><i>t</i>:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| − 1</sub>)⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i>:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| − 1<i>S</i></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>
</span>

</span>
</span>
</div>

</div>
<div class="Standard">
where <span class="formula"><i>L</i><sub><i>W</i></sub>(<span class="overline"><i>x</i></span>)</span> is the likelihood of the TFBS <span class="formula"><span class="overline"><i>x</i></span></span> to be emitted by PWM <span class="formula"><i>W</i></span>: <span class="formula"><i>L</i><sub><i>M</i></sub>(<span class="overline"><i>x</i></span>) = <i>P</i>(<span class="overline"><i>x</i></span>|<i>W</i>) = <span class="unknown">\underset</span><i>i</i> ∈ {1, ..., |<span class="overline"><i>x</i></span>|}<span class="limits"><span class="limit">∏</span></span><i>W</i><sub><span class="overline"><i>x</i></span><sub><i>i</i></sub>, <i>i</i></sub></span>. 
</div>
<div class="Standard">
Note that the last addition component, which holds the TFBS log likelihood, does not contain elements from <span class="formula"><i>θ</i></span> as the PWMs are not learned in HOP-HMM, and therefore it is not reestimated in the M-steps.
</div>
<div class="Standard">
The <span class="formula"><i>θ</i><sup>*</sup></span> which optimizes <span class="formula"><i>Q</i></span> here, <span class="formula"><i>θ</i><sup>*</sup> = <i>argmax</i><sub><i>θ</i></sub><i>Q</i>(<i>θ</i>, <i>θ</i>’)</span>, is archived by optimizing its 3 independent parts as well, each having its own constrain under which we optimize <span class="formula"><i>Q</i></span> are:
</div>
<ul>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i> ∈ [<i>m</i>]</sub><i>π</i><sub><i>j</i></sub> = 1</span>
</li>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i><sub>2</sub> ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> + <span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub> = 1</span> for all <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span>
</li>
<li>
<span class="formula"><span class="limits"><span class="limit">∑</span></span><sub><i>b</i><sub><i>o</i></sub> ∈ [<i>n</i>]</sub><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = 1</span> for all <span class="formula"><i>j</i> ∈ [<i>n</i>]</span>
</li>

</ul>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--8"></a>M-step
</h3>
<div class="Standard">
The <span class="formula"><i>π</i></span> and <span class="formula"><i>E</i></span> conditions produce almost exact same maximization as in regular Baum-Welch <a class="Reference" href="#Pi-Update">(6↑)</a> and <a class="Reference" href="#E-Update">(8↑)</a>:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="HOP-Pi-Update">(11) </a><i>π</i><sub><i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub>1</sub> = (<i>j</i>, 0)|<i>θ</i><sup>’</sup><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>|<i>θ</i><sup>’</sup><span class="symbol">)</span></span><span class="ignored">)</span></span> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub>1</sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="HOP-E-Update">(12) </a><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span><b> 1</b><sub><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub>(<i>x</i><sub><i>t</i> − <i>o</i> + 1, ..., <i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
As for the second condition of <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span>, we will define the Lagrange multipliers <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub></span> for <span class="formula"><i>j</i><sub>1</sub> ∈ [<i>m</i>]</span> and derive the two terms that contain <span class="formula"><i>T</i></span> and <span class="formula"><i>G</i></span>:
</div>
<div class="Standard">
<div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>T</i><sub><i>j</i><sub>1, </sub><i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logT</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span> + <i>λ</i><sub><i>j</i><sub>1</sub></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i>’</sub> − <span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>

</div>
<div class="Standard">
<div class="formula">
<span class="fraction"><span class="ignored">(</span><span class="numerator">∂</span><span class="ignored">)/(</span><span class="denominator">∂<i>G</i><sub><i>j</i><sub>1</sub>, <i>l</i></sub></span><span class="ignored">)</span></span><span class="symbol">(</span><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>logG</i><sub><i>j</i><sub>1</sub>, <i>l</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, <i>l</i>)<span class="symbol">)</span> + <i>λ</i><sub><i>j</i><sub>1</sub></sub><span class="symbol">(</span>1 − <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i>’</sub> − <span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub><span class="symbol">)</span><span class="symbol">)</span> = 0
</div>

</div>
<div class="Standard">
which yields <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub></span><span class="ignored">)</span></span></span> and <span class="formula"><i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub>⋅<i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, <i>l</i>)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>G</i><sub><i>j</i><sub>1</sub><i>l</i></sub></span><span class="ignored">)</span></span></span> for <span class="formula"><i>j</i><sub>2</sub> ∈ [<i>m</i>]</span> and <span class="formula"><i>l</i> ∈ [<i>k</i>]</span>. 
</div>
<div class="Standard">
When the <span class="formula"><i>m</i> + <i>k</i></span> equations are summed we receive:
</div>
<div class="Standard">
<div class="formula">
<i>λ</i><sub><i>j</i><sub>1</sub></sub> = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span> + <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>1</sub>, <i>l</i>)<span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span>
</div>

</div>
<div class="Standard">
which gives us the updates 
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="HOP-T-Update">(13) </a><i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="HOP-G-Update">(14) </a><i>G</i><sub><i>j</i>, <i>l</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ 2...<i>L</i></sub><i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--9"></a>E-step
</h3>
<div class="Standard">
Preceding the M-step where we update components of <span class="formula"><i>θ</i></span> by <a class="Reference" href="#HOP-Pi-Update">(11↑)</a>, <a class="Reference" href="#HOP-E-Update">(12↑)</a>, <a class="Reference" href="#HOP-T-Update">(13↑)</a> and <a class="Reference" href="#HOP-G-Update">(14↑)</a>, we will calculate the three probability terms inside them in the E-step, denoted as <span class="formula"><i>γ</i>, </span> <span class="formula"><i>ξ</i></span> and <span class="formula"><i>η</i></span>:<br>
<br>
 <div class="formula">
<a class="eqnumber" name="HOP-gamma">(15) </a><i>γ</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>
 <div class="formula">
<a class="eqnumber" name="HOP-xi">(16) </a><i>ξ</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, <i>t</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="HOP-eta">(17) </a><i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <i>P</i><sub><i>θ</i><sup>’</sup></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
For the calculation of these probabilities, we first need to calculate the forward and backward probabilities output from an HOP-HMM adjusted Forward-Backward algorithm. In this HOP-Forward-Backward algorithm, we will only build the probabilities for being in background states since the TF states probabilities are not needed in the later parts of the E-step.
</div>
<div class="Standard">
<div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
<div class="formula">
<i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</div>

</div>
<div class="Standard">
The adjustments for the forward and backward algorithm are straight forward, as the summation is composed of two parts. We calculate <span class="formula"><i>α</i></span> of size <span class="formula"><i>m</i> × <i>L</i></span>, iterating over <span class="formula"><i>t</i> = 1, 2, ..., <i>L</i></span> as following:
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-3"> </a><div class="algorithm">
<div class="caption">
Algorithm 3 HOP Forward Algorithm
</div>
<b>Input:</b>    \strikeout off\uuline off\uwave offX - Observed DNA sequence<b>Algorithm:</b>     <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span><div class="PlainVisible">
         <span class="formula"><i>α</i><sub><i>j</i>, 1</sub> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span>
</div>
<div class="PlainVisible">
     <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]:</span>
</div>
<div class="PlainVisible">
         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub> = <span class="unknown">\underset</span><span class="text">background-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub></span></span>
</div>
<div class="PlainVisible">
                   <span class="formula"> + <span class="unknown">\underset</span><span class="text">TF-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>α</i><sub><i>j</i>, <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub></span></span>
</div>

</div>

</div>

</div>
<div class="Standard">
In the beginning of the sequence, when <span class="formula">1 ≤ <i>t</i> &lt; <i>o</i></span>, part of the preceding observable variables are missing. Since E has <span class="formula"><i>o</i> + 1</span> dimensions, <span class="formula"><i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub></span> is not defined, so we define it here as: 
</div>
<div class="Standard">
<div class="formula">
<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub> = <span class="unknown">\underset</span><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i> − <i>t</i></sub> ∈ {<i>A</i>, <i>C</i>, <i>G</i>, <i>T</i>}<span class="limits"><span class="limit">∑</span></span><span class="fraction"><span class="ignored">(</span><span class="numerator">1</span><span class="ignored">)/(</span><span class="denominator">4<sup><i>o</i> − <i>t</i></sup></span><span class="ignored">)</span></span>⋅<i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, .., .<i>b</i><sub><i>o</i> − <i>t</i></sub>, <i>x</i><sub>1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>
</div>
 
</div>
<div class="Standard">
We used the fact that <span class="formula"><i>P</i>(<i>A</i>) = <span class="limits"><span class="limit">∑</span></span><sub><i>b</i> ∈ <i>B</i></sub><i>P</i>(<i>b</i>)⋅<i>P</i>(<i>A</i>|<i>b</i>)</span> and the assumption that the observable variables preceding the sequence came from a uniform distribution. Also, when summing the TF state transition part, PWMs <span class="formula"><i>W</i><sub><i>l</i></sub></span> with length equal or bigger than <span class="formula"><i>t</i> + 1</span> include out-of-sequence TFBS and are not part of the summation.
</div>
<div class="Standard">
For <span class="formula"><i>β</i></span> of size <span class="formula"><i>m</i> × <i>L</i></span>, we iterating over <span class="formula"><i>t</i> = <i>L</i>, <i>L</i> − 1, ..., 1</span> as following:
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-4"> </a><div class="algorithm">
<div class="caption">
Algorithm 4 HOP Backward Algorithm
</div>
<b>Input:</b>    \strikeout off\uuline off\uwave offX - Observed DNA sequence<b>Algorithm:</b>     <span class="formula"><i>β</i><sub>1:<i>m</i>, <i>L</i></sub> = 1</span><div class="PlainVisible">
     <span class="formula"><i>for</i> <i>t</i> = [<i>L</i> − 1, ..., 1]:</span>
</div>
<div class="PlainVisible">
         <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub> = <span class="unknown">\underset</span><span class="text">background-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + 1</sub></sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub></span></span>
</div>
<div class="PlainVisible">
                   <span class="formula"> + <span class="unknown">\underset</span><span class="text">TF-state transitions</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + |<i>W</i><sub><i>l</i></sub>| + 2</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub></span></span>
</div>

</div>

</div>

</div>
<div class="Standard">
Note that when <span class="formula"><i>t</i> &gt; <i>L</i> − |<i>W</i><sub><i>l</i></sub>|</span>, there are missing observable variables to fully calculate the TF state transition. In these situations this contribution of these component to the summation is zero, meaning our HOP-HMM as the behavior of avoiding a transition into a TF state when the PWM is too long to fit into the sequence <span class="formula"><i>X</i></span> length.
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Figure-15"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/HOP-EM forward Algorithm.jpg" alt="figure Figures/HOP-EM forward Algorithm.jpg">
<div class="caption">
Figure 15 In HOP-HMM, the Forward-Backward algorithm dynamic tables <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span> cells are filled from both the adjacent background states transitions and the background states preceding or proceeding the motifs emitted by the TF states.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
We will now explain why the described dynamic calculation result with <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span></span> and <span class="formula"><i>β</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span>, starting with the forward probabilities <span class="formula"><i>α</i></span>. From the law of total probability, the probability <span class="formula"><i>α</i><sub><i>j</i>, <i>t</i></sub></span> is the sum of probabilities of all the possible transition that ended in the background state (j,0):
</div>
<div class="Standard">
<div class="formula">
<i>α</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="unknown">\underset</span><span class="text">background-state transitions</span><span class="underbrace"><span class="unknown">\underset</span><i>j</i>’ ∈ [<i>m</i>]<span class="limits"><span class="limit">∑</span></span><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span></span> + <span class="unknown">\underset</span><span class="text">TF-state transitions</span><span class="underbrace"><span class="unknown">\underset</span><i>l</i> ∈ [<i>k</i>]<span class="limits"><span class="limit">∑</span></span><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span></span>
</div>

</div>
<div class="Standard">
right-side term of a TF state transition can be split with the chain rule to:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub>|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub>, <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>
</div>

</div>
<div class="Standard">
Since <span class="formula"><i>x</i><sub><i>t</i></sub></span> is dependent only on <span class="formula"><i>y</i><sub><i>t</i></sub></span> and <span class="formula"><i>x</i><sub><i>t</i> − <i>o</i>:<i>t</i> − 1</sub></span> and since <span class="formula"><i>y</i><sub><i>t</i></sub></span> is dependent on only <span class="formula"><i>y</i><sub><i>t</i> − 1</sub></span>, we can simplify the probabilities:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub>|<i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i>:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>α</i><sub><i>j</i>, <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>
</div>

</div>
<div class="Standard">
This process is similar to the background state transition. Using the chain rule:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>’, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>α</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>
</div>

</div>
<div class="Standard">
For the backward probabilities <span class="formula"><i>β</i>, </span> the explanation is similar. The main difference between the regular HMM backward probability is the condition on the <span class="formula"><i>o</i> − 1</span> preceding observable variables <span class="formula"><i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub></span>, which are necessary for the background state emission is conditional on them.
</div>
<div class="Standard">
Using the law of total probability:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="unknown">\underset</span><span class="text">background-state transition</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span></span> + <span class="unknown">\underset</span><span class="text">TF-state transition</span><span class="underbrace"><span class="limits"><span class="limit">∑</span></span><sub><i>l</i> ∈ [<i>k</i>]</sub><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span>
</div>

</div>
<div class="Standard">
For the background state transition term, we can use the chain rule and the Markovian independence of the transitions and emissions:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i> + 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 3:<i>t</i> + 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>|<i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0), <i>x</i><sub><i>t</i> − <i>o</i> + 2:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>’, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>β</i><sub><i>j</i>’, <i>t</i> + 1</sub>⋅<i>E</i><sub><i>j</i>’, <i>x</i><sub><i>t</i> − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + 1</sub></sub>⋅<i>T</i><sub><i>j</i>, <i>j</i>’</sub>
</div>

</div>
<div class="Standard">
For the TF state transition term, we use once more the chain rule, followed the simplification using the conditional independencies of HMM:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 2:<i>L</i></sub>|<i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>, <i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>|<i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>, <i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>|<i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>|<i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>|<i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>
</div>

</div>
<div class="Standard">
Using the forward and the backward probability matrices <span class="formula"><i>α</i></span> and <span class="formula"><i>β</i></span>, we can calculate the auxiliary probabilities <a class="Reference" href="#HOP-gamma">(15↑)</a>, <a class="Reference" href="#HOP-xi">(16↑)</a> and <a class="Reference" href="#HOP-eta">(17↑)</a>. The first probability that will help us for that is <span class="formula"><i>ψ</i></span>, a matrix of size <span class="formula"><i>m</i> × <i>k</i> × <i>L</i></span>:
</div>
<div class="Standard">
<div class="formula">
<i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>), <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>), <i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>t</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> + 1</sub> = (<i>j</i>, <i>l</i>)|<i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub>|<i>y</i><sub><i>t</i> + 1:<i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span></sub> = (<i>j</i>, <i>l</i>)<span class="symbol">)</span>⋅
</div>

</div>
<div class="Standard">
<div class="formula">
⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub>|<i>y</i><sub><i>t</i> + <span class="symbol">|</span><i>W</i><sub><i>l</i></sub><span class="symbol">|</span> + 1</sub> = (<i>j</i>, 0)<span class="symbol">)</span><span class="text"> ⋅</span><i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 2:<i>L</i></sub>|<i>y</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub> = (<i>j</i>, 0), <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| − <i>o</i> + 3:<i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i>, </sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub>
</div>

</div>
<div class="Standard">
The second probability is likelihood of the observed sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>:
</div>
<div class="Standard">
<div class="formula">
<i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>]<span class="limits"><span class="limit">∑</span></span><span class="symbol">(</span><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub> + <span class="unknown">\underset</span><i>l</i> ∈ <span class="symbol">[</span><i>k</i><span class="symbol">]</span>,  <i>t</i>’ ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span><span class="limits"><span class="limit">∑</span></span><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i> − <i>s</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
Now we can calculate probability <a class="Reference" href="#HOP-gamma">(15↑)</a> of the background state at a given position given the sequence <span class="formula"><i>X</i></span>, denoted as <span class="formula"><i>γ</i></span> of size <span class="formula"><i>m</i> × <i>L</i></span>:
</div>
<div class="Standard">
<div class="formula">
<i>γ</i><sub><i>j</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>x</i><sub>1:<i>t</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0), <i>x</i><sub>1:<i>t</i></sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>x</i><sub><i>t</i> − <i>o</i> + 1:<i>t</i></sub>, <i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)<span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
The probability <a class="Reference" href="#HOP-xi">(16↑)</a> is the background state to background state transition given the sequence <span class="formula"><i>X</i></span>, denoted as <span class="formula"><i>ξ</i></span> of size <span class="formula"><i>m</i> × <i>m</i> × <i>L</i></span>:
</div>
<div class="Standard">
<div class="formula">
<i>ξ</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>t</i> − 1</sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i>:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>t</i> − 1</sub>, <i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0)|<i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i><sub>1</sub>, 0)<span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>P</i><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>L</i></sub>|<i>y</i><sub><i>t</i></sub> = (<i>j</i><sub>2</sub>, 0), <i>x</i><sub>1:<i>t</i> − 1</sub><span class="symbol">)</span></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i><sub>1</sub>, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>E</i><sub><i>j</i><sub>2</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>⋅<i>β</i><sub><i>j</i><sub>2</sub>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
Finally, the probability <a class="Reference" href="#HOP-eta">(17↑)</a> is the background state to background state transition given the sequence <span class="formula"><i>X</i></span>, denoted as <span class="formula"><i>ψ</i></span> of size <span class="formula"><i>m</i> × <i>k</i> × <i>L</i></span>:
</div>
<div class="Standard">
<div class="formula">
<i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i> − 1</sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>P</i><span class="symbol">(</span><i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span><span class="ignored">)</span></span>
</div>

</div>
<div class="Standard">
Now with <a class="Reference" href="#HOP-gamma">(15↑)</a>, <a class="Reference" href="#HOP-xi">(16↑)</a> and <a class="Reference" href="#HOP-eta">(17↑)</a> at hand, we can complete the M-step and update <span class="formula"><i>θ</i></span> by assigning the updates of <a class="Reference" href="#HOP-Pi-Update">(11↑)</a>, <a class="Reference" href="#HOP-E-Update">(12↑)</a>, <a class="Reference" href="#HOP-T-Update">(13↑)</a> and <a class="Reference" href="#HOP-G-Update">(14↑)</a>.
</div>
<div class="Standard">
The Baum-Welch algorithm adaptation for HOP-HMM, as described in this section:
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-5"> </a><div class="algorithm">
<div class="caption">
Algorithm 5 HOP Baum-Welch
</div>
<b>Input:</b>    \strikeout off\uuline off\uwave offX - Observed DNA sequence<b>Algorithm:</b>    for s=[1...MAX_EM_ITERATIONS]:<div class="PlainVisible">
        <i># E-step</i>
</div>
<div class="PlainVisible">
         <span class="formula"><i>α</i> = <span class="text">hop_forward_algorithm(x<sub>1:L</sub>) </span></span>
</div>
<div class="PlainVisible">
         <span class="formula"><i>β</i> = <span class="text">hop_backward_algorithm(x<sub>1:L</sub>) </span></span>
</div>
<div class="PlainVisible">
        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>l</i> = [1, ..., <i>k</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :
</div>
<div class="PlainVisible">
             <span class="formula"><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
<i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i>, </sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> + 1:<i>t</i> + |<i>W</i><sub><i>l</i></sub>|</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| − <i>o</i> + 2</sub>, ..., <i>x</i><sub><i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1</sub> 
</span>
<span class="case align-l">
| <i>t</i> + |<i>W</i><sub><i>l</i></sub>| + 1 ≤ <i>L</i> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
0 
</span>
<span class="case align-l">
| <i>otherwise</i> 
</span>

</span>

</span>
</span>
</div>
<div class="PlainVisible">
         <span class="formula"><i>Px</i> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>]<span class="limits"><span class="limit">∑</span></span><i>α</i><sub><i>j</i>, <i>L</i></sub></span>
</div>
<div class="PlainVisible">
        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :
</div>
<div class="PlainVisible">
             <span class="formula"><i>γ</i><sub><i>j</i>, <i>t</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i>, <i>t</i></sub>⋅<i>β</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>Px</i></span><span class="ignored">)</span></span></span>
</div>
<div class="PlainVisible">
        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>l</i> = [1, ..., <i>k</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :
</div>
<div class="PlainVisible">
             <span class="formula"><i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>ψ</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>Px</i></span><span class="ignored">)</span></span></span>
</div>
<div class="PlainVisible">
        for <span class="formula"><i>j</i><sub>1</sub> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>j</i><sub>2</sub> = [1, ..., <i>m</i>]</span>, <span class="formula"><i>t</i> = [1, ..., <i>L</i>]</span> :
</div>
<div class="PlainVisible">
             <span class="formula"><i>ξ</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub>, <i>t</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>α</i><sub><i>j</i><sub>1</sub>, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i><sub>1</sub>, <i>j</i><sub>2</sub></sub>⋅<i>E</i><sub><i>j</i><sub>2</sub>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>⋅<i>β</i><sub><i>j</i><sub>2</sub>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>Px</i></span><span class="ignored">)</span></span></span>
</div>
<div class="PlainVisible">
        <i># M-step</i>
</div>
<div class="PlainVisible">
        for <span class="formula"><i>j</i> = [1, ..., <i>m</i>]</span>:
</div>
<div class="PlainVisible">
             <span class="formula"><i>π</i><sub><i>j</i></sub> = <i>γ</i><sub><i>j</i>, 1</sub></span>
</div>
<div class="PlainVisible">
            for <span class="formula"><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub> = [1, ..., 1]</span> <span class="formula">, ..., [4, ..., 4]</span>:
</div>
<div class="PlainVisible">
                 <span class="formula"><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, <i>b</i><sub>2</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>γ</i><sub><i>j</i>, <i>t</i></sub>⋅<b>1</b><sub><i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub>(<i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub>)</span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>t</i> ∈ <i>o</i>, ..., <i>L</i></sub><i>γ</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)</span></span></span>
</div>
<div class="PlainVisible">
            for  <span class="formula"><i>l</i> = [1, ..., <i>k</i>]:</span>
</div>
<div class="PlainVisible">
                 <span class="formula"><i>G</i><sub><i>j</i>, <i>l</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="unknown">\underset</span><i>t</i> ∈ 2, ..., <i>L</i><span class="limits"><span class="limit">∑</span></span><i>η</i><sub><i>j</i>, <i>l</i>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="unknown">\underset</span><i>t</i> ∈ 1, ..., <i>L</i> − 1<span class="limits"><span class="limit">∑</span></span><i>γ</i><sub><i>j</i><sub>1</sub>, <i>t</i></sub></span><span class="ignored">)</span></span></span>
</div>
<div class="PlainVisible">
            for <span class="formula"><i>j</i><sub>2</sub> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
                 <span class="formula"><i>T</i><sub><i>j</i>, <i>j</i><sub>2</sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><span class="unknown">\underset</span><i>t</i> ∈ 2, ..., <i>L</i><span class="limits"><span class="limit">∑</span></span><i>ξ</i><sub><i>j</i>, <i>j</i><sub>2</sub>, <i>t</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="unknown">\underset</span><i>t</i> ∈ 1, ..., <i>L</i> − 1<span class="limits"><span class="limit">∑</span></span><i>γ</i><sub><i>j</i>, <i>t</i></sub></span><span class="ignored">)</span></span></span>
</div>
<div class="PlainVisible">
        If <span class="formula"><i>θ</i></span> converged, break EM for loop 
</div>
<div class="PlainVisible">
    return <span class="formula"><i>θ</i></span>
</div>

</div>

</div>

</div>
<div class="Standard">
The algorithm is described with the input of a single sequence of observable variables <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span>. In reality, we are faced with the task of learning <span class="formula"><i>θ</i></span> from multiple sequences at once. In HOP-HMM we can use the multi-sequence method as in <span class="bibcites">[<a class="bibliocite" name="cite-51" href="#biblio-51">51</a>]</span>, where the E-step probabilities are calculated separately for each sequence, and in the M-step all positions from all sequences are summed for the parameters update.
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--10"></a>Sequence States Inference
</h3>
<div class="Standard">
Acquiring the maximal likelihood <span class="formula"><i>θ</i></span> opens the door to several wanted inferences given a sequence <span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> :
</div>
<ol>
<li>
Most likely hidden state at any position in a sequence
</li>
<li>
Most likely hidden state sequence
</li>
<li>
Dominant hidden state in a short sequence
</li>

</ol>
<div class="Standard">
<span class="formula"><i>γ</i></span> <a class="Reference" href="#HOP-gamma">(15↑)</a> and <span class="formula"><i>η</i></span> <a class="Reference" href="#HOP-eta">(17↑)</a> can be used to solve the inference 1 for HOP-HMM. We aim to maximize here a posterior probability in a specific position:
</div>
<div class="Standard">
<div class="formula">
<i>y</i><sub><i>t</i></sub><sup>*</sup> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>], <i>l</i> ∈ [<i>k</i>]∪{0}<i>argmax</i><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
In regular HMM, we can approximate this by taking the max of the posterior probability held in <span class="formula"><i>γ</i></span> <a class="Reference" href="#gamma">(9↑)</a> built by a <span class="formula"><i>θ</i></span> that we learned with the Baum-Welch algorithm. In HOP-HMM <span class="formula"><i>γ</i></span> <a class="Reference" href="#HOP-gamma">(15↑)</a> is not sufficient since it holds only the probability of background state <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span>. To calculate the posterior probability for TF states, <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> where <span class="formula"><i>l</i> &gt; 0</span> we sum all options of a TF state <span class="formula">(<i>j</i>, <i>l</i>)</span> that cover position <span class="formula"><i>t</i></span> as described in <a class="Reference" href="#PWM Posterior">(16↓)</a>. 
</div>
<div class="Standard">
<div class="formula">
<i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − <i>i</i> + 1:<i>t</i> − <i>i</i> + |<i>W</i><sub><i>l</i></sub>|</sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = 
</div>

</div>
<div class="Standard">
<div class="formula">
 = <span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i> − <i>i</i></sub> = (<i>j</i>, 0), <i>y</i><sub><i>t</i> − <i>i</i> + 1</sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span> = <span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>η</i><sub><i>t</i> − <i>i</i> + 1, <i>j</i>, <i>l</i></sub>
</div>

</div>
<div class="Standard">
Choosing the maximum value over <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>l</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> and <span class="formula"><i>P</i><sub><i>θ</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, 0)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> will give us the most likely state of <span class="formula"><i>ŷ</i><sub><i>t</i></sub></span>:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="PosteriorEstimation">(18) </a><i>ŷ</i><sub><i>t</i></sub> = <span class="unknown">\underset</span><i>j</i> ∈ [<i>m</i>], <i>l</i> ∈ [<i>k</i>]∪{0}<i>argmax</i><i>γ</i><sub><i>j</i>, <i>t</i></sub>∪<span class="limits"><span class="limit">∑</span></span><sub><i>i</i> ∈ <span class="symbol">[</span>|<i>W</i><sub><i>l</i></sub>|<span class="symbol">]</span></sub><i>η</i><sub><i>t</i> − <i>i</i> + 1, <i>j</i>, <i>l</i></sub>
</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="PWM Posterior"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/PWM_posterior_2.jpg" alt="figure Figures/PWM_posterior_2.jpg">
<div class="caption">
Figure 16 <span class="formula"><i>P</i><span class="symbol">(</span><i>y</i><sub><i>t</i></sub> = (<i>j</i>, <i>t</i>)|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> is the posterior probability to be in TF state <span class="formula">(<i>j</i>, <i>l</i>)</span> at position <span class="formula"><i>t</i></span>, marked in dark green. It is equal to the sum of probabilities of entering into the TF state before position <span class="formula"><i>y</i><sub><i>t</i></sub></span>. In this example, <span class="formula"><i>W</i><sub><i>l</i></sub></span> is a PWM of length 5, therefore it has 5 different possible positions that include <span class="formula"><i>y</i><sub><i>t</i></sub></span> that are summed, marked in light green.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
Inference 2 aims for reaching the most likely hidden sequence:
</div>
<div class="Standard">
<div class="formula">
<a class="eqnumber" name="Viterbi">(19) </a><i>y</i><sub>1:<i>L</i></sub><sup>*</sup> = <i>argmax</i><sub><i>y</i><sub>1:<i>L</i></sub></sub><i>P</i><span class="symbol">(</span><i>y</i><sub>1:<i>L</i></sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span>
</div>

</div>
<div class="Standard">
The main difference between inference 1 is the consideration to the dependency between adjacent states. In inference 1, for example, two adjacent positions may been individually inferred states which the transition probability between them equals 0. Even though each hidden state maximizes the likelihood at its position, as a sequence when accounting for the transitions the result might not be the same states.
</div>
<h3 class="Subsubsection-">
<a class="toc" name="toc-Subsubsection--11"></a>HOP-Viterbi Algorithm
</h3>
<div class="Standard">
In HMM, deriving the maximal likelihood hidden sequence of <a class="Reference" href="#Viterbi">(19↑)</a> is done by the Viterbi algorithm, named after Andrew Viterbi who proposed it in <span class="bibcites">[<a class="bibliocite" name="cite-65" href="#biblio-65">65</a>]</span>. Viterbi algorithm resembles the Forward algorithm, with the two main differences:
</div>
<ol>
<li>
Maximization replaces the summation over the possible transitions.
</li>
<li>
Traces of the maximal value chosen in the dynamic filling are kept in <span class="formula"><i>V</i><sup>2</sup></span>, which used to back-trace the chosen state path at the end.
</li>

</ol>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-6"> </a><div class="algorithm">
<div class="caption">
Algorithm 6 Viterbi Algorithm
</div>
<b>Input:</b>    <span class="formula"><i>θ</i></span>- HMM parameters <span class="formula">{<i>π</i>, <i>T</i>, <i>E</i>}</span><div class="PlainVisible">
    \strikeout off\uuline off\uwave off<span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> - Observed DNA sequence
</div>
<b>Algorithm:</b>    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span><div class="PlainVisible">
        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>1</sup> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span>
</div>
<div class="PlainVisible">
        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>2</sup> = 0</span>
</div>
<div class="PlainVisible">
    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]</span>:
</div>
<div class="PlainVisible">
        \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>1</sup> = <i>max</i><sub><i>j</i>’ ∈ [<i>m</i>]</sub><span class="symbol">(</span><i>V</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub><span class="symbol">)</span></span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>2</sup> = <i>argmax</i><sub><i>j</i>’ ∈ [<i>m</i>]</sub><span class="symbol">(</span><i>V</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i></sub></sub><span class="symbol">)</span></span>
</div>
<div class="PlainVisible">
    <i># back tracing</i>
</div>
<div class="PlainVisible">
     <span class="formula"><i>ŷ</i><sub><i>L</i></sub> = <i>argmax</i><sub><i>j</i></sub><i>V</i><sub><i>j</i>, <i>L</i></sub><sup>1</sup></span>
</div>
<div class="PlainVisible">
    \strikeout off\uuline off\uwave offfor <span class="formula"><i>t</i> = [<i>L</i>, ..., 2]</span>:
</div>
<div class="PlainVisible">
        <span class="formula"><i>ŷ</i><sub><i>t</i> − 1</sub> = <i>V</i><sub><i>y</i><sub><i>t</i></sub>, <i>t</i></sub><sup>2</sup></span>
</div>
<div class="PlainVisible">
    return <span class="formula"><i>ŷ</i><sub>1:<i>L</i></sub></span>
</div>

</div>

</div>

</div>
<div class="Standard">
For HOP-HMM the Viterbi algorithm is adapted into a HOP-Viterbi algorithm, in two manners:
</div>
<ul>
<li>
Maximization is done over two types of state transition probabilities: background to background and background to TF, held in A and B vectors.
</li>
<li>
The traces held in <span class="formula"><i>V</i><sup>2</sup></span> tables are two indices, since states in HOP-HMM are described by two indices.
</li>

</ul>
<div class="Standard">
<div class="float">
<a class="Label" name="Algorithm-7"> </a><div class="algorithm">
<div class="caption">
Algorithm 7 HOP-Viterbi Algorithm
</div>
<b>Input:</b>    <span class="formula"><i>θ</i></span>- HOP-HMM parameters <span class="formula">{<i>π</i>, <i>T</i>, <i>G</i>, <i>E</i>}</span><div class="PlainVisible">
    \strikeout off\uuline off\uwave off<span class="formula"><i>x</i><sub>1:<i>L</i></sub></span> - Observed DNA sequence
</div>
<b>Algorithm:</b>    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span><div class="PlainVisible">
        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>1</sup> = <i>π</i><sub><i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub>1</sub></sub></span>
</div>
<div class="PlainVisible">
        <span class="formula"><i>V</i><sub><i>j</i>, 1</sub><sup>2</sup> = 0</span>
</div>
<div class="PlainVisible">
    \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>t</i> = [2, ..., <i>L</i>]</span>:
</div>
<div class="PlainVisible">
        \strikeout off\uuline off\uwave off <span class="formula"><i>for</i> <i>j</i> = [1, ..., <i>m</i>]:</span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>A</i> = <span class="symbol">{</span><i>V</i><sub><i>j</i>’, <i>t</i> − 1</sub>⋅<i>T</i><sub><i>j</i>’, <i>j</i></sub>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>|<i>j</i>’ ∈ [<i>m</i>]<span class="symbol">}</span></span><i> # background state to background state</i>
</div>
<div class="PlainVisible">
             <span class="formula"><i>B</i> = <span class="symbol">{</span><i>V</i><sub><i>j</i>, <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub>⋅<i>G</i><sub><i>j</i>, <i>l</i></sub>⋅<i>L</i><sub><i>W</i><sub><i>l</i></sub></sub><span class="symbol">(</span><i>x</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|</sub>, ..., <i>x</i><sub><i>t</i> − 1</sub><span class="symbol">)</span>⋅<i>E</i><sub><i>j</i>, <i>x</i><sub><i>t</i> − <i>o</i> + 1</sub>, ..., <i>x</i><sub><i>t</i></sub></sub>|<i>l</i> ∈ [<i>k</i>]<span class="symbol">}</span></span> <i># background state to TF state</i>
</div>
<div class="PlainVisible">
             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>1</sup> = <i>max</i><span class="symbol">(</span><i>A</i>∪<i>B</i><span class="symbol">)</span></span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>V</i><sub><i>j</i>, <i>t</i></sub><sup>2</sup> = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
<span class="symbol">(</span><i>argmax</i>(<i>A</i>), 0<span class="symbol">)</span> 
</span>
<span class="case align-l">
<span class="ensuremath"><i>max</i>(<i>A</i>) &gt; <i>max</i>(<i>B</i>)</span> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
<span class="symbol">(</span><i>j</i>, <i>argmax</i>(<i>B</i>)<span class="symbol">)</span> 
</span>
<span class="case align-l">
<i>otherwise</i> 
</span>

</span>

</span>
</span>
</div>
<div class="PlainVisible">
     <span class="formula"><i>ŷ</i><sub><i>L</i></sub> = <span class="symbol">(</span><i>argmax</i><sub><i>j</i></sub><i>V</i><sub><i>j</i>, <i>L</i></sub><sup>1</sup>, 0<span class="symbol">)</span></span> <i># mandatory background state at the end of the sequence</i>
</div>
<div class="PlainVisible">
    \strikeout off\uuline off\uwave off<span class="formula"><i>t</i> = <i>L</i></span>
</div>
<div class="PlainVisible">
    \strikeout off\uuline off\uwave offwhile <span class="formula"><i>t</i> &gt; 1</span>:
</div>
<div class="PlainVisible">
         <span class="formula"><span class="symbol">(</span><i>j</i>, <i>l</i><span class="symbol">)</span> = <i>V</i><sub><i>y</i><sub><i>t</i></sub>[0], <i>t</i></sub><sup>2</sup></span>
</div>
<div class="PlainVisible">
        if <span class="formula"><i>l</i> = 0:</span><i> # if <span class="formula"><i>l</i> = 0</span> the hidden state at <span class="formula"><i>t</i> − 1</span> is a background state</i>
</div>
<div class="PlainVisible">
             <span class="formula"><i>ŷ</i><sub><i>t</i> − 1</sub> = <span class="symbol">(</span><i>j</i>, 0<span class="symbol">)</span></span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>t</i> = <i>t</i> − 1</span>
</div>
<div class="PlainVisible">
        else:
</div>
<div class="PlainVisible">
             <span class="formula"><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>|:<i>t</i> − 1</sub> = <span class="symbol">(</span><i>j</i>, <i>l</i><span class="symbol">)</span></span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>y</i><sub><i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</sub> = <i>y</i><sub><i>t</i></sub></span>
</div>
<div class="PlainVisible">
             <span class="formula"><i>t</i> = <i>t</i> − |<i>W</i><sub><i>l</i></sub>| − 1</span>
</div>
<div class="PlainVisible">
    return <span class="formula"><i>ŷ</i><sub>1:<i>L</i></sub></span>
</div>

</div>

</div>

</div>
<div class="Standard">
Using the Viterbi state path, we can make a simplistic classifications of short DNA sequences by their dominant state. This simple classification made by choosing the most repeating state in the estimated Viterbi state path <span class="formula"><i>y</i><sub>1:<i>L</i></sub>:</span>
</div>
<div class="Standard">
<div class="formula">
<i>y</i><sub><i>class</i></sub> = <i>mode</i><sub><i>t</i> ∈ [<i>L</i>]</sub><i>y</i><sub><i>t</i></sub>
</div>

</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--4"></a>Results
</h1>
<div class="Standard">
For evaluating HOP-HMM, we first measure its capabilities on synthetic DNA data that was created in a controlled way. Afterwards, we see how does a HOP-HMM classify real human DNA sequences. The evaluation process on synthetic data is done by the following steps (see figure <a class="Reference" href="#Workflow">17↓</a>):
</div>
<ol>
<li>
We generate parameters for a HOP-HMM <span class="formula"><i>θ</i></span>, which are treated as the true <span class="formula"><i>θ</i></span>. <span class="formula"><i>θ</i></span> is sampled in the following way:<ol>
<li>
Each cell T is sampled from the uniform distribution <div class="formula">
<a class="eqnumber" name="minTmaxT">(20) </a><i>T</i><sub><i>i</i>, <i>j</i></sub> ~ <i>U</i><span class="symbol">(</span><i>minT</i><sub><i>i</i>, <i>j</i></sub>, <i>maxT</i><sub><i>i</i>, <i>j</i></sub><span class="symbol">)</span>
</div>

</li>
<li>
Each cell <span class="formula"><i>G</i><sub><i>i</i>, <i>j</i></sub></span> is sampled from a uniform and a Bernoulli distribution <div class="formula">
<a class="eqnumber" name="noiseG">(21) </a><i>G</i><sub><i>i</i>, <i>j</i></sub> ~ <i>U</i><span class="symbol">(</span><i>minG</i>, <i>noiseG</i><span class="symbol">)</span> + <b>1</b><sub><span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span> ∈ <i>Reg</i></sub>⋅<i>Bern</i><span class="symbol">(</span><span class="fraction"><span class="ignored">(</span><span class="numerator"><i>k</i></span><span class="ignored">)/(</span><span class="denominator"><i>m</i></span><span class="ignored">)</span></span><span class="symbol">)</span>⋅<i>maxG</i>
</div>
<div class="Standard">
where <div class="formula">
<b>1</b><sub><span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span> ∈ <i>ENH</i></sub> = <span class="array"><span class="arrayrow"><span class="bracket align-l">⎧</span></span><span class="arrayrow"><span class="bracket align-l">⎨</span></span><span class="arrayrow"><span class="bracket align-l">⎩</span></span></span><span class="bracketcases">
<span class="arrayrow">
<span class="case align-l">
1 
</span>
<span class="case align-l">
<span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span> ∈ <i>ENH</i> 
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
  
</span>
<span class="case align-l">
  
</span>

</span>
<span class="arrayrow">
<span class="case align-l">
0 
</span>
<span class="case align-l">
<i>otherwise</i> 
</span>

</span>

</span>

</div>
<span class="formula"><i>ENH</i></span> is the set of &ldquo;enhancer-mimicking&rdquo; background states, which are predefined background states that have high probability of transitioning into TF state. The rest of the background states will have low probability to create TFBS, aiming to model the non-regulatory regions of the DNA with sparse TFBSs. In our experiments <span class="formula"><i>ENH</i></span> contained all but one state: <span class="formula"><span class="symbol">(</span><i>m</i>, 0<span class="symbol">)</span></span> meaning only one background state had almost no TFBS and the rest <span class="formula"><i>m</i> − 1</span> background states did have TFBSs.
</div>

</li>
<li>
After being sampled, T and G are divided element-wise by their rows sum so their rows together become distributions:<div class="Standard">
<div class="formula">
<a class="eqnumber" name="GT_normalization">(22) </a><span class="environment"><span class="arrayrow">
<span class="arraycell align-r">
<i>T</i><sub><i>i</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>T</i><sub><i>i</i>, <i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>i</i>, <i>j</i>’</sub> + <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>k</i>]</sub><i>G</i><sub><i>i</i>, <i>j</i>’</sub></span><span class="ignored">)</span></span>
</span>
<span class="arraycell align-l">

</span>
<span class="arraycell align-r">
<i>G</i><sub><i>i</i>, <i>j</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>G</i><sub><i>i</i>, <i>j</i></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>m</i>]</sub><i>T</i><sub><i>i</i>, <i>j</i>’</sub> + <span class="limits"><span class="limit">∑</span></span><sub><i>j</i>’ ∈ [<i>k</i>]</sub><i>G</i><sub><i>i</i>, <i>j</i>’</sub></span><span class="ignored">)</span></span>
</span>

</span>
</span>
</div>

</div>

</li>
<li>
E is sampled from a uniform distribution <span class="formula"><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> ~ <i>U</i><span class="symbol">(</span>0, 1<span class="symbol">)</span></span> and divided by the sum of its last index to become a distribution array, similar to (c):<div class="formula">
<i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i></sub></sub></span><span class="ignored">)/(</span><span class="denominator"><span class="limits"><span class="limit">∑</span></span><sub><i>b</i>’ = [4]</sub><i>E</i><sub><i>j</i>, <i>b</i><sub>1</sub>, ..., <i>b</i><sub><i>o</i> − 1</sub>, <i>b</i>’</sub></span><span class="ignored">)</span></span>
</div>

</li>
<li>
The start state distribution <span class="formula"><i>π</i></span> is non-random, and set so the first states are always one of the non-enhancer background states: <div class="formula">
<i>π</i><sub><i>i</i></sub> = <span class="fraction"><span class="ignored">(</span><span class="numerator"><b>1</b><sub><span class="symbol">(</span><i>i</i>, 0<span class="symbol">)</span>∉<i>ENH</i></sub></span><span class="ignored">)/(</span><span class="denominator"><i>m</i> − |<i>ENH</i>|</span><span class="ignored">)</span></span>
</div>

</li>

</ol>

</li>
<li>
Sequences are generated using the HOP-HMMs with the true <span class="formula"><i>θ</i></span>. Both the observed and the hidden sequences are used, denoted <span class="formula"><i>X</i></span> and <span class="formula"><i>Y</i></span>. We split the <span class="formula"><i>X</i></span> and <span class="formula"><i>Y</i></span> sequences into train and test for cross validation. 
</li>
<li>
From the DNA sequences of <span class="formula"><i>X</i></span> train, we train a <span class="formula"><i>θ̂</i></span> with the HOP Baum-Welch algorithm.
</li>
<li>
Using the trained parameters <span class="formula"><i>θ̂</i></span>, we estimate <span class="formula"><i>Ŷ</i></span> test from <span class="formula"><i>X</i></span> test and <span class="formula"><i>Ŷ</i></span> train from <span class="formula"><i>X</i></span> train by the HOP-Viterbi algorithm. We also calculate the posterior probability of <span class="formula"><i>P</i><sub><i>θ̂</i></sub><span class="symbol">(</span><i>y</i><sub><i>t</i></sub>|<i>x</i><sub>1:<i>L</i></sub><span class="symbol">)</span></span> from <span class="formula"><i>X</i></span> test and <span class="formula"><i>X</i></span> train. These results are then compared to the real <span class="formula"><i>Y</i></span> test and <span class="formula"><i>Y</i></span> train for accuracy measuring.
</li>

</ol>
<div class="Standard">
<div class="float">
<a class="Label" name="Workflow"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/Workflow.jpg" alt="figure Figures/Workflow.jpg">
<div class="caption">
Figure 17 Workflow of the evaluation process. A <span class="formula"><i>θ</i></span> is sampled and a HOP-HMM model is created with which several fixed-length sequences are generated. A new model <span class="formula"><i>θ̂</i></span> is then fitted to the train section of the observed sequences, via HOP-Baum-Welch algorithm. With <span class="formula"><i>θ̂</i>, </span> a hidden sequence is then estimated by the HOP-Viterbi algorithm, and a posterior probability estimation is calculated by <a class="Reference" href="#PosteriorEstimation">(18↑)</a>.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
The Baum-Welch algorithm is guaranteed to increase the likelihood in each step, however it is not guaranteed to converge to the optimal <span class="formula"><i>θ</i><sup>*</sup></span> (<span class="bibcites">[<a class="bibliocite" name="cite-51" href="#biblio-51">51</a>]</span>) as there is no known analytical way for reaching it. As a consequence, Baum-Welch algorithm converges into a local maximum <span class="formula"><i>θ̂</i></span> which could be a relatively low likelihood estimation, depending on the initialization point of the first <span class="formula"><i>θ</i></span>. The local maximum convergence issue is addressed in two ways:
</div>
<div class="Standard">
1. We use regularization for faster and to a better <span class="formula"><i>θ̂</i></span> convergence (see figure <a class="Reference" href="#Regularization">19↓</a>). Following each M-step update we draw the background states transition probabilities <span class="formula"><i>T</i></span> to remain between <span class="formula"><i>maxT</i></span> and <span class="formula"><i>minT</i></span> matrices from <a class="Reference" href="#minTmaxT">(20↑)</a>:
</div>
<ul>
<li>
If <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> &lt; <i>minT</i><sub><i>i</i>, <i>j</i></sub></span> then we set <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> = <i>minT</i><sub><i>i</i>, <i>j</i></sub></span>
</li>
<li>
If <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> &gt; <i>maxT</i><sub><i>i</i>, <i>j</i></sub></span> then we set <span class="formula"><i>T</i><sub><i>i</i>, <i>j</i></sub> = <i>maxT</i><sub><i>i</i>, <i>j</i></sub></span>
</li>
<li>
T and G are divided by their row sum so their rows together remain a distribution as in <a class="Reference" href="#GT_normalization">(22↑)</a>
</li>

</ul>
<div class="Standard">
2. Since Baum-Welch seek local maximum, running it multiple times with different initializations will cause convergence into different <span class="formula"><i>θ̂</i></span> results. As could be expected, we observed throughout multiple initializations that the higher the log likelihood of final <span class="formula"><i>θ̂</i></span> the lower its root mean square error (RMSE) compared to the true <span class="formula"><i>θ</i></span> (see figure <a class="Reference" href="#LikelihoodVsErr">18↓</a>). This is important since on real observed sequences, only the estimated <span class="formula"><i>θ̂</i></span> likelihood is known while the true <span class="formula"><i>θ</i></span> is unknown. This correlation implies that for an estimation <span class="formula"><i>θ̂</i></span> that closer to the true <span class="formula"><i>θ</i></span>, one should redo several EM runs and choose the <span class="formula"><i>θ̂</i></span> with the highest likelihood.
</div>
<div class="Standard">
<div class="float">
<a class="Label" name="LikelihoodVsErr"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg" alt="figure Figures/rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg">
<div class="caption">
Figure 18 Over multiple runs of HOP-Baum-Welch, higher the sequences likelihood for the estimated <span class="formula"><i>θ</i></span> resulted in lower errors compared to the true <span class="formula"><i>θ</i></span>. 
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
<p><br>
</p>
<div class="float">
<a class="Label" name="Regularization"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/dec_likelihood.jpg" alt="figure Figures/dec_likelihood.jpg">

</div>
<div class="PlainVisible">
<div class="center">
<img class="embedded" src="Figures/dec_theta_error.jpg" alt="figure Figures/dec_theta_error.jpg">

</div>

</div>
<div class="PlainVisible">
<div class="center">
<img class="embedded" src="Figures/dec_theta_error_scatter.jpg" alt="figure Figures/dec_theta_error_scatter.jpg">

</div>

</div>
<div class="PlainVisible">
<div class="center">
<img class="embedded" src="Figures/dec_viterbi.jpg" alt="figure Figures/dec_viterbi.jpg">
<div class="caption">
Figure 19 <b>A)</b> The EM iterations draws the estimated <span class="formula"><i>θ</i></span> values mostly closer to the values of the true <span class="formula"><i>θ</i></span>. <b>B)</b> The error between the true and estimated <span class="formula"><i>θ</i></span> decrease, and after a few iterations converge to the same path regardless of the initialization. <b>C)</b> During the EM iterations, the learned <span class="formula"><i>θ</i></span> yields a more accurate Viterbi estimation of the hidden states. Note that not even the true <span class="formula"><i>θ</i></span> could produce Viterbi paths that is a perfect match to the true hidden sequences. <b>D)</b> The mean log likelihood of the sequences increases during the EM iterations. The experiment was done on 500 synthetic sequences (85% train, 15% test), 1000 long. The trained model had 6 hidden background states with emission order of 2, each background state had 25 TF states.
</div>

</div>

</div>

</div>

</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="PostiriorProbability"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/synthetic_posterior_with_tfs.jpg" alt="figure Figures/synthetic_posterior_with_tfs.jpg">
<div class="caption">
Figure 20 Posterior probability of sequences, estimated by a trained HOP-HMM <span class="formula"><i>θ̂</i></span> on test sequences that were synthetically generated by a HOP-HMM <span class="formula"><i>θ</i></span>. At the bottom of each posterior probability, there are the Viterbi hidden path by <span class="formula"><i>θ̂</i></span> and the true hidden states of each sequence. The black TFBS is the sum of all the probabilities of being in any of the TF states.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="ConfutionMatrix"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/confusion_matrix.jpg" alt="figure Figures/confusion_matrix.jpg">
<div class="caption">
Figure 21 Confusion matrix of true and estimated states by the Viterbi algorithm of HOP-HMM synthetic sequences. Rows are normalized so their sum is equal to 1. The majority of prediction are in the background states <span class="formula">(1, 0)</span>, <span class="formula">(2, 0)</span>, <span class="formula">(3, 0)</span>, <span class="formula">(4, 0)</span> and <span class="formula">(5, 0)</span>, where TF states are sometimes misclassified as their background state state.
</div>

</div>

</div>

</div>

</div>
<div class="Standard">
For testing of HOP-HMM on human genetic data, we manipulated the used the Roadmap project Bed files with BEDTools (<span class="bibcites">[<a class="bibliocite" name="cite-49" href="#biblio-49">49</a>]</span>). We created a dataset of enhancer sequences around the intersection of DNase-I, H3K27ac and H3K4me1 peaks, while avoiding peaks of H3K27me3 and H3K4me3 and sequences within 5000bp from known genes. Sequences were chosen 5000bp long sequences centered around their DNase-I peaks.
</div>
<div class="Standard">
We wanted to evaluate if HOP-HMM can distinguish and detect enhancers active in two human tissues. For this we’ve built a set of 4000 bp fixed length sequences from the HG19 in positions which were labeled as enhancers based on epigenetic data collected by Roadmap project from 57 tissues. Out of these enhancers, we chose only sequences of tissue-specific enhancers in one of two types of tissues, and not in the rest of the 57 tissues. We’ve added sequences with no known role, from random locations in the genome distal from genes or enhancers as background sequences. 
</div>
<div class="Standard">
A HOP-HMM is trained by the HOP-Baum-Welch algorithm on the collected sequences. The trained model is then used to produce a Viterbi estimated hidden states sequence and posterior probability, which can then be compared to the epigenetic tracks.
</div>
<div class="Standard">
For the set of PWMs used by the TF states of the HOP-HMM, we used JASPAR dataset of 519 vertebrates PWMs, out of which we selected 50 PWMs for a practical run-time. The selected PWMs are chosen by 3 methods, each method responsible for a third of the 50:
</div>
<ul>
<li>
PWMs of TFs which were relatively expressed in one tissue compared to the other, according to the Roadmap RNA-seq data. This method does not depend on the sequences themselves, but on epigenetic properties of the tissues.
</li>
<li>
PWMs which are abundant in the sequences, i.e. PWMs with the highest mean likelihood to attach to the sequences. The likelihood of PWM <span class="formula"><i>W</i></span> to bind to a sequence <span class="formula"><i>x</i></span> is calculated as described mean is the average of 3 highest likelihood TFBS as described in figure <a class="Reference" href="#PWM">3↑</a>. Note that here we use the PWM form as in <a class="Reference" href="#PPM">(1↑)</a> and not the PPM form for comparison between PWM likelihoods.
</li>
<li>
PWMs that had strong presence in sequences from one tissue compared to the other. Specifically, the PWMs with sequence binding likelihood (as defined in the previous method) that can best distinguish between sequences from one tissue and the rest of the sequences in terms of AUC-ROC.
</li>

</ul>
<div class="Standard">
In our experiment, some sequences resulted posterior probability had good resemblance to the DNase-seq track, causing a good overlap between the Viterbi-path and the ChromeHMM classifications (see figure <a class="Reference" href="#fig:RealSequences">22↓</a>), though this similarity was not always occurring. 
</div>
<div class="Standard">
<p><br>
</p>

</div>
<div class="Standard">
<div class="float">
<a class="Label" name="fig:RealSequences"> </a><div class="figure">
<div class="center">
<img class="embedded" src="Figures/realSeq1.jpg" alt="figure Figures/realSeq1.jpg">

</div>
<div class="PlainVisible">
<div class="center">
<img class="embedded" src="Figures/realSeq2.jpg" alt="figure Figures/realSeq2.jpg">

</div>

</div>
<div class="PlainVisible">
<div class="center">
<img class="embedded" src="Figures/realSeq3.jpg" alt="figure Figures/realSeq3.jpg">

</div>

</div>
<div class="PlainVisible">
<div class="center">
<img class="embedded" src="Figures/realSeqLegend.jpg" alt="figure Figures/realSeqLegend.jpg">
<div class="caption">
Figure 22 Examples of HOP-HMM classification of 5000pb long tissue specific enhancer sequences from the human genome. Each of the 3 graphs is the output of a different HOP-HMM with three background states (two enhancer states and one non-enhancer state) and 50 TF states, each was trained on enhancers from the two tissues. The H3K27ac and DNase-I measurements are in <span class="formula"> − <i>log</i><sub>10</sub>(<i>p</i> − <i>value</i>)</span> units.
</div>

</div>

</div>

</div>

</div>

</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--5"></a>Discussion and Conclusions
</h1>
<div class="Standard">
In this work I have aimed to develop a generalized HMM, HOP-HMM, tailored for the enhancer structure. I developed the mathematical adjustments to the different parts of the EM algorithm and provided and reasoning for the correctness of the inferring of the altered model from data. For evaluation on real and synthetic data as described in the results, I implemented the model and the algorithm in Matlab code. During the algorithm implementation, I overcame a few difficulties that origin from the scale of the data, such as caching the costly response of the PWMs to the sequences during the Forward Backward algorithms, and splitting to sequences into batches for holding and manipulating the large <span class="formula"><i>η</i></span> <a class="Reference" href="#HOP-eta">(17↑)</a> matrix in memory. The implementation also includes the generation code for DNA sequences from a randomly selected HOP-HMM to which a different model can be fitted and compared. Naturally, in the synthetic data experiment, the more generated data is used to fit the model, the better the fitting performs. During the evaluation of the inference EM algorithm, many runs tend to overshoot the inter-states transition probability, resulting in a tendency for irregular Viterbi paths with frequent state changes. This resembles the known issue of HMM parameter overfitting on small training data. I therefore introduced a regularization technique that had a significant positive impact on the convergence rate and solution quality. Overall, the generated DNA sequences experiment results were positive and are evidence for the ability of the algorithm to train successfully on DNA sequences created under the HOP-HMM assumptions.
</div>
<div class="Standard">
For applying the EM algorithm on real data, I designed a simplistic challenge of correctly recognizing enhancers where their true locations are known from epigenetic experiments. This challenge first required building a dataset of sequences containing tissue-specific enhancers from two tissues together with wide margins, and non-regulatory &ldquo;background&rdquo; sequences. When choosing the tissue-specific enhancers from the epigenetic data provided by the Roadmap project, the noisiness of the data should be considered. After some trail and error, I chose the somewhat arbitrary cutoff of the top 40% strongest DNase-seq peaks, which yielded enough sequences (around 500 sequences per tissue on average) with distinguishable distributions between the tissues.
</div>
<div class="Standard">
Though many real DNA sequences were correctly classified, some tissues caused the EM algorithm to consistently converge to parameters which gave mostly wrong Viterbi path classifications. This could stem from several reasons: wrong PWMs selection as hyperparameters, too small or noisy dataset building from the Roadmap data and a more complex structure than assumed by the HOP-HMM hypothesis. In further research, usage of updated data with cleaner more tissue-diverse experiments would likely provide better results. As a computational approach to improve the generalized HMM used in this work is to introduce learning of the PWMs preceding or during the EM iterations, or to replace the PWMs emission entirely by a different TFBS modeling method.
</div>
<div class="Standard">
<p><br>
</p>

</div>
<h1 class="Section-">
<a class="toc" name="toc-Section--6"></a>Appendix: Source Code
</h1>
<div class="Standard">
The code for this research was written in Matlab, and can be found in <a class="FlexURL" href="https://github.com/David-Taub/HOP-HMM">https://github.com/David-Taub/HOP-HMM</a>.
</div>
<div class="Standard">
<table>
<tr>
<td align="left" valign="top">
Variable
</td>
<td align="left" valign="top" style="width: 10cm;">
Meaning
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span class="code"><div class="PlainVisible">
L
</div>
</span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
DNA sequences length
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span class="code"><div class="PlainVisible">
N
</div>
</span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
Number of DNA sequences
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span class="code"><div class="PlainVisible">
m
</div>
</span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
Number of background states
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span class="code"><div class="PlainVisible">
k
</div>
</span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
Number of TF states of each background state
</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span class="code"><div class="PlainVisible">
order
</div>
</span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;">
<div class="PlainVisible">
Dependency order of the emission of the background states done by <span class="formula"><i>E</i></span>. For example, if <span class="code"><div class="PlainVisible">
order
</div>
</span> equals 3, then the emission is conditional on 2 previous observable variables. 
</div>

</td>

</tr>
<tr>
<td align="left" valign="top">
<div class="PlainVisible">
<span class="code"><div class="PlainVisible">
backgroundAmount
</div>
</span>
</div>

</td>
<td align="left" valign="top" style="width: 10cm;" colspan="1">
Number of background states which are non-enhancers by having low transition probability into TF states
</td>

</tr>

</table>

</div>
<div class="Standard">
The prominent code files in the project:
</div>
<ul>
<li>
<b>HOP-HMM/data/peaks/scripts/download_and_process_all.sh</b><div class="Standard">
Linux bash script which downloads data files of epigenetic from Roadmap website, JASPAR PWMs and hg19 genome. After downloading, the data is per-processed with Bedtools and bigWigToBedGraph. The only part in this project that requires Linux is the bigWigToBedGraph.
</div>

</li>
<li>
<b>HOP-HMM/src/+peaks/minimizeMergePeak.m</b><div class="Standard">
Reads downloaded bed files, process them and saves them into MAT-file v7.3. 
</div>
<blockquote class="Quote">
<span class="code">params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound); </span>
</blockquote>
<blockquote class="Quote">
<span class="code">mergedPeaksMin = minimizeMergePeak(params, L)</span>;
</blockquote>
<div class="Standard">
where <span class="code">doGTBound</span> indicates whether or not to apply regularization on T and G transition probabilities and <span class="code">doESharing</span> indicates whether or not to force <span class="formula"><i>E</i></span> to share the emission across all background states 
</div>

</li>
<li>
<b>HOP-HMM/src/misc/genSyntheticMergedPeaksMin.m</b><div class="Standard">
Generates DNA sequences <span class="formula"><i>X</i></span> and hidden variables <span class="formula"><i>Y</i></span> out of a random <span class="formula"><i>θ</i></span>, which was sampled by genTheta.m
</div>
<blockquote class="Quote">
<span class="code">params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);</span> <span class="code">mergedPeaksMin = genSyntheticMergedPeaksMin(N, L, params, startWithBackground, backgroundGNoise);</span>
</blockquote>
<div class="Standard">
where <span class="code">startWithBackground</span> indicates whether or not to force <span class="formula"><i>π</i></span> to allow starting only from non-enhancer background states and <span class="code">backgroundGNoise</span> is the background rate of background state to TF state transition, marked as <span class="formula"><i>noiseG</i></span> in <a class="Reference" href="#noiseG">(21↑)</a>
</div>

</li>
<li>
<b>HOP-HMM/src/misc/genTheta.m</b><div class="Standard">
Generates a random <span class="formula"><i>θ</i></span>, with options to sample a total random <span class="formula"><i>T</i></span> and a total random <span class="formula"><i>π</i></span>. Note that <span class="formula"><i>π</i></span> is called <span class="code">theta.startT</span> throughout the code.
</div>
<blockquote class="Quote">
<span class="code">params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound); </span>
</blockquote>
<blockquote class="Quote">
<span class="code">theta = genTheta(params, false, false);</span>
</blockquote>

</li>
<li>
<b>HOP-HMM/src/mainRealData.m</b><div class="Standard">
Entry point of the code, reads data from human genome, trains HOP-HMMs model and compares posterior probability to real epigenetic data. Execution of mainRealData will produce figures similar to figure <a class="Reference" href="#RealData">↓</a>
</div>
<blockquote class="Quote">
<span class="code">mainRealData();</span>
</blockquote>

</li>
<li>
<b>HOP-HMM/src/mainPosterior.m</b><div class="Standard">
Entry point of the code, follows the workflow of figure <a class="Reference" href="#Workflow">17↑</a>. Execution of mainPosterior plots random set of sequences with their Viterbi sequence and posterior probabilities similar to figure <a class="Reference" href="#PostiriorProbability">20↑</a> and a confusion matrix similar to figure <a class="Reference" href="#ConfutionMatrix">21↑</a>.
</div>
<blockquote class="Quote">
<span class="code">mainPosterior();</span>
</blockquote>

</li>
<li>
<b>HOP-HMM/src/mainDecErrorPlot.m</b><div class="Standard">
Entry point of the code, follows the workflow of figure <a class="Reference" href="#Workflow">17↑</a>, and at each iteration of the EM, likelihood and errors are collected to form plots similar to figure <a class="Reference" href="#Regularization">19↑</a>.
</div>
<blockquote class="Quote">
<span class="code">mainDecErrorPlot();</span>
</blockquote>

</li>
<li>
<b>HOP-HMM/src/+EM/EM.m</b><div class="Standard">
The function actually trains the HOP-HMM model from a given DNA sequence is the EM(). The neighboring code files residing in the +EM folder which contains it, are the implementations of the E and M steps described in the introduction part of this work.
</div>
<blockquote class="Quote">
<span class="code">[test, train] = misc.crossValidationSplit(params, mergedPeaksMin, testTrainRatio);</span>
</blockquote>
<blockquote class="Quote">
<span class="code">[bestTheta, bestLikelihood, bestThetas] = EM(train, params, maxIter, patience, repeat);</span>
</blockquote>
<div class="Standard">
where <span class="code">maxIter</span> is the maximal number of iterations allowed in a run, <span class="code">parience</span> is the number of iterations without likelihood increase that are allowed in a run and <span class="code">repeat</span> is the number of different runs with different initializations that are tried.
</div>

</li>

</ul>
<div class="Standard">
<p><br>
</p>

</div>
<a class="toc" name="References"></a><h1 class="biblio">
References
</h1>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-1">1</a>] </span> Ahituv, N., Zhu, Y., Visel, A., Holt, A., Afzal, V., Pennacchio, L. A., &amp; Rubin, E. M. (2007). Deletion of ultraconserved elements yields viable mice. PLoS biology, 5(9), e234.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-2">2</a>] </span> Ainscough, R., Bardill, S., Barlow, K., Basham, V., Baynes, C., Beard, L., ... &amp; Burrows, C. (1998). Genome sequence of the nematode C. elegans: a platform for investigating biology. Science, 282(5396), 2012-2018.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-3">3</a>] </span> Alipanahi, B., Delong, A., Weirauch, M. T., &amp; Frey, B. J. (2015). Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning. Nature biotechnology, 33(8), 831.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-4">4</a>] </span> Baum, L. E., &amp; Petrie, T. (1966). Statistical inference for probabilistic functions of finite state Markov chains. The annals of mathematical statistics, 37(6), 1554-1563.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-5">5</a>] </span> Benko, S., Fantes, J. A., Amiel, J., Kleinjan, D., Thomas, S., Ramsay, J., et al. (2009). Highly conserved non. Nature Genetics 64(2), p. 10-12.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-6">6</a>] </span> Boyle, A. P., Davis, S., Shulha, H. P., Meltzer, P., Margulies, E. H., Weng, Z., ... &amp; Crawford, G. E. (2008). High-resolution mapping and characterization of open chromatin across the genome. Cell, 132(2), 311-322.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-7">7</a>] </span> Burge, C., &amp; Karlin, S. (1997). Prediction of complete gene structures in human genomic DNA. Journal of molecular biology, 268(1), 78-94.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-8">8</a>] </span> Buenrostro, J. D., Giresi, P. G., Zaba, L. C., Chang, H. Y., &amp; Greenleaf, W. J. (2013). Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nature methods, 10(12), 1213.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-9">9</a>] </span> Calo, E., &amp; Wysocka, J. (2013). Modification of enhancer chromatin: what, how, and why?. Molecular cell, 49(5), 825-837.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-10">10</a>] </span> Creyghton, M. P., Cheng, A. W., Welstead, G. G., Kooistra, T., Carey, B. W., Steine, E. J., ... &amp; Boyer, L. A. (2010). Histone H3K27ac separates active from poised enhancers and predicts developmental state. Proceedings of the National Academy of Sciences, 107(50), 21931-21936.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-11">11</a>] </span> Cutter, A. R., &amp; Hayes, J. J. (2015). A brief review of nucleosome structure. FEBS letters, 589(20), 2914-2922.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-12">12</a>] </span> De Beer, Z. W., Duong, T. A., Barnes, I., Wingfield, B. D., &amp; Wingfield, M. J. (2014). Redefining Ceratocystis and allied genera. Studies in Mycology, 79, 187-219.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-13">13</a>] </span> Diehl, A. D., Meehan, T. F., Bradford, Y. M., Brush, M. H., Dahdul, W. M., Dougall, D. S., ... &amp; Van Slyke, C. E. (2016). The Cell Ontology 2016: enhanced content, modularization, and ontology interoperability. Journal of biomedical semantics, 7(1), 44.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-14">14</a>] </span> Doniger, S. W., Huh, J., &amp; Fay, J. C. (2005). Identification of functional transcription factor binding sites using closely related Saccharomyces species. Genome research, 15(5), 701-709.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-15">15</a>] </span> Du Preez, J. A. (1998). Efficient training of higher-order hidden Markov models using first-order representations. Computer speech &amp; language, 12(1), 23-39.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-16">16</a>] </span> Emison, E. S., McCallion, A. S., Kashuk, C. S., Bush, R. T., Grice, E., Lin, S., ... &amp; Chakravarti, A. (2005). A common sex-dependent mutation in a RET enhancer underlies Hirschsprung disease risk. Nature, 434(7035), 857.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-17">17</a>] </span> Ernst, J., &amp; Kellis, M. (2012). ChromHMM: automating chromatin-state discovery and characterization. Nature methods, 9(3), 215.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-18">18</a>] </span> Ernst, J., Kheradpour, P., Mikkelsen, T. S., Shoresh, N., Ward, L. D., Epstein, C. B., ... &amp; Ku, M. (2011). Mapping and analysis of chromatin state dynamics in nine human cell types. Nature, 473(7345), 43.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-19">19</a>] </span> Ezkurdia, I., Juan, D., Rodriguez, J. M., Frankish, A., Diekhans, M., Harrow, J., ... &amp; Tress, M. L. (2014). Multiple evidence strands suggest that there may be as few as 19 000 human protein-coding genes. Human molecular genetics, 23(22), 5866-5878.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-20">20</a>] </span> Ferguson, J. D. (1980). pp. 143–179, Variable duration models for speech. In Proc. of the Symposium on the applications of hidden Markov models to text and speech, JD Ferguson, Ed. Princeton: IDA-CRD.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-21">21</a>] </span> Fishilevich, S., Nudel, R., Rappaport, N., Hadar, R., Plaschkes, I., Iny Stein, T., ... &amp; Lancet, D. (2017). GeneHancer: genome-wide integration of enhancers and target genes in GeneCards. Database, 2017.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-22">22</a>] </span> Friedli, M., Barde, I., Arcangeli, M., Verp, S., Quazzola, A., Zakany, J., ... &amp; Duboule, D. (2010). A systematic enhancer screen using lentivector transgenesis identifies conserved and non-conserved functional elements at the Olig1 and Olig2 locus. PLoS One, 5(12), e15741. 
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-23">23</a>] </span> Galperin, M. Y., &amp; Fernández-Suarez, X. M. (2011). The 2012 nucleic acids research database issue and the online molecular biology database collection. Nucleic acids research, 40(D1), D1-D8.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-24">24</a>] </span> Haussler, D. K. D., &amp; Eeckman, M. G. R. F. H. (1996). A generalized hidden Markov model for the recognition of human genes in DNA. In Proc. int. conf. on intelligent systems for molecular biology, st. louis (pp. 134-142).
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-25">25</a>] </span> Hayashi-Takanaka, Y., Yamagata, K., Wakayama, T., Stasevich, T. J., Kainuma, T., Tsurimoto, T., ... &amp; Kimura, H. (2011). Tracking epigenetic histone modifications in single cells using Fab-based live endogenous modification labeling. Nucleic acids research, 39(15), 6475-6488.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-26">26</a>] </span> Heintzman, N. D., Stuart, R. K., Hon, G., Fu, Y., Ching, C. W., Hawkins, R. D., ... &amp; Wang, W. (2007). Distinct and predictive chromatin signatures of transcriptional promoters and enhancers in the human genome. Nature genetics, 39(3), 311.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-27">27</a>] </span> Heintzman, N. D., Hon, G. C., Hawkins, R. D., Kheradpour, P., Stark, A., Harp, L. F., ... &amp; Ching, K. A. (2009). Histone modifications at human enhancers reflect global cell-type-specific gene expression. Nature, 459(7243), 108.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-28">28</a>] </span> Hu, J., Brown, M. K., &amp; Turin, W. (1996). HMM based online handwriting recognition. IEEE Transactions on pattern analysis and machine intelligence, 18(10), 1039-1045.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-29">29</a>] </span> Jin Q, Yu L-R, Wang L, Zhang Z, Kasper LH, Lee J-E, Wang C, Brindle PK, Dent SYR, Ge K. 2011. Distinct roles of GCN5/PCAF-mediated H3K9ac and CBP/p300-mediated H3K18/27ac in nuclear receptor transactivation. The EMBO Journal 30:249–262.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-30">30</a>] </span> Jones, P. A. (2012). Functions of DNA methylation: islands, start sites, gene bodies and beyond. Nature Reviews Genetics, 13(7), 484.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-31">31</a>] </span> Kaplan, T., &amp; Biggin, M. D. (2012). Quantitative models of the mechanisms that control genome-wide patterns of animal transcription factor binding. In Methods in cell biology (Vol. 110, pp. 263-283). Academic Press.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-32">32</a>] </span> Karmodiya, K., Krebs, A. R., Oulad-Abdelghani, M., Kimura, H., &amp; Tora, L. (2012). H3K9 and H3K14 acetylation co-occur at many gene regulatory elements, while H3K14ac marks a subset of inactive inducible promoters in mouse embryonic stem cells. BMC genomics, 13(1), 424.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-33">33</a>] </span> Kelley, D. R., Snoek, J., &amp; Rinn, J. L. (2016). Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks. Genome research, 26(7), 990-999.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-34">34</a>] </span> Khan, A., Fornes, O., Stigliani, A., Gheorghe, M., Castro-Mondragon, J. A., van der Lee, R., ... &amp; Baranasic, D. (2017). JASPAR 2018: update of the open-access database of transcription factor binding profiles and its web framework. Nucleic acids research, 46(D1), D260-D266.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-35">35</a>] </span> Kleftogiannis, D., Kalnis, P., Arner, E., &amp; Bajic, V. B. (2016). Discriminative identification of transcriptional responses of promoters and enhancers after stimulus. Nucleic acids research, 45(4), e25-e25.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-36">36</a>] </span> Kreimer, A., Zeng, H., Edwards, M. D., Guo, Y., Tian, K., Shin, S., ... &amp; Li, Y. (2017). Predicting gene expression in massively parallel reporter assays: a comparative study. Human mutation, 38(9), 1240-1250.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-37">37</a>] </span> Kulakovskiy, I. V., Belostotsky, A. A., Kasianov, A. S., Esipova, N. G., Medvedeva, Y. A., Eliseeva, I. A., &amp; Makeev, V. J. (2011). A deeper look into transcription regulatory code by preferred pair distance templates for transcription factor binding sites. Bioinformatics, 27(19), 2621-2624.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-38">38</a>] </span> Kundaje, A., Meuleman, W., Ernst, J., Bilenky, M., Yen, A., Heravi-Moussavi, A., ... &amp; Amin, V. (2015). Integrative analysis of 111 reference human epigenomes. Nature, 518(7539), 317.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-39">39</a>] </span> Lee, L. M., &amp; Lee, J. C. (2006, June). A study on higher-order hidden Markov models and applications to speech recognition. In International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems (pp. 682-690). Springer, Berlin, Heidelberg.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-40">40</a>] </span> Lettice, L. A., Heaney, S. J., Purdie, L. A., Li, L., de Beer, P., Oostra, B. A., ... &amp; de Graaff, E. (2003). A long-range Shh enhancer regulates expression in the developing limb and fin and is associated with preaxial polydactyly. Human molecular genetics, 12(14), 1725-1735.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-41">41</a>] </span> Lindblad-Toh, K., Garber, M., Zuk, O., Lin, M. F., Parker, B. J., Washietl, S., ... &amp; Ward, L. D. (2011). A high-resolution map of human evolutionary constraint using 29 mammals. Nature, 478(7370), 476.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-42">42</a>] </span> Mari, J. F., Haton, J. P., &amp; Kriouile, A. (1997). Automatic word recognition based on second-order hidden Markov models. IEEE Transactions on speech and Audio Processing, 5(1), 22-25.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-43">43</a>] </span> Markov, A. A. (1906). Extension of the law of large numbers to dependent quantities. Izv. Fiz.-Matem. Obsch. Kazan Univ.(2nd Ser), 15, 135-156.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-44">44</a>] </span> Miguel-Escalada, I., Pasquali, L., &amp; Ferrer, J. (2015). Transcriptional enhancers: functional insights and role in human disease. Current opinion in genetics &amp; development, 33, 71-76.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-45">45</a>] </span> Ng, S. B., Turner, E. H., Robertson, P. D., Flygare, S. D., Bigham, A. W., Lee, C., ... &amp; Bamshad, M. (2009). Targeted capture and massively parallel sequencing of 12 human exomes. Nature, 461(7261), 272.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-46">46</a>] </span> Pennacchio, L. A., Ahituv, N., Moses, A. M., Prabhakar, S., Nobrega, M. A., Shoukry, M., ... &amp; Plajzer-Frick, I. (2006). In vivo enhancer analysis of human conserved non-coding sequences. Nature, 444(7118), 499-502.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-47">47</a>] </span> Pennacchio, L. A., Bickmore, W., Dean, A., Nobrega, M. A., &amp; Bejerano, G. (2013). Enhancers: five essential questions. Nature Reviews Genetics, 14(4), 288.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-48">48</a>] </span> Przybilla, J., Galle, J., &amp; Rohlf, T. (2012). Is adult stem cell aging driven by conflicting modes of chromatin remodeling?. Bioessays, 34(10), 841-848.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-49">49</a>] </span> Quinlan, A. R., &amp; Hall, I. M. (2010). BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26(6), 841-842.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-50">50</a>] </span> Rabiner, L., &amp; Juang, B. H. (1993). Fundamentals of speech processing. Prantice Hall.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-51">51</a>] </span> Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-52">52</a>] </span> Rada-Iglesias, A., Bajpai, R., Swigut, T., Brugmann, S. A., Flynn, R. A., &amp; Wysocka, J. (2011). A unique chromatin signature uncovers early developmental enhancers in humans. Nature, 470(7333), 279.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-53">53</a>] </span> Rosin, J. M., Abassah-Oppong, S., &amp; Cobb, J. (2013). Comparative transgenic analysis of enhancers from the human SHOX and mouse Shox2 genomic regions. Human molecular genetics, 22(15), 3063-3076.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-54">54</a>] </span> Smemo, S., Campos, L. C., Moskowitz, I. P., Krieger, J. E., Pereira, A. C., &amp; Nobrega, M. A. (2012). Regulatory variation in a TBX5 enhancer leads to isolated congenital heart disease. Human molecular genetics, 21(14), 3255-3263.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-55">55</a>] </span> Soldner, F., Stelzer, Y., Shivalila, C. S., Abraham, B. J., Latourelle, J. C., Barrasa, M. I., ... &amp; Jaenisch, R. (2016). Parkinson-associated risk variant in distal enhancer of α-synuclein modulates target gene expression. Nature, 533(7601), 95.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-56">56</a>] </span> Stadler, M. B., Murr, R., Burger, L., Ivanek, R., Lienert, F., Schöler, A., ... &amp; Tiwari, V. K. (2011). DNA-binding factors shape the mouse methylome at distal regulatory regions. Nature, 480(7378), 490. 
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-57">57</a>] </span> Stormo, G. D., Schneider, T. D., Gold, L., &amp; Ehrenfeucht, A. (1982). Use of the ‘Perceptron’algorithm to distinguish translational initiation sites in E. coli. Nucleic acids research, 10(9), 2997-3011.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-58">58</a>] </span> Staden, R. (1984). Computer methods to locate signals in nucleic acid sequences.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-59">59</a>] </span> Taher, L., McGaughey, D. M., Maragh, S., Aneas, I., Bessling, S. L., Miller, W., ... &amp; Ovcharenko, I. (2011). Genome-wide identification of conserved regulatory function in diverged sequences. Genome research, 21(7), 1139-1149.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-60">60</a>] </span> Tate, P. H., &amp; Bird, A. P. (1993). Effects of DNA methylation on DNA-binding proteins and gene expression. Current opinion in genetics &amp; development, 3(2), 226-231.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-61">61</a>] </span> Thurman, R. E., Rynes, E., Humbert, R., Vierstra, J., Maurano, M. T., Haugen, E., ... &amp; Garg, K. (2012). The accessible chromatin landscape of the human genome. Nature, 489(7414), 75.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-62">62</a>] </span> Turin, W., &amp; Sondhi, M. M. (1993). Modeling error sources in digital channels. IEEE Journal on Selected Areas in Communications, 11(3), 340-347.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-63">63</a>] </span> Visel, A., Minovitsky, S., Dubchak, I., &amp; Pennacchio, L. A. (2007). VISTA Enhancer Browser—a database of tissue-specific human enhancers. Nucleic Acids Research, 35(Database issue), D88.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-64">64</a>] </span> Visel, A., Blow, M. J., Li, Z., Zhang, T., Akiyama, J. A., Holt, A., ... &amp; Afzal, V. (2009). ChIP-seq accurately predicts tissue-specific activity of enhancers. Nature, 457(7231), 854.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-65">65</a>] </span> Viterbi, A. (1967). Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE transactions on Information Theory, 13(2), 260-269.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-66">66</a>] </span> Williamson, I., Hill, R. E., &amp; Bickmore, W. A. (2011). Enhancers: from developmental genetics to the genetics of common human disease. Developmental cell, 21(1), 17-19.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-67">67</a>] </span> Winter, R. B., Berg, O. G., &amp; Von Hippel, P. H. (1981). Diffusion-driven mechanisms of protein translocation on nucleic acids. 3. The Escherichia coli lac repressor-operator interaction: kinetic measurements and conclusions. Biochemistry, 20(24), 6961-6977.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-68">68</a>] </span>Yang, F., Balakrishnan, S., &amp; Wainwright, M. J. (2015, December). Statistical and computational guarantees for the Baum-Welch algorithm. In 2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton) (pp. 658-665). IEEE.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-69">69</a>] </span> Zentner, G. E., Tesar, P. J., &amp; Scacheri, P. C. (2011). Epigenetic signatures distinguish multiple classes of enhancers with distinct cellular functions. Genome research, 21(8), 1273-1283.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-70">70</a>] </span> Zhang, Y., Liu, T., Meyer, C. A., Eeckhoute, J., Johnson, D. S., Bernstein, B. E., ... &amp; Liu, X. S. (2008). Model-based analysis of ChIP-Seq (MACS). Genome biology, 9(9), R137.
</p>
<p class="biblio">
<span class="entry">[<a class="biblioentry" name="biblio-71">71</a>] </span> Zhou, J., &amp; Troyanskaya, O. G. (2015). Predicting effects of noncoding variants with deep learning–based sequence model. Nature methods, 12(10), 931.
</p>

</div>
</body>
</html>
