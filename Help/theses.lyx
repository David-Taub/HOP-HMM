#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{babel}
\usepackage{float}
\end_preamble
\use_default_options false
\begin_modules
logicalmkup
\end_modules
\maintain_unincluded_children false
\begin_local_layout
InsetLayout Flex:Code
    LyxType               charstyle
    LabelString           code
    LatexType             command
    LatexName             code
    Font
      Family              Typewriter
    EndFont
    Preamble
    \newcommand{\code}[1]{\texttt{#1}}
    EndPreamble
    InToc                 true
    HTMLTag               code
End
\end_local_layout
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "newtxmath" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 1
\output_sync_macro "\synctex=1"
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\headheight 0cm
\headsep 0cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
The Hebrew University of Jerusalem â€“ the Faculty of Computer Science and
 Engineering
\end_layout

\begin_layout Title
Classifiers of Regulatory Sequences in the Human Genome Using High-Order
 Generalized Hidden Markov Model 
\end_layout

\begin_layout Part*
Abstract
\end_layout

\begin_layout Standard
Enhancers are regulatory DNA sequences that, when bound to proteins called
 transcription factors, enhance the likelihood that a transcription of a
 target gene will occur.
 Regulation of transcription is an important form of gene expression control,
 and the activity of enhancers allows specific regulation of genes in a
 stage-specific and tissue-specific manner.
 It has been shown over the years that genetic variation within enhancer's
 sequence might cause cells behavior modification and diseases.
 Transcription factors tend to attach to the DNA at transcription factor
 binding sites, which are motifs inside the DNA, which are over represented
 in enhancer sequences.
 Except for these binding sites, the rules and structure nuances of the
 enhancer sequence is not fully clear.
 Enhancers activity can be detected mainly by adjacent histone marks, the
 presence of transcription factors and accessibility.
 All of these epigenetic data is often noisy, and the extraction process
 is costly, and requires a sample of cells from the tested tissue, which
 is not always practical for all tissue types of all stages.
 We offer here a computational approach to detect enhancers based on their
 sequence in an unsupervised manner.
 We created a generalized hidden Markov model with states that emit transcriptio
n factor binding sites using a positional weight matrix model, and states
 that emit single nucleotides with high order dependency on previously emitted
 nucleotides.
 This model learns a more complex underlying structure of DNA sequences,
 containing both motifs and high-order distributions of nucleotides in between
 them.
 We first review the background of Markov and hidden Markov models and the
 demonstrate how to calculate the likelihood of this model from a sequence.
 Then, we describe our generalized model in detail and develop the expectation
 maximization and Viterbi algorithms for regular hidden Markov model, followed
 by the adjustments needed for our generalized version of the model.
 We then create a synthetic enhancer-like dataset using the generative property
 of the model, and simulate the model in a controlled way to evaluate its
 performance.
 Next, we experiment on the Roadmap project dataset, containing human DNA
 sequences of known active enhancers.
\end_layout

\begin_layout Standard
TODO: FINISH
\end_layout

\begin_layout Part*
Introduction
\end_layout

\begin_layout Standard
The genome of every organism contains the inherited information that defines
 its complex structure and function.
 The genome is built out of Deoxyribonucleic acid (DNA) molecule, that is
 a built out of two chains of nucleotides units that form a double helix
 shape.
 Each nucleotide is built our of 4 different types bases: cytosine, guanine,
 adenine or thymine or in short A,C,G and T.
 The nucleotides are organized in pairs called base pairs where each of
 the paired nucleotides are complimentary to each other and provide redundancy.
\end_layout

\begin_layout Standard
Proteins are macromolecoles, which carry various roles and functions within
 organisms.
 They are built out of 20 different amino acids, which order and structure
 is encoded inside genetic segments in the genome called genes.
 Through the transcription and translation processes, the genes are expressed
 and result in the formation of proteins.
 In the transcription process the gene is read and transcribed into a single
 strand sequence of RNA.
 Later, the RNA molecules are translated into a sequence of amino acids
 that constitute a protein.
\end_layout

\begin_layout Standard
Gene sequences are built out fragmented introns and exons, where only the
 exons becomes the RNA molecules that translates into proteins while the
 introns are spliced away beforehand.
 Although the exons alone hold the recipe for the construction of the organism's
 proteins, the complexity of the organism is not a product of their number
 or their length.
 For example, the humans and Caenorhabditis elegans roundworms both have
 about 19,000 genes (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-16"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-57"

\end_inset

), with roughly the same total exon length and number, although the human
 body is vastly more diverse and complex.
 The source for the organisms complexity differences is attributed to the
 gene regulation mechanism.
 The human genome is 3.23 Gb long, and it is estimated that gene regulation
 regions involve 10-20% of it (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-46"

\end_inset

), compared to exon regions that involve only 1% (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-45"

\end_inset

).
\end_layout

\begin_layout Standard
Enhancers are are non-coding regulatory DNA sequences that play a key role
 in the regulation transcription of genes.
 In humans there are hundreds of thousands of enhancers, scattered over
 the non-coding regions of the genome, and their length are usually between
 100-1000 bp.
 When activated, the DNA folding draws the enhancer spatially closer to
 another type of regulatory element called promoter, resulting in the translatio
n of a gene adjacent to the promoter (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Transcription"

\end_inset

).
 The enhancer's target gene is the expressed gene from this activation process.
 It can be located up to a megabase upstream or downstream from their activating
 enhancer (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-43"

\end_inset

), and are orientation independent to it.
 Moreover, the gene-enhancer connection is not exclusive, and the common
 case is that each enhancer has several target genes and vice versa (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-20"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Enhancer_gene_transcription.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Transcription"

\end_inset

A) An enhancer and its distal target gene.
 B) The DNA folds and the attached with transcription factors draw other
 co-factor proteins that together form the transcription complex.
 C) The RNA Polymerase II is recruited and while moving along the gene it
 generates a new RNA molecule that is transcribed off the gene sequence.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In VISTA Project (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

), mouse fertilized eggs where injected enhancers sequences, adjacent to
 LacZ reporter gene, encoding enzyme with blue color.
 The injected DNA sequences bared no epigenetic information and integrated
 in an arbitrary position in the mouse genome.
 The transgenic embryos where photographed after 11.5 days and, for some
 of the DNA sequences, a similar pattern was present over several instances.
 These results imply that for many DNA sequences, the DNA code alone possess
 the potential to become a tissue specific enhancer, even without epigenetic
 information.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/f735.jpg
	scale 15

\end_inset


\begin_inset Graphics
	filename Figures/experiment_process.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Mouse"

\end_inset

Transgenic mouse embryo in the 11.5 day.
 As an fertilized egg a synthetic enhancer sequence was injected, which
 is related to the dorsal root ganglia spinal neurons.
 The enhancer became activated and caused the expression of the blue color
 marker gene that was coupled to it.
 Taken from Vista Enhancer Browser, experiment hs-51 embryo 2.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
Transcription factors (TF) are proteins that bind to the DNA, and together
 with other co-factor proteins initiate the gene transcription process.
 TFs tend to bind to certain transcription factor binding sites (TFBS),
 which are motifs of nucleotides on the DNA with average length of 12 bp
 in humans (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-36"

\end_inset

) that are conserved between species (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-12"

\end_inset

).
 ChIP-seq method can measure the amount of TFs which are bounded to the
 DNA strand, by applying antibodies which attach to the TFs and reading
 a short DNA sequence around the TF and antibody.
 Genome-wide association studies (GWAS) of ChIP-seq found that different
 TFs have different and distinct distributions of TFBS (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-32"

\end_inset

).
\end_layout

\begin_layout Standard
Both enhancers and promoters contain TFBSs that are critical for the their
 correct regulatory operation.
 Multiple studies have shown that genetic alternations in TFBS can affect
 the expression of the regulated gene and are a major cause of different
 human diseases (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-35"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-44"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-54"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-53"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-6"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-13"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-39"

\end_inset

).
 From the sequence aspect, enhancers and promoters have a similar structure
 of a background nucleotide sequence with distribution different from other
 part of the genome, with TFBS motifs tiled inside this background sequence.
\end_layout

\begin_layout Standard
The enrichment of TFBS is a good predictor for the location of promoter
 and enhancer regulatory regions and the type of cells they will be active
 in.
 Folding of DNA allows the enhancer-promoter interactions, in which the
 TFs take major part.
 Once bounded to the DNA, the TFs recruit other cofactor proteins to them,
 and together they form a transcription preinitiation complex (PIC), a very
 large assembly of proteins.
 Out of the tens of proteins constructing the PIC, the sub-unit RNA Polymerase
 (RNA pol II) has the role of transcribing the adjacent gene.
 it opens the double stranded DNA, so that one strand of nucleotides is
 exposed and becomes a template for RNA synthesis.
\end_layout

\begin_layout Standard
For generating a simplistic yet accurate model for representing the TF binding
 potential of a DNA sequence, i.e.
 
\begin_inset Formula $P(x_{1:n}|binding)$
\end_inset

, we are usually required to assume independence between positions and a
 small span of influence by the sequence around the binding site.
 The peaks of the ChIP-seq mark the TF binding locations, from which a binding
 site 
\begin_inset Quotes eld
\end_inset

grammar
\begin_inset Quotes erd
\end_inset

 can be modeled.
 Position weight matrix (PWM), as introduced in 
\begin_inset CommandInset citation
LatexCommand citet
key "key-7"

\end_inset

, is the most commonly used probabilistic model for addressing this task.
 The underlying assumption of the PWM model is that every position in the
 DNA sequence has an independent probability to attach to the TF, and therefore
 the total binding probability is a multiplication of all the per-position
 probabilities in the motif:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(x_{1:n}|binding)=\prod_{i\in[n]}P(x_{i}|binding)
\]

\end_inset

Where n is the size of relevant sequence.
 The size of the sequence that is affected by the binding event is derived
 from the physical characteristics of the TF.
\end_layout

\begin_layout Standard
\begin_inset Formula $P(x_{i}|binding)$
\end_inset

 is estimated by counting the nucleotides frequency in every position of
 the observed binding sites, which are the ChIP-seq peaks.
 For a motif of length J, this probability estimation is stored in a position
 probability matrix (PPM) W as followed: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
W_{i,j}=\frac{1}{N}\sum_{n\in[N]}\boldsymbol{1}(x_{j}^{(n)}=i)
\]

\end_inset

where 
\begin_inset Formula $x^{(n)}$
\end_inset

 is the n'th sequence out of the found binding sites, 
\begin_inset Formula $j\in[J]$
\end_inset

 the position in the motif and 
\begin_inset Formula $i\in[4]$
\end_inset

 the nucleotide index of A,C,G and T.
 The PPM is normalized 
\begin_inset Formula 
\begin{equation}
{\displaystyle M_{i,j}=\mathrm{log}\left(\frac{W_{i,j}}{b_{i}}\right)}\label{PPM}
\end{equation}

\end_inset

where 
\begin_inset Formula $b_{i}$
\end_inset

 is prior background model, which is 
\begin_inset Formula $0.25$
\end_inset

 in case of nucleotides.
 From a generative model point of view, the TFBS sequence is generated by
 an emission model of the PWM.
 The division in 
\begin_inset Formula $M$
\end_inset

 by 
\begin_inset Formula $b_{i}$
\end_inset

 allows comparison between the binding likelihood of different TFs with
 different lengths.
 The practical length-normalized log likelihood of a PWM 
\begin_inset Formula $log\left(\mathscr{\mathcal{L}}(W;x_{1:n})\right)$
\end_inset

 is easily is done be a convolution of 
\begin_inset Formula $log(W)$
\end_inset

 on a one-hot encoding of the sequence (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

), and actually holds the log likelihood of a TF binding to a sequence relative
 to a random sequence.
 In this work, we use the more familiar term PWMs, but will actually use
 PPMs for the TFBS emission model which are essentially simmilar.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/pwm_mult.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "PWM"

\end_inset

Sub-sequences out of the DNA is represented in a one-hot encoding, then
 multiplied entry-wise with a PWM.
 Then, the sum of the logs of the maximal values of each column in the result
 matrix is calculated, which is the log likelihood of the TF binding to
 the sub-sequence.
 This log likelihood is calculated for each location in the sequence, where
 location with high values indicate high likelihood of TF binding.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Conserved non-coding elements (CNE) reside in clusters, usually with low
 gene density but with vicinity to genes.
 Typically, CNE are structured in arrays known as genomic regulatory block
 (GRB), with a mean length of 1.4 Mb (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-11"

\end_inset

).
 The correlation between conservation of non-coding region and enhancer
 functionality is not strong.
 Some verified enhancers are weakly or not conserved between species (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-21"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-52"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-56"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-40"

\end_inset

) and some highly conserved areas in the mouse genome are not associated
 to regulatory activity and their deletion and yielded viable mice (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-1"

\end_inset

).
 Nevertheless, an assay of elements with 100% sequence identity of over
 200 bp between human and mouse found that 50% showed enhancers activity
 in mice (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

).
 The reason for such ultra-conservation of 200 bp sequences when the TFBS
 is only 4-8 bp long is unclear.
 It is possible that these conserved sequences have spacial role when binding
 to multiple TFs of the PIC or that these enhancers has other functions
 which are not yet understood such as eRNA (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-23"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-3"

\end_inset

).
\end_layout

\begin_layout Subsection*
Epigenetics
\end_layout

\begin_layout Standard
Almost all cells in every organism contain its genome, but only part of
 genome is active in any specific cell.
 Cells of different types and in different operation modes differ by gene
 expression patterns.
 The reason for that lies in regulation components that are outside of the
 genomic sequence.
 The location and presence of TFBS, background nucleotides distribution
 and other sequence related properties are not enough to explain regulatory
 role of regions in the genome.
\end_layout

\begin_layout Standard
Several epigenetic features (which do not involve the nucleotides sequence
 directly) correlate with enhancer regions in the genome:
\end_layout

\begin_layout Itemize
Accessibility
\end_layout

\begin_layout Itemize
TF & cofactors binding
\end_layout

\begin_layout Itemize
Histone modifications
\end_layout

\begin_layout Itemize
DNA methylation
\end_layout

\begin_layout Standard
These properties and mechanisms have measurable features that lie on top
 of the genome.
 Their combination is the main source of identification for enhancer regions
 in the genome.
 Each cell has its own epigenetic features, in a binaric form, e.g.
 a specific part of the genome can be either accessible, or not.
 When several similar cells from the same tissue sample are measured, a
 frequency or count of the feature is measured per DNA loci, and generates
 epigenetic data.
 The epigenetic data is commonly used as the ground truth indication for
 enhancer sequences, as done for the human genome in the ENCODE project.
\end_layout

\begin_layout Subsubsection*
Accessibility
\end_layout

\begin_layout Standard
In eukaryotes, the DNA is packed around a structure of 8 histone proteins,
 together forming a nucleosome core.
 The location of the nucleosome binding is not random over the DNA sequence,
 but has a tendency for specific DNA binding sites (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-9"

\end_inset

).
 DNA that is wrapped around a nucleosome has a lesser probability to interact
 with proteins, as it is physically inaccessible.
 Both the enhancer, the promoter and the gene need to be accessible for
 a successful transcription.
\end_layout

\begin_layout Standard
Since the scenario of TF binding on an enhancer requires an accessible DNA
 region, I hypersensative sites are used for detecting a potential DNA cleavages
 that have the potential of being regulatory elements, in usually a better
 resolution than histone marks.
\end_layout

\begin_layout Subsubsection*
Histone Marks
\end_layout

\begin_layout Standard
Chromatin modifications signatures, also called histone marks, are predictive
 of enhancer position and activity status (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-19"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-18"

\end_inset

).
 The histone marks are considered to contain a certain 
\begin_inset Quotes eld
\end_inset

histone code
\begin_inset Quotes erd
\end_inset

 which encode complex information, additionally to the DNA, regarding the
 transcription regulation and other aspects.
 Comparing to other epigenetic information, and especially DNA methylation
 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-48"

\end_inset

), chromatin modifications have a short time-scale of seconds or hours (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-25"

\end_inset

), hence they are considered part of the dynamic changes of the cell's modes.
\end_layout

\begin_layout Standard
Histone marks can be detected with ChIP-seq procedure, similarly to TF binding
 detection described above, by using antibodies which attach to the chromatin
 modification instead of the TF protein.
 H3K4me1 and H3K27ac are among the predominant histone marks of active enhancers
, where H3K4me1 is enriched on transcribed genes and enhancers prior to
 activation (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-7"

\end_inset

), and is thought to precede the H3K27ac modification (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-51"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-62"

\end_inset

) which is known to occur during the activation.
 Other histone marks that are present on active enhancers and are used for
 their detection are H3K9ac (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-15"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-30"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-62"

\end_inset

) and H3K18ac (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-28"

\end_inset

).
 Even though H3K27ac have been identified as an important mark for distinguishin
g active enhancers from poised enhancers (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

), it is not enough as its own since when present alongside H3K4me3 it is
 an indication for active promoters (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-26"

\end_inset

).
 In contrast, H3K27ac absence and H3K4me1and H3K27me3 enrichment are typical
 for poised enhancers (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

).
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Enhancers_status.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Enhancer"

\end_inset

The accessibility of the enhancer's sequence and its surrounding histone
 marks are connected to its regulatory activity state.
 On the upper part an active enhancer sequence that is accessible for protein
 interaction needed for transcription, where as on the lower part an inactive
 enhancer is inaccessible since it is wrapped around a nucleosome.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
DNA Methylation
\end_layout

\begin_layout Standard
DNA methylation at cytosine and CpG sites has been involved in genome silencing
 in multiple processes (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-29"

\end_inset

), and has been documented as largely correlated with gene expression inhibition
 when present in promoters.
 In enhancer elements, anti-correlation was found between DNA methylation
 density and enrichment of active enhancer histone marks and TF binding
 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-55"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-58"

\end_inset

), although the cause and consequence relationship underlying these correlations
 is not yet clear.
\end_layout

\begin_layout Subsubsection*
Epigenetics Limitation
\end_layout

\begin_layout Standard
The currently most accurate method for predicting the location of enhancers
 sequences in a genome wide scale, is analyzing the histone marks, TF and
 cofactors presence using ChIP-seq from a cell line or from a tissue, combined
 with DNase I hypersensative (DHS).
\end_layout

\begin_layout Standard
Several approaches have faced the problem of locating enhancers by modeling
 gene expression based on epigenetic marks.
 However, these models rely on experimental data, and are inherently limited
 to the specific tissues we can extract and isolate for epigenetic examination.
 Furthermore, such models do no supply  a classification of enhancers for
 new variation found in the population.
 Another disadvantage is the need for live cells for the verification of
 the regulatory activity of a sequence.
 The ultimate goal of an efficient computational method for predicting and
 explaining the reason for the functional nature of sequences
\begin_inset Quotes eld
\end_inset

in-silico
\begin_inset Quotes erd
\end_inset

 has produced positive, yet far from sufficient results in the last years,
 as reviewed in (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-33"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/genome_browser.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "GenomeBrowser"

\end_inset

Epigenetic feature tracks measured by ENCODE, taken from the tenth chromosome
 of a H1-hESC cell line.
 Highlighted in light blue, the peaks of the H3K27ac (1st green plot) and
 H3K4me1 (2nd green plot) histone marks and the DNaseI hyper sensitivity
 feature (4th green plot) together with the lack of H3K27me3 (3rd green
 plot) signal are indication of an active enhancer, as indicated by the
 ChromHMM classification (bottom).
 Note the decrease between the two peaks of H3K27ac and H3K4me1 is located
 on top of the increase of the DNaseI hyper sensitivity, which implies a
 cleavage in between two nucleosomes with modifications.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Previous Work
\end_layout

\begin_layout Standard
There are several achievements in the task of predicting epigenetic and
 regulatory properties of DNA elements given only their sequence using machine
 learning algorithms.
 DeepSEA (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-63"

\end_inset

) deep convolutional neural network (DCNN) is fed with 1000 bp DNA sequence
 and predicts an output vector of 919 binary features which represents the
 chromatin modifications of 200 bp bin in the center of the input sequence.
 The training labels used are the chromatin modification are extracted from
 ENCODE and Roadmap Epigenomics data releases.
\end_layout

\begin_layout Standard
Basset (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-32"

\end_inset

) also used DCNN with known PWM as weights initialization on ENCODE and
 Roadmap Epigenomics data to predict a binary vector that represents accessibili
ty in 164 cell types based on 600 bp DNA sequence.
 In DeepBind (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-2"

\end_inset

) a DCNN was used to predict binding of 538 TFs and 194 RNA binding proteins
 from DNA sequences of varying lengths.
 In gkm-SVM (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-5"

\end_inset

), gapped kmers presence indicator vector were used as features for an SVM
 classifier to predict the role of DNA sequences with varying lengths.
\end_layout

\begin_layout Standard
ChromHMM (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-14"

\end_inset

) is a widely used software that tackles the problem of analyzing the epigenetic
 data for concluding roles in the genomic sequence.
 The algorithm uses chromatin mark reads, threshold to binary values, as
 input to HMM which then allows classifying the genome state in each position
 in the genome.
\end_layout

\begin_layout Standard
A disadvantage of these method is their need for a training data of known
 regulatory elements or with epigenetic data, which is commonly obtained
 from GWAS surveys done on 127 obtained human cell types in the Roadmap
 and ENCODE projects (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-37"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-15"

\end_inset

).
 The number of different cell types in the human body is estimated to be
 higher than 2200 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-10"

\end_inset

), and so we cannot know in certainty the number and location of tissue
 specific enhancers active in most of these cell types.
\end_layout

\begin_layout Subsubsection*

\series bold
Data Representation
\end_layout

\begin_layout Standard
When a DNA sequence is read from a tissue sample, it is often stored as
 a sequence of letters A,C,G and T in FASTA format.
 For an algorithm to process it, these characters are mapped into a data
 structure of integers 1,2,3 and 4 respectively.
 For many algorithms, such as in DeepSEA, Basset, and our HOP-Baum-Welch,
 it is preferable to encode these sequences of integers as a sequence one-hot
 vectors (also called indicator vectors), as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

.
\end_layout

\begin_layout Standard
A common feature extraction technique often used is representing the DNA
 sequence as a vector of the in-sequence frequencies of all the possible
 kmer as used in gkm-SVM.
 In this technique, similarly to the bag of words technique in text analysis
 and natural language processing, the order of the kmer locations is sacrificed
 for a more meaning-oriented, structured and fixed-length data encoding.
\end_layout

\begin_layout Section*
Stochastic Models
\end_layout

\begin_layout Subsection*
Generative & Discriminative Models
\end_layout

\begin_layout Standard
In machine learning classification models, there are a two main approaches
 called generative models and discriminative models.
 Both assumes an observed variables X and target variables Y, also commonly
 referred to as data samples and labels.
\end_layout

\begin_layout Itemize
The generative models assume a joint probability 
\begin_inset Formula $P\left(X,Y\right)$
\end_inset

.
 Using the data one can estimate the distribution 
\begin_inset Formula $P\left(X,Y\right)$
\end_inset

, then from it estimate 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

.
 It is assumed that such a model can generate the random instances of the
 data either as pairs of 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 or generate instances of x given y.
\end_layout

\begin_layout Itemize
Discriminative models assume conditional probability 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

, which is estimated directly from the data.
\end_layout

\begin_layout Standard
In classification problems, the task at hand is to arrive from the observed
 X to its label Y, e.g.
 given a DNA sequence X, deciding its role label Y.
 Both models eventually use the 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

 estimation to base their classification.
 Namely, classifying a data sample 
\begin_inset Formula $x$
\end_inset

 by 
\begin_inset Formula $y_{est}=argmax_{y}P\left(Y=y|X=x\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Discriminative models are more widely used than generative models.
 They are often easier to use and build since they require less assumptions
 on the origin or generation of the data.
 For example, a discriminative model such as a DNN classifying the role
 of DNA sequence assumes very little on the way the DNA sequence is related
 to it's role and generated based on it, but instead it finds features in
 the sequence that indicate its role.
 Such a model often gives very little for later understanding of the nature
 of the data generation process, and can generate no new data later for
 other uses.
\end_layout

\begin_layout Subsection*
Markov Model
\end_layout

\begin_layout Standard
Markov model (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-42"

\end_inset

), named after a Russian mathematician Andrey Markov, is a stochastic model
 which models a system that changes randomly such as the weather or car
 traffic.
 In a Markov model, at any time the model is at one of m states 
\begin_inset Formula $\left\{ S_{1},...,S_{m}\right\} $
\end_inset

, where the first state is sampled from a distribution 
\begin_inset Formula $\pi_{i}=P\left(y_{1}=S_{i}\right)$
\end_inset

 and the probability of transitions between the states is denoted by 
\begin_inset Formula $T_{i,j}=P\left(y_{t}=S_{i}|y_{t-1}=S_{j}\right)$
\end_inset

.
 The model's travel over the states is called a Markov process, and the
 sequence of states visited in the process is called a Markov chain.
\end_layout

\begin_layout Standard
The likelihood of a Markov chain X generated by a Markov Model 
\begin_inset Formula $\theta=\{\pi,T\}$
\end_inset

 is a joint probability of the first state and all following transition,
 which due to the independence between transition events can be written
 as :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{L}(\theta;X)=P_{\theta}(x_{0},x_{1},...,x_{L})=\pi_{x_{0}}\cdot T_{x_{0},x_{1}}\cdot T_{x_{1},x_{2}}\cdot...\cdot T_{x_{L-1},x_{L}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Markov_model.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Markov"

\end_inset

A) Markov model with 3 states (yellow green and blue).
 B,C) The model starts with a state sampled from 
\begin_inset Formula $\pi$
\end_inset

, and travels between the states with a transition distribution 
\begin_inset Formula $T$
\end_inset

.
 D) The model can generate Markov chains of states, where the transition
 between the states is conditioned on the previous state alone, causing
 the Markov process to be memoryless.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Hidden Markov Model
\end_layout

\begin_layout Standard
Hidden Markov model (HMM) is a Markov model variation that models a system
 that travels over hidden states in a Markov process, and while doing so
 it emits variables called observed variables.
 As the Markov model, HMM is an generative model, and therefore it assumes
 the existence of a joint probability 
\begin_inset Formula $P\left(x_{1:L},y_{1:L}\right)$
\end_inset

 that is derived from the compact parameters 
\begin_inset Formula $\theta$
\end_inset

.
 HMM relies on the assumption that the observed DNA sequence 
\begin_inset Formula $X=x_{1},...,x_{L}$
\end_inset

 is generated by a parameterized model 
\begin_inset Formula $\theta$
\end_inset

, and has an hidden state sequence 
\begin_inset Formula $Y=y_{1},...,y_{L}$
\end_inset

 that are generated alongside it.
 In this generation process, a single observed variable is emitted per step
 of the model, and so the observed sequence is generated with the same length
 as the hidden Markov chain.
 The observed variables 
\begin_inset Formula $V_{1},...,V_{n}$
\end_inset

 are sampled from an emission distribution 
\begin_inset Formula $E_{i,j}=P\left(x_{t}=V_{j}|y_{t}=S_{i}\right)$
\end_inset

, that is conditioned on the hidden state of the model.
 Similarly to the Markov model, the distribution to the first hidden state
 is marked as 
\begin_inset Formula $\pi$
\end_inset

 and the transition distribution is marked as 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HMM_two_states.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "HMM"

\end_inset

A) HMM with 2 hidden states.
 B) The observed variables (dark blue) are emitted by the hidden state at
 their location, sampled from the discrete conditional distribution E.
 C,D) The hidden states (yellow and green) behave as Markov model states
 with starting and transition probabilities, 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

.
 E) The output of the model is a observable sequence with an underlying
 hidden sequence.
 The hidden sequence is a Markov chain, where on each step the hidden state
 emits a single observed variable.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Multiple signal processing algorithms have been used in computational biology,
 and HMM is especially popular among them.
 Hidden Markov model (HMM) is a statistical model proposed by Leonard Baum
 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-4"

\end_inset

) and is based on the Markov model for modeling regions with alternating
 frequencies of patterns and symbols.
 It was used extensively in various engineering fields since the 1980s,
 especially in speech recognition (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-49"

\end_inset

), handwriting recognition (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-27"

\end_inset

) and digital communication (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-59"

\end_inset

) and was adopted in the computational biology field.
\end_layout

\begin_layout Standard
For example, in the case where the observable sequence is made out of DNA,
 a simplistic model can assume the DNA sequence is composed out of 4 states:
 genes, promoter enhancers and background regions.
 Each of these types will have different nucleotide frequency, and we assume
 the DNA sequence was generated by a HMM with underlying sequence of 4 hidden
 states, one for each region type.
 The emitted observed DNA sequence x is determined by the underlying hidden
 sequence y that describes the
\begin_inset Quotes eld
\end_inset

mode
\begin_inset Quotes erd
\end_inset

 of the sequence in each position.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Subsubsection*
HMM Likelihood and Posterior Probability
\end_layout

\begin_layout Standard
Having a HMM with 
\begin_inset Formula $\theta$
\end_inset

 on hand, two questions arise given an observed sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

:
\end_layout

\begin_layout Itemize
What is the likelihood that x was generated by the HMM? 
\begin_inset Formula $P_{\theta}\left(x_{1:L}\right)$
\end_inset


\end_layout

\begin_layout Itemize
What is the probability of a hidden state at every location? 
\begin_inset Formula $P_{\theta}\left(y_{t}=j|x_{1:L}\right)$
\end_inset


\end_layout

\begin_layout Standard
The two probabilities in the questions above are the likelihood and the
 posterior probabilities of HMM.
\end_layout

\begin_layout Standard
As in many generative models, HMM's likelihood function 
\begin_inset Formula $\mathcal{L}\left(\theta|x_{1:L}\right)$
\end_inset

 from the first question, can be split by the total probability law to the
 sum of all possible hidden sequences:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathcal{L}\left(\theta;x_{1:L}\right)=P_{\theta}\left(x_{1:L}\right)=\sum_{y_{1:L}\in\left[m\right]^{L}}P_{\theta}\left(x_{1:L},y_{1:L}\right)\label{Likelihoods}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The probability 
\begin_inset Formula $P_{\theta}\left(x_{1:L}\right)$
\end_inset

 is called the incomplete-data likelihood function and the probability 
\begin_inset Formula $P_{\theta}\left(x_{1:L},y_{1:L}\right)$
\end_inset

 is called the complete-data likelihood function.
 In the case of HMM with parameters 
\begin_inset Formula $\theta$
\end_inset

, the complete-data can be calculated by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P_{\theta}\left(x_{1:L},y_{1:L}\right)=P_{\theta}\left(y_{1}\right)\cdot P_{\theta}\left(x_{1}|y_{1}\right)\cdot\prod_{i=2}^{N}P_{\theta}\left(y_{i}|y_{i-1}\right)\cdot P_{\theta}\left(x_{i}|y_{i}\right)=\pi_{y_{1}}E_{y_{1},x_{1}}\prod_{i=2}^{L}T_{y_{i-1},y_{i}}E_{y_{i},x_{i}}\label{Complete-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Although the computation of the complete-data likelihood of 
\begin_inset Formula $\theta$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Complete-Likelihood"

\end_inset

 is linear-by-L, naively computing the incomplete-data likelihood as in
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Likelihoods"

\end_inset

 involves the summation of all possible hidden sequences, an impracticable
 exponential-by-L operation.
 A dynamic approach had overcame this gap, to utilizing the Markovian memoryless
ness of HMM, and answers both the likelihood and the posterior questions
 we raised above.
 This approach is called Forward-Backward algorithm, and it was suggested
 as a step in the Baum-Welch algorithm (
\begin_inset CommandInset citation
LatexCommand citet
key "key-4"

\end_inset

), which is a EM algorithm for finding the unknown 
\begin_inset Formula $\theta$
\end_inset

 given a observed sequence, further described in a later section.
 In the Forward-Backward algorithm, two matrices of size 
\begin_inset Formula $m\times L$
\end_inset

 are dynamically calculated, holding the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P_{\theta}\left(y_{t}=j,x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
\begin_inset Newpage newpage
\end_inset

Forward Algorithm
\end_layout

\begin_layout Standard
The forward probabilities matrix 
\begin_inset Formula $\alpha$
\end_inset

 holds the probability that a sequence 
\begin_inset Formula $x_{1:t}$
\end_inset

 was emitted and that the hidden sequence ended with the state j:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P_{\theta}\left(y_{t}=j,x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
It is calculated by the dynamic algorithm:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Forward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[2,...,L]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,t}=\sum_{j'\in[m]}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The building of the table is based on the HMM basic assumptions that each
 hidden state 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent only on the previous one 
\begin_inset Formula $y_{t-1}$
\end_inset

 and that each observed variable 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent only on its hidden state that emitted it 
\begin_inset Formula $y_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P_{\theta}\left(y_{t}=j,x_{1:t}\right)=P_{\theta}\left(x_{t}|y_{t}=j,x_{1:t-1}\right)\cdot P_{\theta}\left(y_{t}=j,x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P_{\theta}\left(x_{t}|y_{t}=j\right)\cdot\sum_{j'\in[m]}P_{\theta}\left(y_{t}=j|y_{t-1}=j'\right)\cdot P_{\theta}\left(y_{t-1}=j',x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=E_{j,x_{t}}\cdot\sum_{j'\in[m]}T_{j',j}\cdot\alpha_{j',t-1}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HMM forward Algorithm.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "ForwAlg"

\end_inset

Forward algorithm dynamically calculates the probability stored in 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 by using the previously calculated 
\begin_inset Formula $\alpha_{j',t-1}$
\end_inset

 values.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Subsubsection*
Backward Algorithm
\end_layout

\begin_layout Standard
The backwards probabilities matrix 
\begin_inset Formula $\beta$
\end_inset

 holds the probability that a sequence 
\begin_inset Formula $x_{t+1:L}$
\end_inset

 was emitted given the hidden state at position t had value j:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)
\]

\end_inset


\end_layout

\begin_layout Standard
It is calculated by the dynamic algorithm:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Backward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{1:m,L}=1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[L-1,...,1]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{j,t}=\sum_{j'\in[m]}\beta_{j',t+1}\cdot T_{j,j'}\cdot E_{j',x_{t}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This matrix building process is similarly explained by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)=\sum_{j'\in[m]}P_{\theta}\left(y_{t+1}=j',x_{t+1:L}|y_{t}=j\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\sum_{j'\in[m]}P_{\theta}\left(x_{t+2:L}|y_{t+1}=j'\right)\cdot P_{\theta}\left(x_{t+1}|y_{t+1}=j'\right)\cdot P_{\theta}\left(y_{t+1}=j'|y_{t}=j\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{j'\in[m]}\beta_{j',t+1}\cdot E_{j',x_{t+1}}\cdot T_{j,j'}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HMM backward Algorithm.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "BackAlg"

\end_inset

Backward algorithm dynamically calculates the probability stored in 
\begin_inset Formula $\beta_{j,t}$
\end_inset

 by using the previously calculated 
\begin_inset Formula $\beta_{j',t+1}$
\end_inset

 values
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Once we obtain 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 probabilities, the incomplete-data likelihood of HMM can finally be easily
 calculated:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P_{\theta}\left(x_{1:L}\right)=\sum_{j\in[m]}P_{\theta}\left(y_{L}=j,x_{1:L}\right)=\sum_{j\in[m]}\alpha_{j,L}\label{Incomplete-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
And so can the posterior probability be computed:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P_{\theta}\left(y_{t}=j|x_{1:L}\right)=\frac{P_{\theta}\left(y_{t}=j,x_{1:L}\right)}{P\left(x_{1:L}\right)}=\frac{P_{\theta}\left(y_{t}=j,x_{1:t}\right)\cdot P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)}{P\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{P_{\theta}\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
HMM Limitations
\end_layout

\begin_layout Standard
Although HMM is simple and efficient, applying it on DNA sequences has a
 major disadvantage: the inherit Markovian lack-of-memory property.
 That is, the model's next state is always dependent only on the previous
 state, without further history consideration.
 For the task of emitting a TFBS motif, where each position has a different
 emission distribution depending on the location in the motif, a HMM would
 need to different hidden states per position in the motif.
 This means that for an HMM to be able to emit even a small number of short
 motifs, it needs to hold a large number of states that require learning
 a large number of parameters, e.g.
 for the ability to emit 50 motifs of length 5, an HMM needs to have over
 60,000 parameters.
 Furthermore, the enhancer modeling task at hand is even more complex, since
 we would like to model multiple enhancers and backgrounds states, each
 having different probability of emitting motifs and unique k-order emission
 distribution when not in those motifs.
 For our data structure prior assumption the required number of model's
 parameters would have been about 
\begin_inset Formula $10^{7}$
\end_inset

, large enough to introduce problems such as unfeasible memory complexity
 and overfitting.
\end_layout

\begin_layout Standard
A common way to avoid overfitting the data when training machine learning
 models is reducing the model's complexity by fixing some of its parameters.
 Our proposed HOP-HMM addresses both the memory issue and the overfitting
 issue while remaining equivalent to a regularized HMM with a large number
 of states with fixed parameters.
 Namely, most of the transition probabilities are fixed to zero and therefore
 never stored in memory, and some of the emission probabilities are predetermine
d and are fixed during the training.
 This allows us to learn a model with the enhancer prior assumptions of
 motifs and high-order emission without overfitting, and with reasonable
 memory complexity.
\end_layout

\begin_layout Subsubsection*
Generalized HMM
\end_layout

\begin_layout Standard
In a generalized HMM (GHMM), the transition or the emission are sampled
 from a different distribution type assigned to each of the states in the
 model.
 Some of the states in the system may emit zero or multiple observable variables
, sampled from custom emission models specifically tailored for the expected
 scenario.
 Such models were used for genes prediction in the 1990's (
\begin_inset CommandInset citation
LatexCommand citet
key "key-24"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citet
key "key-22"

\end_inset

), where specific exon states emitted codons instead of single nucleotides
 and feed forward neural networks were used for evaluating the probability
 of certain transitions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/sHMM_two_states.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "GHMM"

\end_inset

GHMM with a TF state which emits using a PWM.
 A) the model has one background hidden state (yellow) and one TF hidden
 state.
 Although the TF state emits 5 bases motifs, the rest of the emissions,
 transitions and start probabilities remain the same as in a regular HMM
 (B,C,D).
 An example output generated from such model in (E) shows the TFBS motif
 sampled in an arbitrary location inside a sequence.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another generalization made to the HMM called higher-order HMM uses conditional
 distribution by making the transition and emission dependent on previous
 hidden states (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-17"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-41"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-47"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-38"

\end_inset

).
 Although these HMM variants are capable of expressing a more complex structure
 of DNA sequence (different kmers frequencies in the genomic regions), the
 number of parameters required for DNA analysis tends to rise with the increase
 of the assumed complexity of the DNA structure.
 The increase of hidden states needed may introduce overfitting in the learning
 process, when the data size is limited.
\end_layout

\begin_layout Standard
Instead of higher-order emission which depends on the previous hidden states
 was previous used, high-order emission which depends on previous emitted
 observable variables is a less researched field.
 Such a HMM variant fits better to the locality nature for the task of emission
 kmer structures, but it only requires 
\begin_inset Formula $O\left(m^{2}+4^{K}\right)$
\end_inset

 compared to 
\begin_inset Formula $O$
\end_inset

 
\begin_inset Formula $\left(m^{K}\right)$
\end_inset

 parameters that would have been required for holding a kmer distribution
 in a regular HMM, where m is the number of hidden states of the HOP-HMM,
 and K is the number of previous states in the dependency.
 
\end_layout

\begin_layout Subsection*
HOP-HMM
\end_layout

\begin_layout Standard
Here we present HOP-HMM, a GHMM, that is well fitted to utilize the structure
 of enhancers containing TFBSs inside them, due to the TFBS emitting TF-states
 that take part in the generation process of the sequence.
 Due to the assumed local physical nature of the TF binding of the DNA sequence
 and success of HMM in gene prediction, we think the memorylessness of HMMs
 fit well to the task of enhancer prediction.
 HOP-HMM balances between the Markovian memorylessness and the observed
 kmer of the TFBS present in regulatory regions in the DNA.
\end_layout

\begin_layout Standard
HOP-HMM extends the GHMM model of 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-64"

\end_inset

, where some of the hidden states emit TFBS sampled from PWMs to predict
 enhancers location in the genome.
 In HOP-HMM we added the high order conditional emission probability on
 non-TF-states.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP_HMM_two_states.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM1"

\end_inset

Small HOP-HMM that has one background-state which emits a single observable
 variable, and one TF-state which emits multiple observable variable that
 represent a TFBS sampled from a PWM.
 Unlike GHMM, in HOP-HMM TF-state can not be the starting hidden state and
 the background-state is has 2-order emission, meaning it is conditioned
 on the previous observable variable.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Transition_repack.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "TGCompact"

\end_inset

Instead of holding a single sparse 8
\begin_inset Formula $\times$
\end_inset

8 transition matrix, an alternative compact form holds only the non-fixed
 transition probabilities, split into T and G matrices.
 The non-fixed transition probabilities held in the compact form are the
 ones in between background-states, and between background-states to their
 TF-states (outlined with blue).
 A concatenation of a row in T and G holds the probability of the next hidden-st
ate given the current background-state.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP_HMM_multi_states.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM2"

\end_inset

A) A more complex HOP-HMM with two background-state 
\begin_inset Formula $BG_{1}$
\end_inset

 and 
\begin_inset Formula $BG_{2}$
\end_inset

, where each has 3 TF-states.
 B) each of the background-states has its own 2-order emission distribution
 in a 4x4 matrix.
 C) The start hidden state distribution 
\begin_inset Formula $\pi$
\end_inset

 allows only background-states to start the hidden sequence.
 D) The transition probability is held by matrices T and G.
 E) The example generated sequence is built out of two types of sequences,
 each has its own TFBS frequency and background nucleotide bigram frequency,
 representing two alternating types of enhancers.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Hidden States Indexing
\end_layout

\begin_layout Standard
We use two indices to describe a hidden-state in HOP-HMM:
\end_layout

\begin_layout Itemize
Background-states are indexed as 
\begin_inset Formula $(j,0)$
\end_inset

 where 
\begin_inset Formula $j\in[m]$
\end_inset

 and 
\begin_inset Formula $m$
\end_inset

 is the number background-states.
\end_layout

\begin_layout Itemize
TF-states are indexed as 
\begin_inset Formula $(j,l)$
\end_inset

 where 
\begin_inset Formula $j\in[m]$
\end_inset

, 
\begin_inset Formula $l\in[k]$
\end_inset

.
 and 
\begin_inset Formula $k$
\end_inset

 is the number of TF-states each of the background-states has.
\end_layout

\begin_layout Standard
For example, in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM2"

\end_inset

 we see a HOP-HMM with 
\begin_inset Formula $m=2$
\end_inset

 and 
\begin_inset Formula $k=3$
\end_inset

 and a total of 8 hidden-states.
 The TF-state indexed 
\begin_inset Formula $(j,l)$
\end_inset

 belongs to the 
\begin_inset Formula $(j,0)$
\end_inset

 background-state (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM3"

\end_inset

), and the only allowed transfer into 
\begin_inset Formula $(j,l)$
\end_inset

 only from its background-state 
\begin_inset Formula $(j,0)$
\end_inset

.
 Note that we used a simpler 
\begin_inset Formula $BG_{j}$
\end_inset

 notation in figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM1"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM2"

\end_inset

 for readability.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP_HMM_general_mk.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\shape italic
\emph on
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM3"

\end_inset

General hidden states graph of HOP-HMM.
 Each row represents a sequence type, where each of the 
\begin_inset Formula $m$
\end_inset

 background-states (yellow) has 
\begin_inset Formula $k$
\end_inset


\shape default
\emph default
 TF-state
\shape italic
\emph on
s (green).
 Not all transitions are possible, moving between the rows is possible only
 by a background-state to background-state transition.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
While most background-states 
\begin_inset Formula $(j,0)$
\end_inset

 represent an enhancer type, we also would like to model true background
 regions in between the enhancer that carry no regulatory role and have
 no TFBSs.
 For that end we predefine one or more background-states as non-enhancers
 by restricting their transfer probability into their TF-states, as seen
 in the results section.
\end_layout

\begin_layout Subsubsection*
Emission
\end_layout

\begin_layout Standard
HOP-HMM is defined with k PWMs 
\begin_inset Formula $W_{1},W_{2},...,W_{k}$
\end_inset

 that remain fixed during training.
 Each of the k PWMs is shared with m TF-states, e.g.
 the PWM 
\begin_inset Formula $W_{l}$
\end_inset

, where 
\begin_inset Formula $l\in[k]$
\end_inset

, is shared between subs-states 
\begin_inset Formula $(1,l),(2,l),...,(m,l)$
\end_inset

 and is used for the TF-state emission sampling.
 The PWMs vary in their column amounts (as the different TFBSs vary in length),
 where each column represents a nucleotide distribution at that position.
 When the model enters a TF-state, it emits a motif by sampling from a PWM
 column by column independently, as described in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "GHMM"

\end_inset

.
\end_layout

\begin_layout Standard
The background-states, denoted as 
\begin_inset Formula $(1,0),(2,0),...,(m,0)$
\end_inset

, are responsible for the emission of inter-TFBS parts of the enhancers
 lacking long motifs.
 Similarly to regular states in HMM, background-states emit single nucleotides,
 where their emission is conditional on the previous of letters emitted
 in the DNA sequence.
 The emission from background-states is done by sampling a nucleotide from
 the distributions stored in E tensor.
 E dimension is o+1, and its size is 
\begin_inset Formula $\text{ }m\times4\times4\times...\times4$
\end_inset

 (with o fours) and its values are describe the emission probability 
\begin_inset Formula $E_{j,x_{t-o+1},x_{t-o+2},...,x_{t}}=P\left(x_{t}|y_{t}=(j,0),x_{t-o+1},...,x_{t-1}\right)$
\end_inset

, meaning that when 
\begin_inset Formula $x_{t}$
\end_inset

 is sampled by the model, the preceding 
\begin_inset Formula $o-1$
\end_inset

 observed variables are used as indices of the tensor for getting emission
 probability vector 
\begin_inset Formula $E_{j,x_{t-o+1},x_{t-o+2},...,x_{t-1},*}$
\end_inset

.
\end_layout

\begin_layout Standard
For the first variables emitted in the sequence, the missing dimensions
 of the preceding variables are summed to form the probability vector, e.g.
 if 
\begin_inset Formula $t=o-1$
\end_inset

, a single variable is missing for emitting 
\begin_inset Formula $x_{t}$
\end_inset

 and the distribution used for emission sampling is 
\begin_inset Formula $\sum_{i\in[4]}\frac{E_{j,i,x_{1},...,x_{t-1}}}{4}$
\end_inset

.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Subsubsection*
Transition
\end_layout

\begin_layout Standard
In HOP-HMM, the first hidden state in a sequence can only be a background-state.
 The first background-state, as in HMM, is chosen by sampling from 
\begin_inset Formula $\pi,$
\end_inset

 a probability vector 
\begin_inset Formula $\pi_{j}=P(y_{1}=(j,0))$
\end_inset

.
 Once in a background-state, the model can only transit into a small subset
 of states, and since most of the possible transition are not allowed, a
 single transition matrix from all states to all states would be sparse.
 Instead, as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "TGCompact"

\end_inset

, we hold only the possible transition probabilities in two matrices, representi
ng the two types of allowed transitions:
\end_layout

\begin_layout Itemize
T for background-state to background-state transitions, a 
\begin_inset Formula $m\times m$
\end_inset

 matrix where 
\begin_inset Formula $T_{j_{1},j_{2}}=P\left(y_{t+1}=(j_{2},0)|y_{t}=(j_{1},0)\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
G for background-state to TF-state transitions a 
\begin_inset Formula $m\times k$
\end_inset

 matrix where 
\begin_inset Formula $G_{j,l}=P\left(y_{t+1:t+|W_{l}|}=(j,l)|y_{t}=(j,0)\right)$
\end_inset

.
\end_layout

\begin_layout Standard
When in a background-state, after the observable variable emission, the
 model samples its next hidden state from a probability vector that is a
 concatenation of a row in T and a row in G.
 If a TF-state is chosen, after the TF-state's motif emission, the model
 returns back to the background-state to emit another single observable
 variable and so on.
\end_layout

\begin_layout Part*
Methods
\end_layout

\begin_layout Subsection*
Baum-Welch Algorithm
\end_layout

\begin_layout Standard
When fitting a HMM to a DNA sequence, we seek the parameters 
\begin_inset Formula $\theta^{*}$
\end_inset

 that best explain the sequence via a algorithm called Baum-Welch algorithm,
 which is a special case of EM algorithm.
 Formally, given the observed DNA sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

, we would like to find the parameters that maximize the incomplete-likelihood:
 
\begin_inset Formula 
\[
\theta^{*}=argmax_{\theta}\mathcal{L}\left(\theta|x_{1:L}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Even though the incomplete-data likelihood of HMM in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Likelihoods"

\end_inset

 is derivable by 
\begin_inset Formula $\theta$
\end_inset

, optimizing it is as difficult as calculating it and therefore is also
 impractical.
 Instead, the strategy of the EM algorithm is to optimize the expected value
 of the complete-data log-likelihood 
\begin_inset Formula $log\left(P\left(x_{1:L},y_{1:L}|\theta^{'}\right)\right)$
\end_inset

 over all possible 
\begin_inset Formula $y_{1:L}$
\end_inset

 where 
\begin_inset Formula $\theta^{'}$
\end_inset

 is the model's parameters from previous EM iteration (or guessed parameters
 in the first iteration) and while assuming a fixed observed 
\begin_inset Formula $x_{1:L}$
\end_inset

, as it is the given DNA sequence.
 For this task we define our target function Q:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Q\left(\theta,\theta^{'}\right)=E_{Y}\left[log\left(P_{\theta}\left(x_{1:L},y_{1:L}\right)\right)|x_{1:L},\theta^{'}\right]=\sum_{y_{1:L}\in\left[m\right]^{L}}log\left(P_{\theta}\left(x_{1:L},y_{1:L}\right)\right)\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)\label{Q}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Here E is expressing an expected value, not to be confused with the HMM
 emission probability.
 Every EM iteration is built out of two parts called the E (expectation)
 step and the M (maximization) step.
 In the E-step we calculate the probabilities needed for the maximization
 of Q and in the M-step we infer the 
\begin_inset Formula $\theta$
\end_inset

 that maximizes it.
 We will update the 
\begin_inset Formula $\theta$
\end_inset

 for maximizing 
\begin_inset Formula $Q\left(\theta,\theta^{'}\right)$
\end_inset

 in every M-step of the EM algorithm until convergence.
 
\end_layout

\begin_layout Standard
Using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Complete-Likelihood"

\end_inset

 we will split the Q function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Q"

\end_inset

 into three independent parts:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{y_{1:L}\in\left[m\right]^{L}}log\pi_{y_{1}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)\\
+ & \sum_{y_{1:L}\in\left[m\right]^{L}}\left(\sum_{t\in2...L}logT_{y_{t-1},y_{t}}\right)\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)\\
+ & \sum_{y_{1:L}\in\left[m\right]^{L}}\left(\sum_{t\in[L]}logE_{y_{t},x_{t}}\right)\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
then by manipulating the summation, the exponential state sequence summation
 could be simplified to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{j\in[m]}log\pi_{j}\cdot P_{\theta^{'}}\left(x_{1:L},y_{1}=j\right)\\
+ & \sum_{t\in2...L}\sum_{j_{1},j_{2}\in[m]}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)\\
+ & \sum_{t\in[L]}\sum_{j\in[m]}logE_{j,x_{t}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Each of the three parts above is a set of constraint linear functions that
 could be derived and maximized independently using a Lagrange multipliers,
 under the following probability constrains:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j\in[m]}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j_{2}\in[m]}T_{j_{1},j_{2}}=1$
\end_inset

 for all 
\begin_inset Formula $j_{1}\in[m]$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{b\in[n]}E_{j,b}=1$
\end_inset

 for all 
\begin_inset Formula $j\in[n]$
\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $m$
\end_inset

 is the number of different hidden states and 
\begin_inset Formula $n$
\end_inset

 is the number of different observed variables (4 in our case of DNA).
\end_layout

\begin_layout Standard
First, we start with maximizing the first 
\begin_inset Formula $\pi$
\end_inset

 part using Lagrange multiplier 
\begin_inset Formula $\lambda$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\pi_{j}}\left(\sum_{j'\in[m]}log\pi_{j'}P_{\theta^{'}}\left(x_{1:L},y_{1}=j'\right)+\lambda\left(1-\sum_{j'\in[m]}\pi_{j'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
we derive the term and get 
\begin_inset Formula $\frac{P_{\theta^{'}}\left(x_{1:L},y_{1}=j\right)}{\pi_{j}}=\lambda$
\end_inset

 for 
\begin_inset Formula $j\in[m]$
\end_inset

.
 Then we use these m equations to get 
\begin_inset Formula $\lambda=P_{\theta^{'}}\left(x_{1:L}\right)$
\end_inset

, which yields the reestimated 
\begin_inset Formula $\pi_{j}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\pi_{j}=\frac{P_{\theta^{'}}\left(x_{1:L},y_{1}=j\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=P_{\theta^{'}}\left(y_{1}=j|x_{1:L}\right)\label{Pi-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Second, we define a Lagrange multipliers 
\begin_inset Formula $\lambda_{j_{1}}$
\end_inset

 for each 
\begin_inset Formula $j_{1}\in[m]$
\end_inset

 for the 
\begin_inset Formula $T$
\end_inset

 part:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial T_{j_{1},j_{2}}}\left(\sum_{t\in2...L}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
which yields 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)}{T_{j_{1},j_{2}}}$
\end_inset

 for 
\begin_inset Formula $j_{2}\in[m]$
\end_inset

 
\end_layout

\begin_layout Standard
when the m equations are summed, gives 
\begin_inset Formula $\lambda_{j_{1}}=\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1}\right)$
\end_inset

 
\end_layout

\begin_layout Standard
therefore the update of 
\begin_inset Formula $T_{j_{1},j_{2}}$
\end_inset

 will be:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T_{j_{1},j_{2}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1}\right)}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=j_{1},y_{t}=j_{2}|x_{1:L}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=j_{1}|x_{1:L}\right)}\label{T-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Finally, we'll define multiplier 
\begin_inset Formula $\lambda_{j}$
\end_inset

 for every 
\begin_inset Formula $j\in[m]$
\end_inset

 for the 
\begin_inset Formula $E$
\end_inset

 part:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial E_{j,b}}\left(\sum_{t\in[L]}logE_{j,x_{t}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)+\lambda_{j}\left(1-\sum_{b'\in[n]}E_{j,b'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
this step is slightly trickier due to the derivation of 
\begin_inset Formula $\frac{\partial E_{j,x_{t}}}{\partial E_{j,b}}=\boldsymbol{1}_{b}(x_{t})$
\end_inset

 where 
\begin_inset Formula $\boldsymbol{1}_{b}(x_{t})=\begin{cases}
1 & b=x_{t}\\
0 & otherwise
\end{cases}$
\end_inset

.
\end_layout

\begin_layout Standard
we get 
\begin_inset Formula $\lambda_{j}=\frac{\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)\cdot\boldsymbol{1}_{b}(x_{t})}{E_{j,b}}$
\end_inset

 for 
\begin_inset Formula $b\in[n]$
\end_inset

 
\end_layout

\begin_layout Standard
when all n equations are summed, gives 
\begin_inset Formula $\lambda_{j}=\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)\cdot\boldsymbol{1}_{b}(x_{t})$
\end_inset

 
\end_layout

\begin_layout Standard
therefore the update of 
\begin_inset Formula $E_{j,b}$
\end_inset

 will be:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E_{j,b}=\frac{\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)\boldsymbol{\cdot1}_{b}(x_{t})}{\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)}=\frac{\sum_{t\in[L]}P_{\theta^{'}}\left(y_{t}=j|x_{1:L}\right)\boldsymbol{1}_{b}(x_{t})}{\sum_{t\in[L]}P_{\theta^{'}}\left(y_{t}=j|x_{1:L}\right)}\label{E-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For us to be able to calculate these reestimation of 
\begin_inset Formula $\theta$
\end_inset

 as written in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "E-Update"

\end_inset

, we are still left with the calculation of the two probabilities terms
 inside them.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
To resemble the notations coined in 
\begin_inset CommandInset citation
LatexCommand citet
key "key-50"

\end_inset

, the first widely accepted HMM application, we'll denote these as 
\begin_inset Formula $\gamma$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\gamma_{t,j}=P_{\theta^{'}}\left(y_{t}=j|x_{1:L}\right)\label{gamma}
\end{equation}

\end_inset

 
\begin_inset Formula 
\begin{equation}
\xi_{t,j_{1},j_{2}}=P_{\theta^{'}}\left(y_{t-1}=j_{1},y_{t}=j_{2}|x_{1:L}\right)\label{xi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We will use 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Incomplete-Likelihood"

\end_inset

 and the output of the Forward-Backward algorithm 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 for their calculation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\gamma_{t,j}=\frac{P_{\theta^{'}}\left(y_{t}=j,x_{1:L}\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=\frac{P_{\theta^{'}}\left(x_{1:L}|y_{t}=j\right)\cdot P_{\theta^{'}}\left(y_{t}=j\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=\frac{P_{\theta^{'}}\left(y_{t}=j,x_{1:t}\right)\cdot P_{\theta^{'}}\left(x_{t+1:L}|y_{t}=j\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{\sum_{j\in[m]}\alpha_{j,L}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\xi_{t,j_{1},j_{2}}=\frac{P\left(y_{t-1}=j_{1},y_{t]}=j_{2},x_{1:L}\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P_{\theta^{'}}\left(y_{t-1}=j_{1},x_{1:t-1}\right)\cdot P_{\theta^{'}}\left(y_{t}=j_{2}|y_{t-1}=j_{1}\right)\cdot P_{\theta^{'}}\left(x_{t}|y_{t}=j_{2}\right)\cdot P_{\theta^{'}}\left(x_{t+1:L}|y_{t}=j_{2}\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2},}\cdot E_{j_{2},x_{t}}\cdot\beta_{j',t}}{\sum_{j\in[m]}\alpha_{j,L}}
\]

\end_inset

The calculation of 
\begin_inset Formula $\alpha,\beta,\gamma$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset

 matrices is considered the E-step of Baum-Welch algorithm, and they allow
 us to update 
\begin_inset Formula $\theta$
\end_inset

 and finish the EM iteration.
\end_layout

\begin_layout Section*
Baum-Welch Algorithm for HOP-HMM
\end_layout

\begin_layout Standard
The transitions and emissions mechanisms of HOP-HMM are different, and therefore
 the complete-data likelihood of HOP-HMM requires different calculation
 for the Baum-Welch algorithm to hold.
 The Baum-Welch algorithm can be adjusted to infer the parameters of the
 HOP-HMM variant 
\begin_inset Formula $\theta=\{\pi,E,G,T\}$
\end_inset

 from a DNA sequence X.
 As in the regular Baum-Welch algorithm covered in the previous section,
 given a sequence X at each EM iteration we optimize the Q function in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Q"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{j\in[m]}log\pi_{j}\cdot P_{\theta^{'}}\left(x_{1:L},y_{1}=(j,0)\right)\\
+ & \sum_{t\in2...L}\sum_{j_{1},j_{2}\in[m]}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)\\
+ & \sum_{t\in2...L}\sum_{j\in[m],l\in[k]}logG_{j,l}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j,0),y_{t}=(j,l)\right)\\
+ & \sum_{t\in o,...,L}\sum_{j\in[m]}logE_{j,b_{1},...,x_{t}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t}=(j,0)\right)\\
+ & \sum_{t\in[L]}\sum_{l\in[k]}logL_{W}(x_{t:t+|W_{l}|-1})\cdot P_{\theta^{'}}\left(x_{1:L},y_{t:t+|W_{l}|-1S}=(j,l)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $L_{W}(\overline{x})$
\end_inset

 is the likelihood of the TFBS 
\begin_inset Formula $\overline{x}$
\end_inset

 to be emitted by PWM 
\begin_inset Formula $W$
\end_inset

: 
\begin_inset Formula $L_{M}(\overline{x})=P(\overline{x}|W)=\underset{i\in\{1,...,|\overline{x}|\}}{\prod}W_{\overline{x}_{i},i}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Note that the last addition component, which holds the TFBS log likelihood,
 does not contain elements from 
\begin_inset Formula $\theta$
\end_inset

 as the PWMs are not learned in HOP-HMM, and therefore it is not reestimated
 in the M-steps.
\end_layout

\begin_layout Standard
The 
\begin_inset Formula $\theta^{*}$
\end_inset

 which optimizes 
\begin_inset Formula $Q$
\end_inset

 here, 
\begin_inset Formula $\theta^{*}=argmax_{\theta}Q(\theta,\theta')$
\end_inset

, is archived by optimizing its 3 independent parts as well, each having
 its own constrain under which we optimize 
\begin_inset Formula $Q$
\end_inset

 are:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j\in[m]}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j_{2}\in[m]}T_{j_{1},j_{2}}+\sum_{l\in[k]}G_{j_{1}l}=1$
\end_inset

 for all 
\begin_inset Formula $j_{1}\in[m]$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{b_{o}\in[n]}E_{j,b_{1},...,b_{o}}=1$
\end_inset

 for all 
\begin_inset Formula $j\in[n]$
\end_inset


\end_layout

\begin_layout Paragraph
M-step
\end_layout

\begin_layout Standard
The 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $E$
\end_inset

 conditions produce almost exact same maximization as in regular Baum-Welch
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Pi-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "E-Update"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\pi_{j}=\frac{P_{\theta^{'}}\left(x_{1:L},y_{1}=(j,0)|\theta^{'}\right)}{P_{\theta^{'}}\left(x_{1:L}|\theta^{'}\right)}=P_{\theta^{'}}\left(y_{1}=(j,0)|x_{1:L}\right)\label{HOP-Pi-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E_{j,b_{1},...,b_{o}}=\frac{\sum_{t\in o,...,L}P_{\theta^{'}}\left(x_{1:L},y_{t}=(j,0)\right)\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1,...,t})}{\sum_{t\in o,...,L}P_{\theta^{'}}\left(x_{1:L},y_{t}=(j,0)\right)}\label{HOP-E-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
As for the second condition of 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

, we will define the Lagrange multipliers 
\begin_inset Formula $\lambda_{j_{1}}$
\end_inset

 for 
\begin_inset Formula $j_{1}\in[m]$
\end_inset

 and derive the two terms that contain 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial T_{j_{1,}j_{2}}}\left(\sum_{t\in2...L}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}-\sum_{l\in[k]}G_{j_{1}l}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial G_{j_{1},l}}\left(\sum_{t\in2...L}logG_{j_{1},l}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l)\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}-\sum_{l\in[k]}G_{j_{1}l}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
which yields 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)}{T_{j_{1},j_{2}}}$
\end_inset

 and 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l)\right)}{G_{j_{1}l}}$
\end_inset

 for 
\begin_inset Formula $j_{2}\in[m]$
\end_inset

 and 
\begin_inset Formula $l\in[k]$
\end_inset

.
 
\end_layout

\begin_layout Standard
When the 
\begin_inset Formula $m+k$
\end_inset

 equations are summed we receive:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lambda_{j_{1}}=\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)+\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
which gives us the updates 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T_{j_{1},j_{2}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0)\right)}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j_{1},0)|x_{1:L}\right)}\label{HOP-T-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
G_{j,l}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j,0),y_{t}=(j,l)\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j,0)\right)}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j,0)|x_{1:L}\right)}\label{HOP-G-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection*
E-step
\end_layout

\begin_layout Standard
Preceding the M-step where we update components of 
\begin_inset Formula $\theta$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-E-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-G-Update"

\end_inset

, we will calculate the three probability terms inside them in the E-step,
 denoted as 
\begin_inset Formula $\gamma,$
\end_inset

 
\begin_inset Formula $\xi$
\end_inset

 and 
\begin_inset Formula $\eta$
\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

 
\begin_inset Formula 
\begin{equation}
\gamma_{j,t}=P_{\theta^{'}}\left(y_{t}=(j,0)|x_{1:L}\right)\label{HOP-gamma}
\end{equation}

\end_inset

 
\begin_inset Formula 
\begin{equation}
\xi_{j_{1},j_{2},t}=P_{\theta^{'}}\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)\label{HOP-xi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\eta_{j,l,t}=P_{\theta^{'}}\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)\label{HOP-eta}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For the calculation of these probabilities, we first need to calculate the
 forward and backward probabilities output from an HOP-HMM adjusted Forward-Back
ward algorithm.
 In this HOP-Forward-Backward algorithm, we will only build the probabilities
 for being in background-states since the TF-states probabilities are not
 needed in the later parts of the E-step.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0)\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
HOP-Forward Algorithm
\end_layout

\begin_layout Standard
We calculate 
\begin_inset Formula $\alpha$
\end_inset

 of size 
\begin_inset Formula $m\times L$
\end_inset

, iterating over 
\begin_inset Formula $t=1,2,...,L$
\end_inset

 as following:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP Forward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[2,...,L]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,t}=\underset{\text{background-state transitions}}{\underbrace{\sum_{j'\in[m]}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $+\underset{\text{TF-state transitions}}{\underbrace{\sum_{l\in[k]}\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Calculation notes: In the beginning of the sequence, when 
\begin_inset Formula $1\leq t<o$
\end_inset

 , part of the preceding observable variables are missing.
 Since E has 
\begin_inset Formula $o+1$
\end_inset

 dimensions, 
\begin_inset Formula $E_{j,x_{1},...,x_{t}}$
\end_inset

 is not defined, so we define it here as: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{j,x_{1},...,x_{t}}=\underset{b_{1},...,b_{o-t}\in\{A,C,G,T\}}{\sum}\frac{1}{4^{o-t}}\cdot E_{j,b_{1},..,.b_{o-t},x_{1},...,x_{t}}
\]

\end_inset

 
\end_layout

\begin_layout Standard
We used the fact that 
\begin_inset Formula $P(A)=\sum_{b\in B}P(b)\cdot P(A|b)$
\end_inset

 and the assumption that the observable variables preceding the sequence
 came from a uniform distribution.
 Also, when summing the TF-state transition part, PWMs 
\begin_inset Formula $W_{l}$
\end_inset

 with length equal or bigger than 
\begin_inset Formula $t+1$
\end_inset

 include out-of-sequence TFBS and are not part of the summation.
\end_layout

\begin_layout Subsubsection*
HOP-Backward Algorithm
\end_layout

\begin_layout Standard
For 
\begin_inset Formula $\beta$
\end_inset

 of size 
\begin_inset Formula $m\times L$
\end_inset

, we iterating over 
\begin_inset Formula $t=L,L-1,...,1$
\end_inset

 as following:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP Backward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{1:m,L}=1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[L-1,...,1]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{j,t}=\underset{\text{background-state transitions}}{\underbrace{\sum_{j'\in[m]}\beta_{j',t+1}\cdot E_{j',x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $+\underset{\text{TF-state transitions}}{\underbrace{\sum_{l\in[k]}\beta_{j,t+|W_{l}|+1}\cdot L_{W_{l}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t-o+|W_{l}|+2},...,x_{t+|W_{l}|+1}}\cdot G_{j,l}}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that when 
\begin_inset Formula $t>L-|W_{l}|$
\end_inset

, there are missing observable variables to fully calculate the TF-state
 transition.
 In these situations this contribution of these component to the summation
 is zero, meaning our HOP-HMM as the behavior of avoiding a transition into
 a TF-state when the PWM is too long to fit into the sequence X length.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP-EM forward Algorithm.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
In HOP-HMM, the Forward-Backward algorithm dynamic tables 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 cells are filled from both the adjacent background-states transitions and
 the background-states preceding or proceeding the motifs emitted by the
 TF-states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Forward Algorithm Explanation
\end_layout

\begin_layout Standard
We will now explain why the described dynamic calculation result with 
\begin_inset Formula $\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)$
\end_inset

 and 
\begin_inset Formula $\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0)\right)$
\end_inset

, starting with the forward probabilities 
\begin_inset Formula $\alpha$
\end_inset

.
 From the law of total probability, the probability 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 is the sum of probabilities of all the possible transition that ended in
 the background-state (j,0):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\underset{\text{background-state transitions}}{\underbrace{\underset{j'\in[m]}{\sum}P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)}}+\underset{\text{TF-state transitions}}{\underbrace{\underset{l\in[k]}{\sum}P\left(y_{t-|W_{l}|-1}=(j,0),y_{t-|W_{l}|:t-1}=(j,l),x_{1:t}\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard
right-side term of a TF-state transition can be split with the chain rule
 to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)= & \,P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot\\
 & \cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\\
 & \cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\\
 & \cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1},y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent only on 
\begin_inset Formula $y_{t}$
\end_inset

 and 
\begin_inset Formula $x_{t-o:t-1}$
\end_inset

 and since 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent on only 
\begin_inset Formula $y_{t-1}$
\end_inset

, we can simplify the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0)\right)\cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{t-o:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Standard
This process is similar to the background-state transition.
 Using the chain rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(x_{t}|y_{t}=(j,0),y_{t-1}=(j',0),x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Backward Algorithm Explanation
\end_layout

\begin_layout Standard
For the backward probabilities 
\begin_inset Formula $\beta,$
\end_inset

 the explanation is similar.
 The main difference between the regular HMM backward probability is the
 condition on the 
\begin_inset Formula $o-1$
\end_inset

 preceding observable variables 
\begin_inset Formula $x_{t-o+2:t}$
\end_inset

, which are necessary for the background-state emission is conditional on
 them.
\end_layout

\begin_layout Standard
Using the law of total probability:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{t+1:L}|y_{t}=(j,0),x_{t-o+2:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\underset{\text{background-state transition}}{\underbrace{\sum_{j'\in[m]}P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0),x_{t-o+2:t}\right)}}+\underset{\text{TF-state transition}}{\underbrace{\sum_{l\in[k]}P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard
For the background-state transition term, we can use the chain rule and
 the Markovian independence of the transitions and emissions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0),x_{t-o+2:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{t+2:L}|y_{t+1}=(j',0),y_{t}=(j,0),x_{t-o+2:t+1}\right)\cdot P\left(x_{t+1}|y_{t+1}=(j',0),y_{t}=(j,0),x_{t-o+2:t}\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0),x_{t-o+2:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{t+2:L}|y_{t+1}=(j',0),x_{t-o+3:t+1}\right)\cdot P\left(x_{t+1}|y_{t+1}=(j',0),x_{t-o+2:t}\right)\cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\beta_{j',t+1}\cdot E_{j',x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}
\]

\end_inset


\end_layout

\begin_layout Standard
For the TF-state transition term, we use once more the chain rule, followed
 the simplification using the conditional independencies of HMM:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{t+\left|W_{l}\right|+2:L}|x_{t+1:t+\left|W_{l}\right|+1},y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|x_{t+1:t+\left|W_{l}\right|},y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{t+\left|W_{l}\right|+2:L}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\beta_{j,t+|W_{l}|+1}\cdot E_{j,x_{t-o+|W_{l}|+1},...,x_{t+|W_{l}|+1}}\cdot L_{W_{l}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot G_{j,l}
\]

\end_inset


\end_layout

\begin_layout Standard
Using the forward and the backward probability matrices 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

, we can calculate the auxiliary probabilities 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

.
 The first probability that will help us for that is 
\begin_inset Formula $\psi$
\end_inset

, a matrix of size 
\begin_inset Formula $m\times k\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\psi_{j,l,t}=P\left(y_{t}=(j,0),y_{t+1}=(j,l),x_{1:L}\right)=P\left(y_{t}=(j,0),y_{t+1}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:L}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(y_{t}=(j,0),y_{t+1}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)\cdot P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{1:t},y_{t}=(j,0)\right)\cdot P\left(y_{t+1}=(j,l)|y_{t}=(j,0)\right)\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\text{\cdot}P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{t+|W_{l}|-o+3:t+|W_{l}|+1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\alpha_{j,t}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t+|W_{l}|-o+2},...,x_{t+|W_{l}|+1}}\cdot\beta_{j,t+|W_{l}|+1}
\]

\end_inset


\end_layout

\begin_layout Standard
The second probability is likelihood of the observed sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{1:L}\right)=\underset{j\in[m]}{\sum}\left(\alpha_{j,t}\cdot\beta_{j,t}+\underset{l\in\left[k\right],\ t'\in\left[|W_{l}|\right]}{\sum}\psi_{j,l,t-s}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Now we can calculate probability 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 of the background-state at a given position given the sequence X, denoted
 as 
\begin_inset Formula $\gamma$
\end_inset

 of size 
\begin_inset Formula $m\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\gamma_{j,t}=P\left(y_{t}=(j,0)|x_{1:L}\right)=\frac{P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{1:t},y_{t}=(j,0)\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{t-o+1:t},y_{t}=(j,0)\right)}{P\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
The probability 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 is the background-state to background-state transition given the sequence
 X, denoted as 
\begin_inset Formula $\xi$
\end_inset

 of size 
\begin_inset Formula $m\times m\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\xi_{j_{1},j_{2},t}=P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)=\frac{P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0),x_{1:L}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P\left(x_{1:t-1},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)\cdot P\left(x_{t:L}|y_{t}=(j_{2},0),x_{1:t-1}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P\left(x_{1:t-1},y_{t-1}=(j_{1},0)\right)\cdot P\left(y_{t}=(j_{2},0)|y_{t-1}=(j_{1},0)\right)\cdot P\left(x_{t}|y_{t}=(j_{2},0),x_{1:t-1}\right)\cdot P\left(x_{t+1:L}|y_{t}=(j_{2},0),x_{1:t-1}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+1},...,x_{t}}\cdot\beta_{j_{2},t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
Finally, the probability 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 is the background-state to background-state transition given the sequence
 X, denoted as 
\begin_inset Formula $\psi$
\end_inset

 of size 
\begin_inset Formula $m\times k\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\eta_{j,l,t}=P\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)=\frac{\psi_{j,l,t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
Now with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 at hand, we can complete the M-step and update 
\begin_inset Formula $\theta$
\end_inset

 by assigning the updates of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-E-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-G-Update"

\end_inset

.
\end_layout

\begin_layout Standard
The Baum-Welch algorithm adaptation for HOP-HMM, as described in this section:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP Baum-Welch
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for s=[1...MAX_EM_ITERATIONS]:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# E-step
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha=\text{hop\_forward\_algorithm(x_{1:L}) }$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta=\text{hop\_backward\_algorithm(x_{1:L}) }$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $l=[1,...,k]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\psi_{j,l,t}=\begin{cases}
\alpha_{j,t}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1:t+|W_{l}|}\right)\cdot E_{j,x_{t+|W_{l}|-o+2},...,x_{t+|W_{l}|+1}}\cdot\beta_{j,t+|W_{l}|+1} & |\,t+|W_{l}|+1\leq L\\
0 & |\,otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $Px=\underset{j\in[m]}{\sum}\alpha_{j,L}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\gamma_{j,t}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $l=[1,...,k]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\eta_{j,l,t}=\frac{\psi_{j,l,t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j_{1}=[1,...,m]$
\end_inset

, 
\begin_inset Formula $j_{2}=[1,...,m]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\xi_{j_{1},j_{2},t}=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+1},...,x_{t}}\cdot\beta_{j_{2},t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# M-step
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\pi_{j}=\gamma_{j,1}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $b_{1},...,b_{o}=[1,...,1]$
\end_inset

 
\begin_inset Formula $,...,[4,...,4]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $E_{j,b_{1},b_{2},...,b_{o}}=\frac{\sum_{t\in o,...,L}\gamma_{j,t}\cdot\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1},...,x_{t})}{\sum_{t\in o,...,L}\gamma_{j,t}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for  
\begin_inset Formula $l=[1,...,k]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $G_{j,l}=\frac{\underset{t\in2,...,L}{\sum}\eta_{j,l,t}}{\underset{t\in1,...,L-1}{\sum}\gamma_{j_{1},t}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j_{2}=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $T_{j,j_{2}}=\frac{\underset{t\in2,...,L}{\sum}\xi_{j,j_{2},t}}{\underset{t\in1,...,L-1}{\sum}\gamma_{j,t}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

If 
\begin_inset Formula $\theta$
\end_inset

 converged, break EM for loop 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Learning Multiple Sequences at Once
\end_layout

\begin_layout Standard
The algorithm is described with the input of a single sequence of observable
 variables 
\begin_inset Formula $x_{1:L}$
\end_inset

.
 In reality, we are faced with the task of learning 
\begin_inset Formula $\theta$
\end_inset

 from multiple sequences at once.
 In HOP-HMM we can use the multi-sequence method as in 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-50"

\end_inset

, where the E-step probabilities are calculated separately for each sequence,
 and in the M-step all positions from all sequences are summed for the parameter
s update.
\end_layout

\begin_layout Section*
Sequence States Inference
\end_layout

\begin_layout Subsubsection*
TODO: After description of HOP HMM, add inference section about: 1.
 viterbi 2.
 posterior 3: posterior sum hirizontal 4.
 posterior sum vertical 5.
 transition posterior (with figures all over)
\end_layout

\begin_layout Standard
Acquiring the maximal likelihood 
\begin_inset Formula $\theta$
\end_inset

 opens the door to several wanted inferences given a sequence:
\end_layout

\begin_layout Enumerate
Most likely hidden-state at any position in a sequence
\end_layout

\begin_layout Enumerate
Most likely hidden-state sequence
\end_layout

\begin_layout Enumerate
Dominant hidden-state in a short sequence
\end_layout

\begin_layout Standard
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 and 
\begin_inset Formula $\eta$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 can be used to solve the inference 1 for HOP-HMM.
 We aim to maximize here a posterior probability in a specific position:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
y_{t}^{*}=\underset{j\in[m],l\in[k]\cup\{0\}}{argmax}P\left(y_{t}=(j,l)|x_{1:L}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In regular HMM, we can approximate this by taking the max of the posterior
 probability held in 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "gamma"

\end_inset

 built by a 
\begin_inset Formula $\theta$
\end_inset

 that we learned with the Baum-Welch algorithm.
 In HOP-HMM 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 is not sufficient since it holds only the probability of background-state
 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,0)|x_{1:L}\right)$
\end_inset

.
 To calculate the posterior probability for TF-states, 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,l)|x_{1:L}\right)$
\end_inset

 where 
\begin_inset Formula $l>0$
\end_inset

 we sum all options of a TF-state 
\begin_inset Formula $(j,l)$
\end_inset

 that cover position 
\begin_inset Formula $t$
\end_inset

 as described in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PWM Posterior"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P_{\theta}\left(y_{t}=(j,l)|x_{1:L}\right)=\sum_{i\in\left[|W_{l}|\right]}P_{\theta}\left(y_{t-i+1:t-i+|W_{l}|}=(j,l)|x_{1:L}\right)=\sum_{i\in\left[|W_{l}|\right]}P_{\theta}\left(y_{t-i}=(j,0),y_{t-i+1}=(j,l)|x_{1:L}\right)=\sum_{i\in\left[|W_{l}|\right]}\eta_{t-i+1,j,l}
\]

\end_inset


\end_layout

\begin_layout Standard
Choosing the maximum value over 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,l)|x_{1:L}\right)$
\end_inset

 and 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,0)|x_{1:L}\right)$
\end_inset

 will give us the most likely state of 
\begin_inset Formula $\hat{y}_{t}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{y}_{t}=\underset{j\in[m],l\in[k]\cup\{0\}}{argmax}{\gamma_{j,t}}\cup{\sum_{i\in\left[|W_{l}|\right]}\eta_{t-i+1,j,l}}\label{PosteriorEstimation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/PWM_posterior_2.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "PWM Posterior"

\end_inset


\begin_inset Formula $P\left(y_{t}=(j,t)|x_{1:L}\right)$
\end_inset

 is the posterior probability to be in TF-state 
\begin_inset Formula $(j,l)$
\end_inset

 at position 
\begin_inset Formula $t$
\end_inset

, marked in dark green.
 It is equal to the sum of probabilities of entering into the TF-state before
 position 
\begin_inset Formula $y_{t}$
\end_inset

.
 In this example, 
\begin_inset Formula $W_{l}$
\end_inset

 is a PWM of length 5, therefore it has 5 different possible positions that
 include 
\begin_inset Formula $y_{t}$
\end_inset

 that are summed, marked in light green.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Inference 2 aims for reaching the most likely hidden sequence:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y_{1:L}^{*}=argmax_{y_{1:L}}P\left(y_{1:L}|x_{1:L}\right)\label{Viterbi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The main difference between inference 1 is the consideration to the dependency
 between adjacent states.
 In inference 1, for example, two adjacent positions may been individually
 inferred states which the transition probability between them equals 0.
 Even though each hidden state maximizes the likelihood at its position,
 as a sequence when accounting for the transitions the result might not
 be the same states.
\end_layout

\begin_layout Subsubsection*
HOP-Viterbi Algorithm
\end_layout

\begin_layout Standard
In HMM, deriving the maximal likelihood hidden sequence of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Viterbi"

\end_inset

 is done by the Viterbi algorithm, named after Andrew Viterbi who proposed
 it in 
\begin_inset CommandInset citation
LatexCommand citet
key "key-65"

\end_inset

.
 Viterbi algorithm resembles the Forward algorithm, with the two main difference
s:
\end_layout

\begin_layout Enumerate
Maximization replaces the summation over the possible transitions.
\end_layout

\begin_layout Enumerate
Traces of the maximal value chosen in the dynamic filling are kept in 
\begin_inset Formula $V^{2}$
\end_inset

, which used to back-trace the chosen state path at the end.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Viterbi Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\theta$
\end_inset

- HMM parameters 
\begin_inset Formula $\{\pi,T,E\}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{2}=0$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,t=[2,...,L]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{1}=max_{j'\in[m]}\left(V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{2}=argmax_{j'\in[m]}\left(V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# back tracing
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{L}=argmax_{j}V_{j,L}^{1}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
for 
\begin_inset Formula $t=[L,...,2]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\hat{y}_{t-1}=V_{y_{t},t}^{2}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\hat{y}_{1:L}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For HOP-HMM the Viterbi algorithm is adapted into a HOP-Viterbi algorithm,
 in two manners:
\end_layout

\begin_layout Itemize
Maximization is done over two types of state transition probabilities: backgroun
d to background and background to TF, held in A and B vectors.
\end_layout

\begin_layout Itemize
The traces held in 
\begin_inset Formula $V^{2}$
\end_inset

 tables are two indices, since states in HOP-HMM are described by two indices.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP-Viterbi Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\theta$
\end_inset

- HOP-HMM parameters 
\begin_inset Formula $\{\pi,T,G,E\}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{2}=0$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,t=[2,...,L]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $A=\left\{ V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}|j'\in[m]\right\} $
\end_inset


\emph on
 # background-state to background-state
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $B=\left\{ V_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}|l\in[k]\right\} $
\end_inset

 
\emph on
# background-state to TF-state
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{1}=max\left(A\cup B\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{2}=\begin{cases}
\left(argmax(A),0\right) & \ensuremath{max(A)>max(B)}\\
\left(j,argmax(B)\right) & otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{L}=\left(argmax_{j}V_{j,L}^{1},0\right)$
\end_inset

 
\emph on
# mandatory background-state at the end of the sequence
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t=L$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
while 
\begin_inset Formula $t>1$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\left(j,l\right)=V_{y_{t}[0],t}^{2}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

if 
\begin_inset Formula $l=0:$
\end_inset


\emph on
 # if 
\begin_inset Formula $l=0$
\end_inset

 the hidden state at 
\begin_inset Formula $t-1$
\end_inset

 is a background-state
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{t-1}=\left(j,0\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $t=t-1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

else:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $y_{t-|W_{l}|:t-1}=\left(j,l\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $y_{t-|W_{l}|-1}=y_{t}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $t=t-|W_{l}|-1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\hat{y}_{1:L}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Using the Viterbi state path, we can make a simplistic classifications of
 short DNA sequences by their dominant state.
 This simple classification made by choosing the most repeating state in
 the estimated Viterbi state path 
\begin_inset Formula $y_{1:L}:$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{class}=mode_{t\in[L]}y_{t}
\]

\end_inset


\end_layout

\begin_layout Part*
Results
\end_layout

\begin_layout Standard
For evaluating HOP-HMM, we first measure its capabilities on synthetic DNA
 data that was created in a controlled way.
 Afterwards, we see how does a HOP-HMM classify real human DNA sequences.
 The evaluation process on synthetic data is done by the following steps
 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

):
\end_layout

\begin_layout Enumerate
We generate parameters for a HOP-HMM 
\begin_inset Formula $\theta$
\end_inset

, which are treated as the true 
\begin_inset Formula $\theta$
\end_inset

.
 
\begin_inset Formula $\theta$
\end_inset

 is sampled in the following way:
\end_layout

\begin_deeper
\begin_layout Enumerate
Each cell T is sampled from the uniform distribution 
\begin_inset Formula 
\begin{equation}
T_{i,j}\sim U\left(minT_{i,j},maxT_{i,j}\right)\label{minTmaxT}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Each cell 
\begin_inset Formula $G_{i,j}$
\end_inset

 is sampled from a uniform and a Bernoulli distribution 
\begin_inset Formula 
\begin{equation}
G_{i,j}\sim U\left(minG,noiseG\right)+\boldsymbol{1}_{\left(i,0\right)\in Reg}\cdot Bern\left(\frac{k}{m}\right)\cdot maxG\label{noiseG}
\end{equation}

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
where 
\begin_inset Formula 
\[
\boldsymbol{1}_{\left(i,0\right)\in ENH}=\begin{cases}
1 & \left(i,0\right)\in ENH\\
0 & otherwise
\end{cases}
\]

\end_inset


\begin_inset Formula $ENH$
\end_inset

 is the set of 
\begin_inset Quotes eld
\end_inset

enhancer-mimicking
\begin_inset Quotes erd
\end_inset

 background-states, which are predefined background-states that have high
 probability of transitioning into TF-state.
 The rest of the background-states will have low probability to create TFBS,
 aiming to model the non-regulatory regions of the DNA with sparse TFBSs.
 In our experiments 
\begin_inset Formula $ENH$
\end_inset

 contained all but one state: 
\begin_inset Formula $\left(m,0\right)$
\end_inset

 meaning only one background-state had almost no TFBS and the rest 
\begin_inset Formula $m-1$
\end_inset

 background-states did have TFBSs.
\end_layout

\end_deeper
\begin_layout Enumerate
After being sampled, T and G are divided element-wise by their rows sum
 so their rows together become distributions:
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\begin{align}
T_{i,j}=\frac{T_{i,j}}{\sum_{j'\in[m]}T_{i,j'}+\sum_{j'\in[k]}G_{i,j'}} &  & G_{i,j}=\frac{G_{i,j}}{\sum_{j'\in[m]}T_{i,j'}+\sum_{j'\in[k]}G_{i,j'}}\label{GT_normalization}
\end{align}

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
E is sampled from a uniform distribution 
\begin_inset Formula $E_{j,b_{1},...,b_{o}}\sim U\left(0,1\right)$
\end_inset

 and divided by the sum of its last index to become a distribution array,
 similar to (c):
\begin_inset Formula 
\[
E_{j,b_{1},...,b_{o}}=\frac{E_{j,b_{1},...,b_{o}}}{\sum_{b'=[4]}E_{j,b_{1},...,b_{o-1},b'}}
\]

\end_inset


\end_layout

\begin_layout Enumerate
The start state distribution 
\begin_inset Formula $\pi$
\end_inset

 is non-random, and set so the first states are always one of the non-enhancer
 background-states: 
\begin_inset Formula 
\[
\pi_{i}=\frac{\boldsymbol{1}_{\left(i,0\right)\notin ENH}}{m-|ENH|}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Sequences are generated using the HOP-HMMs with the true 
\begin_inset Formula $\theta$
\end_inset

.
 Both the observed and the hidden sequences are used, denoted 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

.
 We split the 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 sequences into train and test for cross validation.
 
\end_layout

\begin_layout Enumerate
From the DNA sequences of 
\begin_inset Formula $X$
\end_inset

 train, we train a 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the HOP Baum-Welch algorithm.
\end_layout

\begin_layout Enumerate
Using the trained parameters 
\begin_inset Formula $\hat{\theta}$
\end_inset

, we estimate 
\begin_inset Formula $\hat{Y}$
\end_inset

 test from 
\begin_inset Formula $X$
\end_inset

 test and 
\begin_inset Formula $\hat{Y}$
\end_inset

 train from 
\begin_inset Formula $X$
\end_inset

 train by the HOP-Viterbi algorithm.
 We also calculate the posterior probability of 
\begin_inset Formula $P_{\hat{\theta}}\left(y_{t}|x_{1:L}\right)$
\end_inset

 from 
\begin_inset Formula $X$
\end_inset

 test and 
\begin_inset Formula $X$
\end_inset

 train.
 These results are then compared to the real 
\begin_inset Formula $Y$
\end_inset

 test and 
\begin_inset Formula $Y$
\end_inset

 train for accuracy measuring.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Workflow.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Workflow"

\end_inset

Workflow of the evaluation process.
 A 
\begin_inset Formula $\theta$
\end_inset

 is sampled and a HOP-HMM model is created with which several fixed-length
 sequences are generated.
 A new model 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is then fitted to the train section of the observed sequences, via HOP-Baum-Wel
ch algorithm.
 With 
\begin_inset Formula $\hat{\theta},$
\end_inset

 an hidden sequence is then estimated by the HOP-Viterbi algorithm, and
 a posterior probability estimation is calculated by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PosteriorEstimation"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Baum-Welch algorithm is guaranteed to increase the likelihood in each
 step, however it is not guaranteed to converge to the optimal 
\begin_inset Formula $\theta^{*}$
\end_inset

 (
\begin_inset CommandInset citation
LatexCommand citet
key "key-50"

\end_inset

) as there is no known analytical way for reaching it.
 As a consequence, Baum-Welch algorithm converges into a local maximum 
\begin_inset Formula $\hat{\theta}$
\end_inset

 which could be a relatively low likelihood estimation, depending on the
 initialization point of the first 
\begin_inset Formula $\theta$
\end_inset

.
 The local maximum convergence issue is addressed in two ways:
\end_layout

\begin_layout Standard
1.
 We use regularization for faster and to a better 
\begin_inset Formula $\hat{\theta}$
\end_inset

 convergence (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization"

\end_inset

).
 Following each M-step update we draw the background-states transition probabili
ties 
\begin_inset Formula $T$
\end_inset

 to remain between 
\begin_inset Formula $maxT$
\end_inset

 and 
\begin_inset Formula $minT$
\end_inset

 matrices from 
\begin_inset CommandInset ref
LatexCommand eqref
reference "minTmaxT"

\end_inset

:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $T_{i,j}<minT_{i,j}$
\end_inset

 then we set 
\begin_inset Formula $T_{i,j}=minT_{i,j}$
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $T_{i,j}>maxT_{i,j}$
\end_inset

 then we set 
\begin_inset Formula $T_{i,j}=maxT_{i,j}$
\end_inset


\end_layout

\begin_layout Itemize
T and G are divided by their row sum so their rows together remain a distributio
n as in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "GT_normalization"

\end_inset


\end_layout

\begin_layout Standard
2.
 Since Baum-Welch seek local maximum, running it multiple times with different
 initializations will cause convergence into different 
\begin_inset Formula $\hat{\theta}$
\end_inset

 results.
 As could be expected, we observed throughout multiple initializations that
 the higher the log likelihood of final 
\begin_inset Formula $\hat{\theta}$
\end_inset

 the lower its root mean square error (RMSE) compared to the true 
\begin_inset Formula $\theta$
\end_inset

 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "LikelihoodVsErr"

\end_inset

).
 This is important since on real observed sequences, only the estimated
 
\begin_inset Formula $\hat{\theta}$
\end_inset

 likelihood is known while the true 
\begin_inset Formula $\theta$
\end_inset

 is unknown.
 This correlation implies that for an estimation 
\begin_inset Formula $\hat{\theta}$
\end_inset

 that closer to the true 
\begin_inset Formula $\theta$
\end_inset

, one should redo several EM runs and choose the 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the highest likelihood.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/DecError_rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "LikelihoodVsErr"

\end_inset

Over multiple runs of HOP-Baum-Welch, a correlation exists between the estimated
 
\begin_inset Formula $\theta$
\end_inset

 likelihood over the learned sequences and the error comparing the true
 
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_likelihood.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_theta_error.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_theta_error_scatter.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_viterbi.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Regularization"

\end_inset

(A) The EM iterations draws the estimated 
\begin_inset Formula $\theta$
\end_inset

 values mostly closer to the values of the true 
\begin_inset Formula $\theta$
\end_inset

.
 (B) The error between the true and estimated 
\begin_inset Formula $\theta$
\end_inset

 decrease, and after a few iterations converge to the same path regardless
 of the initialization.
 (C) During the EM iterations, the learned 
\begin_inset Formula $\theta$
\end_inset

 yields a more accurate Viterbi estimation of the hidden states.
 Note that not even the true 
\begin_inset Formula $\theta$
\end_inset

 could produce Viterbi paths that is a perfect match to the true hidden
 sequences.
 (D) The mean log likelihood of the sequences increases during the EM iterations.
 The experiment was done on 500 synthetic sequences (85% train, 15% test),
 1000 long.
 The trained model had 6 hidden background-states with emission order of
 2, each background-state had 25 TF-states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/synthetic_posterior_with_tfs.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "PostiriorProbability"

\end_inset

Posterior probability of sequences, estimated by a trained HOP-HMM 
\begin_inset Formula $\hat{\theta}$
\end_inset

 on test sequences that were synthetically generated by a HOP-HMM 
\begin_inset Formula $\theta$
\end_inset

.
 At the bottom of each posterior probability, there are the Viterbi hidden
 path by 
\begin_inset Formula $\hat{\theta}$
\end_inset

 and the true hidden states of each sequence.
 The black TFBS is the sum of all the probabilities of being in any of the
 TF-states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/confusion_matrix.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "ConfutionMatrix"

\end_inset

Confusion matrix of true and estimated states by the Viterbi algorithm of
 HOP-HMM synthetic sequences.
 Rows are normalized so their sum is equal to 1.
 The majority of prediction are in the background-states 
\begin_inset Formula $(1,0)$
\end_inset

, 
\begin_inset Formula $(2,0)$
\end_inset

, 
\begin_inset Formula $(3,0)$
\end_inset

, 
\begin_inset Formula $(4,0)$
\end_inset

 and 
\begin_inset Formula $(5,0)$
\end_inset

, where TF-states are sometimes misclassified as their background-state
 state.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Roadmap Dataset
\end_layout

\begin_layout Standard
For testing of HOP-HMM performance on human genetic data, we used the Roadmap
 project tracks.
 We defined the dataset of known enhancers as sequences around intersection
 of DNAse, H3K27ac and H3K4me1 peaks, while removing peaks of H3K27me3 and
 H3K4me3 and sequences within 5000bp from known genes.
 Bed files manipulation was done with BEDTools (
\begin_inset CommandInset citation
LatexCommand citet
key "key-68"

\end_inset

), which resulted in 1000bp long sequences centered around their H3K27ac
 peaks.
\end_layout

\begin_layout Standard
We wanted to evaluate if HOP-HMM can distinguish and detect enhancers active
 in two human tissues.
 For this we've built a set of 4000 bp fixed length sequences from the HG19
 in positions which were labeled as enhancers based on epigenetic data collected
 by Roadmap project from 57 tissues.
 Out of these enhancers, we chose only sequences of tissue-specific enhancers
 in one of two types of tissues, and not in the rest of the 57 tissues.
 We've added sequences with no known role, from random locations in the
 genome distal from genes or enhancers as background sequences.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
A HOP-HMM is trained by the HOP-Baum-Welch algorithm on the collected sequences.
 The trained model is then used to produce a Viterbi estimated hidden-states
 sequence and posterior probability, which can then be compared to the epigeneti
c tracks.
\end_layout

\begin_layout Standard
For the set of PWMs used by the TF-states of the HOP-HMM, we used JASPAR
 dataset of 519 vertebrates PWMs, out of which we selected 60 PWMs for a
 reasonable runtime.
 The selected PWMs are chosen as followed:
\end_layout

\begin_layout Itemize
PWMs of TFs which are over or under expressed in the evaluated tissues,
 according to the Roadmap RNA-seq data.
 TFs were chosen if 20% or more of their expression is in one of the evaluated
 tissues, out of 57 tissue types available in Roadmap dataset.
\end_layout

\begin_layout Itemize
PWMs which are abundant in the sequences, i.e.
 PWMs with the highest mean likelihood to attach to the sequences.
 The likelihood of PWM 
\begin_inset Formula $W$
\end_inset

 to bind to a sequence 
\begin_inset Formula $x$
\end_inset

 is calculated as described mean is the average of 3 highest likelihood
 TFBS as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

.
 Note that here we use the PWM form as in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PPM"

\end_inset

 and not the PPM form for comparison between PWM likelihoods.
\end_layout

\begin_layout Itemize
PWMs that had stronger presence in sequences from one tissue compared to
 the other.
 This is defined as the PWMs with sequence binding likelihood (as defined
 in the previous point) can be best distinguish between sequences from one
 tissue and the rest in terms of AUC-ROC.
\end_layout

\begin_layout Standard
In our experiments some sequences had good resemblance to the DNaseI track
 and ChromeHMM classifications, though no clear correlation was found.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq1.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq2.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq3.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "RealData"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq4.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeqLegend.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Appendix: Source Code
\end_layout

\begin_layout Standard
The code for this research was written in Matlab, and can be found in 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/David-Taub/HOP-HMM
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="2">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Variable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meaning
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
L
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DNA sequences length
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
N
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of DNA sequences
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
m
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of background-states
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
k
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of TF-states of each background-state
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
order
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dependency order of the emission of the background-states done by 
\begin_inset Formula $E$
\end_inset

.
 For example, if 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
order
\end_layout

\end_inset

 equals 3, then the emission is conditional on 2 previous observable variables.
 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
backgroundAmount
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none" width="10cm">
\begin_inset Text

\begin_layout Plain Layout
Number of background-states that are non-enhancers, i.e.
 with very low transition probability into TF-states
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
The prominent code files in the project:
\end_layout

\begin_layout Itemize

\series bold
HOP-HMM/data/peaks/scripts/download_and_process_all.sh
\end_layout

\begin_deeper
\begin_layout Standard
Linux bash script which downloads data files of epigenetic from Roadmap
 website, JASPAR PWMs and hg19 genome.
 After downloading, the data is per-processed with Bedtools and bigWigToBedGraph.
 The only part in this project that requires Linux is the bigWigToBedGraph.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/+peaks/minimizeMergePeak.m
\end_layout

\begin_deeper
\begin_layout Standard
Reads downloaded bed files, process them and saves them into MAT-file v7.3.
 
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
 
\end_layout

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mergedPeaksMin = minimizeMergePeak(params, L)
\end_layout

\end_inset

;
\end_layout

\begin_layout Standard
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
doGTBound
\end_layout

\end_inset

 indicates whether or not to apply regularization on T and G transition
 probabilities and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
doESharing
\end_layout

\end_inset

 indicates whether or not to force 
\begin_inset Formula $E$
\end_inset

 to share the emission across all background-states 
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/misc/genSyntheticMergedPeaksMin.m
\end_layout

\begin_deeper
\begin_layout Standard
Generates DNA sequences X and hidden variables Y out of a random 
\begin_inset Formula $\theta$
\end_inset

, which was sampled by genTheta.m
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
\end_layout

\end_inset

 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mergedPeaksMin = genSyntheticMergedPeaksMin(N, L, params, startWithBackground,
 backgroundGNoise);
\end_layout

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
startWithBackground
\end_layout

\end_inset

 indicates whether or not to force 
\begin_inset Formula $\pi$
\end_inset

 to allow starting only from non-enhancer background-states and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
backgroundGNoise
\end_layout

\end_inset

 is the background rate of background-state to TF-state transition, marked
 as 
\begin_inset Formula $noiseG$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "noiseG"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/misc/genTheta.m
\end_layout

\begin_deeper
\begin_layout Standard
Generates a random 
\begin_inset Formula $\theta$
\end_inset

, with options to sample a total random 
\begin_inset Formula $T$
\end_inset

 and a total random 
\begin_inset Formula $\pi$
\end_inset

.
 Note that 
\begin_inset Formula $\pi$
\end_inset

 is called 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
theta.startT
\end_layout

\end_inset

 throughout the code.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
 
\end_layout

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
theta = genTheta(params, false, false);
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/mainRealData.m
\end_layout

\begin_deeper
\begin_layout Standard
Entry point of the code, reads data from human genome, trains HOP-HMMs model
 and compares posterior probability to real epigenetic data.
 Execution of mainRealData will produce figures similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "RealData"

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mainRealData();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/mainPosterior.m
\end_layout

\begin_deeper
\begin_layout Standard
Entry point of the code, follows the workflow of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

.
 Execution of mainPosterior plots random set of sequences with their Viterbi
 sequence and posterior probabilities similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PostiriorProbability"

\end_inset

 and a confusion matrix similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "ConfutionMatrix"

\end_inset

.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mainPosterior();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/mainDecErrorPlot.m
\end_layout

\begin_deeper
\begin_layout Standard
Entry point of the code, follows the workflow of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

, and at each iteration of the EM, likelihood and errors are collected to
 form plots similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization"

\end_inset

.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mainDecErrorPlot();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/+EM/EM.m
\end_layout

\begin_deeper
\begin_layout Standard
The function actually trains the HOP-HMM model from a given DNA sequence
 is the EM().
 The neighboring code files residing in the +EM folder which contains it,
 are the implementations of the E and M steps described in the introduction
 part of this work.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
[test, train] = misc.crossValidationSplit(params, mergedPeaksMin, testTrainRatio)
;
\end_layout

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
[bestTheta, bestLikelihood, bestThetas] = EM(train, params, maxIter, patience,
 repeat);
\end_layout

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
maxIter
\end_layout

\end_inset

 is the maximal number of iterations allowed in a run, 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
parience
\end_layout

\end_inset

 is the number of iterations without likelihood increase that are allowed
 in a run and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
repeat
\end_layout

\end_inset

 is the number of different runs with different initializations that are
 tried.
\end_layout

\end_deeper
\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ahituv et al.(2007)"
key "key-1"

\end_inset

 Ahituv, N., Zhu, Y., Visel, A., Holt, A., Afzal, V., Pennacchio, L.
 A., & Rubin, E.
 M.
 (2007).
 Deletion of ultraconserved elements yields viable mice.
 PLoS biology, 5(9), e234.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ainscough et al.(1998)"
key "key-57"

\end_inset

 Ainscough, R., Bardill, S., Barlow, K., Basham, V., Baynes, C., Beard, L., ...
 & Burrows, C.
 (1998).
 Genome sequence of the nematode C.
 elegans: a platform for investigating biology.
 Science, 282(5396), 2012-2018.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Akalin et al.(2009)"
key "key-11"

\end_inset

 Akalin, A., Fredman, D., Arner, E., Dong, X., Bryne, J.
 C., Suzuki, H., ...
 & Lenhard, B.
 (2009).
 Transcriptional features of genomic regulatory blocks.
 Genome biology, 10(4), R38.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Alipanahi et al.(2015)"
key "key-2"

\end_inset

 Alipanahi, B., Delong, A., Weirauch, M.
 T., & Frey, B.
 J.
 (2015).
 Predicting the sequence specificities of DNA-and RNA-binding proteins by
 deep learning.
 Nature biotechnology, 33(8), 831.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Andersson et al.(2014)"
key "key-3"

\end_inset

 Andersson, R., Gebhard, C., Miguel-Escalada, I., Hoof, I., Bornholdt, J., Boyd,
 M., ...
 & Ntini, E.
 (2014).
 An atlas of active enhancers across human cell types and tissues.
 Nature, 507(7493), 455.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Baum et al.(1966)"
key "key-4"

\end_inset

 Baum, L.
 E., & Petrie, T.
 (1966).
 Statistical inference for probabilistic functions of finite state Markov
 chains.
 The annals of mathematical statistics, 37(6), 1554-1563.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Benko et al.(2009)"
key "key-6"

\end_inset

 Benko, S., Fantes, J.
 A., Amiel, J., Kleinjan, D., Thomas, S., Ramsay, J., et al.
 (2009).
 Highly conserved non.
 Nature Genetics 64(2), p.
 10-12.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Burge and Karlin(1997)"
key "key-22"

\end_inset

Burge, C., & Karlin, S.
 (1997).
 Prediction of complete gene structures in human genomic DNA.
 Journal of molecular biology, 268(1), 78-94.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Calo et al.(2013)"
key "key-7"

\end_inset

 Calo, E., & Wysocka, J.
 (2013).
 Modification of enhancer chromatin: what, how, and why?.
 Molecular cell, 49(5), 825-837.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Creyghton et al.(2010)"
key "key-8"

\end_inset

 Creyghton, M.
 P., Cheng, A.
 W., Welstead, G.
 G., Kooistra, T., Carey, B.
 W., Steine, E.
 J., ...
 & Boyer, L.
 A.
 (2010).
 Histone H3K27ac separates active from poised enhancers and predicts development
al state.
 Proceedings of the National Academy of Sciences, 107(50), 21931-21936.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Cutter et al.(2015)"
key "key-9"

\end_inset

 Cutter, A.
 R., & Hayes, J.
 J.
 (2015).
 A brief review of nucleosome structure.
 FEBS letters, 589(20), 2914-2922.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Beer et al.(2014)"
key "key-5"

\end_inset

 De Beer, Z.
 W., Duong, T.
 A., Barnes, I., Wingfield, B.
 D., & Wingfield, M.
 J.
 (2014).
 Redefining Ceratocystis and allied genera.
 Studies in Mycology, 79, 187-219.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Diehl et al.(2016)"
key "key-10"

\end_inset

 Diehl, A.
 D., Meehan, T.
 F., Bradford, Y.
 M., Brush, M.
 H., Dahdul, W.
 M., Dougall, D.
 S., ...
 & Van Slyke, C.
 E.
 (2016).
 The Cell Ontology 2016: enhanced content, modularization, and ontology
 interoperability.
 Journal of biomedical semantics, 7(1), 44.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Doniger et al.(2005)"
key "key-12"

\end_inset

 Doniger, S.
 W., Huh, J., & Fay, J.
 C.
 (2005).
 Identification of functional transcription factor binding sites using closely
 related Saccharomyces species.
 Genome research, 15(5), 701-709.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Emison et al.(2005)"
key "key-13"

\end_inset

 Emison, E.
 S., McCallion, A.
 S., Kashuk, C.
 S., Bush, R.
 T., Grice, E., Lin, S., ...
 & Chakravarti, A.
 (2005).
 A common sex-dependent mutation in a RET enhancer underlies Hirschsprung
 disease risk.
 Nature, 434(7035), 857.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ernst and Kellis(2012)"
key "key-14"

\end_inset

 Ernst, J., & Kellis, M.
 (2012).
 ChromHMM: automating chromatin-state discovery and characterization.
 Nature methods, 9(3), 215.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ernst et al.(2011)"
key "key-15"

\end_inset

 Ernst, J., Kheradpour, P., Mikkelsen, T.
 S., Shoresh, N., Ward, L.
 D., Epstein, C.
 B., ...
 & Ku, M.
 (2011).
 Mapping and analysis of chromatin state dynamics in nine human cell types.
 Nature, 473(7345), 43.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ezkurdia et al.(2014)"
key "key-16"

\end_inset

 Ezkurdia, I., Juan, D., Rodriguez, J.
 M., Frankish, A., Diekhans, M., Harrow, J., ...
 & Tress, M.
 L.
 (2014).
 Multiple evidence strands suggest that there may be as few as 19 000 human
 protein-coding genes.
 Human molecular genetics, 23(22), 5866-5878.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ferguson(1980)"
key "key-17"

\end_inset

 Ferguson, J.
 D.
 (1980).
 pp.
 143â€“179, Variable duration models for speech.
 In Proc.
 of the Symposium on the applications of hidden Markov models to text and
 speech, JD Ferguson, Ed.
 Princeton: IDA-CRD.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Fernandez and Galperin(2012)"
key "key-18"

\end_inset

 Galperin, M.
 Y., & FernÃ¡ndez-Suarez, X.
 M.
 (2011).
 The 2012 nucleic acids research database issue and the online molecular
 biology database collection.
 Nucleic acids research, 40(D1), D1-D8.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Fishilevich et al.(2017)"
key "key-20"

\end_inset

 Fishilevich, S., Nudel, R., Rappaport, N., Hadar, R., Plaschkes, I., Iny Stein,
 T., ...
 & Lancet, D.
 (2017).
 GeneHancer: genome-wide integration of enhancers and target genes in GeneCards.
 Database, 2017.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Friedli et al.(2010)"
key "key-21"

\end_inset

 Friedli, M., Barde, I., Arcangeli, M., Verp, S., Quazzola, A., Zakany, J., ...
 & Duboule, D.
 (2010).
 A systematic enhancer screen using lentivector transgenesis identifies
 conserved and non-conserved functional elements at the Olig1 and Olig2
 locus.
 PLoS One, 5(12), e15741.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Haussler and Eeckman(1996)"
key "key-24"

\end_inset

 Haussler, D.
 K.
 D., & Eeckman, M.
 G.
 R.
 F.
 H.
 (1996).
 A generalized hidden Markov model for the recognition of human genes in
 DNA.
 In Proc.
 int.
 conf.
 on intelligent systems for molecular biology, st.
 louis (pp.
 134-142).
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Hayashi-Takanaka et al.(2011)"
key "key-25"

\end_inset

 Hayashi-Takanaka, Y., Yamagata, K., Wakayama, T., Stasevich, T.
 J., Kainuma, T., Tsurimoto, T., ...
 & Kimura, H.
 (2011).
 Tracking epigenetic histone modifications in single cells using Fab-based
 live endogenous modification labeling.
 Nucleic acids research, 39(15), 6475-6488.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Heintzman et al.(2007)"
key "key-26"

\end_inset

 Heintzman, N.
 D., Stuart, R.
 K., Hon, G., Fu, Y., Ching, C.
 W., Hawkins, R.
 D., ...
 & Wang, W.
 (2007).
 Distinct and predictive chromatin signatures of transcriptional promoters
 and enhancers in the human genome.
 Nature genetics, 39(3), 311.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Heintzman et al.(2009)"
key "key-19"

\end_inset

 Heintzman, N.
 D., Hon, G.
 C., Hawkins, R.
 D., Kheradpour, P., Stark, A., Harp, L.
 F., ...
 & Ching, K.
 A.
 (2009).
 Histone modifications at human enhancers reflect global cell-type-specific
 gene expression.
 Nature, 459(7243), 108.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Hu et al.(1996)"
key "key-27"

\end_inset

 Hu, J., Brown, M.
 K., & Turin, W.
 (1996).
 HMM based online handwriting recognition.
 IEEE Transactions on pattern analysis and machine intelligence, 18(10),
 1039-1045.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Jin et al.(2011)"
key "key-28"

\end_inset

 Jin Q, Yu L-R, Wang L, Zhang Z, Kasper LH, Lee J-E, Wang C, Brindle PK,
 Dent SYR, Ge K.
 2011.
 Distinct roles of GCN5/PCAF-mediated H3K9ac and CBP/p300-mediated H3K18/27ac
 in nuclear receptor transactivation.
 The EMBO Journal 30:249â€“262.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Jones et al.(2012)"
key "key-29"

\end_inset

 Jones, P.
 A.
 (2012).
 Functions of DNA methylation: islands, start sites, gene bodies and beyond.
 Nature Reviews Genetics, 13(7), 484.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kaplan et al.(2012)"
key "key-64"

\end_inset

 Kaplan, T., & Biggin, M.
 D.
 (2012).
 Quantitative models of the mechanisms that control genome-wide patterns
 of animal transcription factor binding.
 In Methods in cell biology (Vol.
 110, pp.
 263-283).
 Academic Press.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Karmodiya et al.(2012)"
key "key-30"

\end_inset

 Karmodiya, K., Krebs, A.
 R., Oulad-Abdelghani, M., Kimura, H., & Tora, L.
 (2012).
 H3K9 and H3K14 acetylation co-occur at many gene regulatory elements, while
 H3K14ac marks a subset of inactive inducible promoters in mouse embryonic
 stem cells.
 BMC genomics, 13(1), 424.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kelley et al.(2016)"
key "key-31"

\end_inset

 Kelley, D.
 R., Snoek, J., & Rinn, J.
 L.
 (2016).
 Basset: learning the regulatory code of the accessible genome with deep
 convolutional neural networks.
 Genome research, 26(7), 990-999.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Khan et al.(2018)"
key "key-32"

\end_inset

 Khan, A., Fornes, O., Stigliani, A., Gheorghe, M., Castro-Mondragon, J.
 A., van der Lee, R., ...
 & Baranasic, D.
 (2017).
 JASPAR 2018: update of the open-access database of transcription factor
 binding profiles and its web framework.
 Nucleic acids research, 46(D1), D260-D266.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kim et al.(2010)"
key "key-23"

\end_inset

 Kim, T.
 K., Hemberg, M., Gray, J.
 M., Costa, A.
 M., Bear, D.
 M., Wu, J., ...
 & Markenscoff-Papadimitriou, E.
 (2010).
 Widespread transcription at neuronal activity-regulated enhancers.
 Nature, 465(7295), 182.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kleftogiannis et al.(2016)"
key "key-33"

\end_inset

 Kleftogiannis, D., Kalnis, P., Arner, E., & Bajic, V.
 B.
 (2016).
 Discriminative identification of transcriptional responses of promoters
 and enhancers after stimulus.
 Nucleic acids research, 45(4), e25-e25.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kreimer et al.(2017)"
key "key-35"

\end_inset

 Kreimer, A., Zeng, H., Edwards, M.
 D., Guo, Y., Tian, K., Shin, S., ...
 & Li, Y.
 (2017).
 Predicting gene expression in massively parallel reporter assays: a comparative
 study.
 Human mutation, 38(9), 1240-1250.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kulakovskiy et al.(2011)"
key "key-36"

\end_inset

 Kulakovskiy, I.
 V., Belostotsky, A.
 A., Kasianov, A.
 S., Esipova, N.
 G., Medvedeva, Y.
 A., Eliseeva, I.
 A., & Makeev, V.
 J.
 (2011).
 A deeper look into transcription regulatory code by preferred pair distance
 templates for transcription factor binding sites.
 Bioinformatics, 27(19), 2621-2624.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kundaje et al.(2015)"
key "key-37"

\end_inset

 Kundaje, A., Meuleman, W., Ernst, J., Bilenky, M., Yen, A., Heravi-Moussavi,
 A., ...
 & Amin, V.
 (2015).
 Integrative analysis of 111 reference human epigenomes.
 Nature, 518(7539), 317.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lee and Lee(2006)"
key "key-38"

\end_inset

 Lee, L.
 M., & Lee, J.
 C.
 (2006, June).
 A study on high-order hidden Markov models and applications to speech recogniti
on.
 In International Conference on Industrial, Engineering and Other Applications
 of Applied Intelligent Systems (pp.
 682-690).
 Springer, Berlin, Heidelberg.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lettice et al.(2003)"
key "key-39"

\end_inset

 Lettice, L.
 A., Heaney, S.
 J., Purdie, L.
 A., Li, L., de Beer, P., Oostra, B.
 A., ...
 & de Graaff, E.
 (2003).
 A long-range Shh enhancer regulates expression in the developing limb and
 fin and is associated with preaxial polydactyly.
 Human molecular genetics, 12(14), 1725-1735.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lindblad-Toh et al.(2011)"
key "key-40"

\end_inset

 Lindblad-Toh, K., Garber, M., Zuk, O., Lin, M.
 F., Parker, B.
 J., Washietl, S., ...
 & Ward, L.
 D.
 (2011).
 A high-resolution map of human evolutionary constraint using 29 mammals.
 Nature, 478(7370), 476.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Mari et al.(1997)"
key "key-41"

\end_inset

 Mari, J.
 F., Haton, J.
 P., & Kriouile, A.
 (1997).
 Automatic word recognition based on second-order hidden Markov models.
 IEEE Transactions on speech and Audio Processing, 5(1), 22-25.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Markov(1906)"
key "key-42"

\end_inset

 Markov, A.
 A.
 (1906).
 Extension of the law of large numbers to dependent quantities.
 Izv.
 Fiz.-Matem.
 Obsch.
 Kazan Univ.(2nd Ser), 15, 135-156.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Miguel-Escalada et al.(2015)"
key "key-44"

\end_inset

 Miguel-Escalada, I., Pasquali, L., & Ferrer, J.
 (2015).
 Transcriptional enhancers: functional insights and role in human disease.
 Current opinion in genetics & development, 33, 71-76.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ng et al.(2009)"
key "key-45"

\end_inset

 Ng, S.
 B., Turner, E.
 H., Robertson, P.
 D., Flygare, S.
 D., Bigham, A.
 W., Lee, C., ...
 & Bamshad, M.
 (2009).
 Targeted capture and massively parallel sequencing of 12 human exomes.
 Nature, 461(7261), 272.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Pennacchio et al.(2015)"
key "key-46"

\end_inset

 Pennacchio, L.
 A., Bickmore, W., Dean, A., Nobrega, M.
 A., & Bejerano, G.
 (2013).
 Enhancers: five essential questions.
 Nature Reviews Genetics, 14(4), 288.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Preez(1998)"
key "key-47"

\end_inset

 du Preez, J.
 A.
 (1998).
 Efficient training of high-order hidden Markov models using first-order
 representations.
 Computer speech & language, 12(1), 23-39.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Przybilla et al.(2012)"
key "key-48"

\end_inset

 Przybilla, J., Galle, J., & Rohlf, T.
 (2012).
 Is adult stem cell aging driven by conflicting modes of chromatin remodeling?.
 Bioessays, 34(10), 841-848.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Quinlan and Hall(2010)"
key "key-68"

\end_inset

 Quinlan, A.
 R., & Hall, I.
 M.
 (2010).
 BEDTools: a flexible suite of utilities for comparing genomic features.
 Bioinformatics, 26(6), 841-842.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rabiner and Juang(1993)"
key "key-49"

\end_inset

 Rabiner, L., & Juang, B.
 H.
 (1993).
 Fundamentals of speech processing.
 Prantice Hall.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rabiner(1989)"
key "key-50"

\end_inset

 Rabiner, L.
 R.
 (1989).
 A tutorial on hidden Markov models and selected applications in speech
 recognition.
 Proceedings of the IEEE, 77(2), 257-286.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rada-Iglesias et al.(2011)"
key "key-51"

\end_inset

 Rada-Iglesias, A., Bajpai, R., Swigut, T., Brugmann, S.
 A., Flynn, R.
 A., & Wysocka, J.
 (2011).
 A unique chromatin signature uncovers early developmental enhancers in
 humans.
 Nature, 470(7333), 279.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rosin et al.(2013)"
key "key-52"

\end_inset

 Rosin, J.
 M., Abassah-Oppong, S., & Cobb, J.
 (2013).
 Comparative transgenic analysis of enhancers from the human SHOX and mouse
 Shox2 genomic regions.
 Human molecular genetics, 22(15), 3063-3076.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Smemo S(2012)"
key "key-53"

\end_inset

 Smemo, S., Campos, L.
 C., Moskowitz, I.
 P., Krieger, J.
 E., Pereira, A.
 C., & Nobrega, M.
 A.
 (2012).
 Regulatory variation in a TBX5 enhancer leads to isolated congenital heart
 disease.
 Human molecular genetics, 21(14), 3255-3263.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Soldner et al.(2016)"
key "key-54"

\end_inset

 Soldner, F., Stelzer, Y., Shivalila, C.
 S., Abraham, B.
 J., Latourelle, J.
 C., Barrasa, M.
 I., ...
 & Jaenisch, R.
 (2016).
 Parkinson-associated risk variant in distal enhancer of Î±-synuclein modulates
 target gene expression.
 Nature, 533(7601), 95.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Stadler et al.(2011)"
key "key-55"

\end_inset

 Stadler, M.
 B., Murr, R., Burger, L., Ivanek, R., Lienert, F., SchÃ¶ler, A., ...
 & Tiwari, V.
 K.
 (2011).
 DNA-binding factors shape the mouse methylome at distal regulatory regions.
 Nature, 480(7378), 490.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Stormo et al.(1982)"
key "key-7"

\end_inset

 Stormo, G.
 D., Schneider, T.
 D., Gold, L., & Ehrenfeucht, A.
 (1982).
 Use of the â€˜Perceptronâ€™algorithm to distinguish translational initiation
 sites in E.
 coli.
 Nucleic acids research, 10(9), 2997-3011.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Staden(1984)"
key "key-8"

\end_inset

 Staden, R.
 (1984).
 Computer methods to locate signals in nucleic acid sequences.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Taher et al.(2011)"
key "key-56"

\end_inset

 Taher, L., McGaughey, D.
 M., Maragh, S., Aneas, I., Bessling, S.
 L., Miller, W., ...
 & Ovcharenko, I.
 (2011).
 Genome-wide identification of conserved regulatory function in diverged
 sequences.
 Genome research, 21(7), 1139-1149.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Thurman et al.(2012)"
key "key-58"

\end_inset

 Thurman, R.
 E., Rynes, E., Humbert, R., Vierstra, J., Maurano, M.
 T., Haugen, E., ...
 & Garg, K.
 (2012).
 The accessible chromatin landscape of the human genome.
 Nature, 489(7414), 75.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Turin and Sondhi(1993)"
key "key-59"

\end_inset

 Turin, W., & Sondhi, M.
 M.
 (1993).
 Modeling error sources in digital channels.
 IEEE Journal on Selected Areas in Communications, 11(3), 340-347.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2007)"
key "key-60"

\end_inset

 Visel, A., Minovitsky, S., Dubchak, I., & Pennacchio, L.
 A.
 (2007).
 VISTA Enhancer Browserâ€”a database of tissue-specific human enhancers.
 Nucleic Acids Research, 35(Database issue), D88.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2009)"
key "key-61"

\end_inset

 Visel, A., Blow, M.
 J., Li, Z., Zhang, T., Akiyama, J.
 A., Holt, A., ...
 & Afzal, V.
 (2009).
 ChIP-seq accurately predicts tissue-specific activity of enhancers.
 Nature, 457(7231), 854.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Viterbi(1967)"
key "key-65"

\end_inset

 Viterbi, A.
 (1967).
 Error bounds for convolutional codes and an asymptotically optimum decoding
 algorithm.
 IEEE transactions on Information Theory, 13(2), 260-269.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Williamson et al.(2011)"
key "key-43"

\end_inset

 Williamson, I., Hill, R.
 E., & Bickmore, W.
 A.
 (2011).
 Enhancers: from developmental genetics to the genetics of common human
 disease.
 Developmental cell, 21(1), 17-19.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Yang and Wainwright(2015)"
key "key-66"

\end_inset

Yang, F., Balakrishnan, S., & Wainwright, M.
 J.
 (2015, December).
 Statistical and computational guarantees for the Baum-Welch algorithm.
 In 2015 53rd Annual Allerton Conference on Communication, Control, and
 Computing (Allerton) (pp.
 658-665).
 IEEE.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zentner et al.(2011)"
key "key-62"

\end_inset

 Zentner, G.
 E., Tesar, P.
 J., & Scacheri, P.
 C.
 (2011).
 Epigenetic signatures distinguish multiple classes of enhancers with distinct
 cellular functions.
 Genome research, 21(8), 1273-1283.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zhou and Troyanskaya(2015)"
key "key-63"

\end_inset

 Zhou, J., & Troyanskaya, O.
 G.
 (2015).
 Predicting effects of noncoding variants with deep learningâ€“based sequence
 model.
 Nature methods, 12(10), 931.
\end_layout

\end_body
\end_document
