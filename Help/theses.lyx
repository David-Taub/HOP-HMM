#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{babel}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\headheight 0cm
\headsep 0cm
\footskip 0cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
High-Order and PWM Hidden Markov Model (HOP-HMM)
\end_layout

\begin_layout Section*
Abstract
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
Recent new techniques for high throughput sequencing.
 Little is currently known on regulation sequences.
\end_layout

\begin_layout Standard
Levin, blue mice researches, showed that insertion of a sequence without
 any epigenetic information will activate an enhancer with a near by blue
 coloring gene.
\end_layout

\begin_layout Standard
This implies that for some enhancers, the sequence and the location of the
 enhancer & gene is enough for activation regulation.
\end_layout

\begin_layout Standard
The TF inside the nucleus of specific tissues are thought to be a key factor
 in the activation of specific enhancer.
 The TFs form a transcription complex and are connected to the enhancer
 and promotor sequences on top of the TF binding sites (TFBS).
 Studies using TFBS of TF present in specific cell types are used to classify
 cell specific enhancer sequences.
 show heat map of AUC-ROC results.
 Between these TFBS, k-mer frequencies varies between enhancers and non
 regulatory 
\begin_inset Quotes eld
\end_inset

backgound
\begin_inset Quotes erd
\end_inset

 DNA, and was used to classify enhancers from backgound using only the k-mer
 distribution (Inbar and tomy, gkm-SVM), and is thought to play a role in
 spacial properties, nucleosome location and cleavage that cause accessibility
 of near-by TFBS.
 Using 44 out of 127 epigenetic data of Roadmap Project to select tissue
 specific enhancer sequences dataset.
 In our method, we look for different TFBS and k-mer presence in sequences
 to classify cell-specific sequences, inside regulatory modules.
\end_layout

\begin_layout Standard
[PWMs and motif to classify tissue specific enhancers]
\end_layout

\begin_layout Standard
[k-mer to classify tissue specific enhancers]
\end_layout

\begin_layout Standard
[HMM to classify tissue specific enhancers]
\end_layout

\begin_layout Standard
[other machine learning work to classify tissue specific enhancers]
\end_layout

\begin_layout Standard
[Why the HOP-HMM approach to the problem differently]
\end_layout

\begin_layout Section*
Background
\end_layout

\begin_layout Standard
[description of enhancers, target genes and DNA folding]
\end_layout

\begin_layout Standard
Enhancers are non-coding regulatory DNA sequences that are responsible of
 regulating gene expression.
 It is now well acknowledged that enhancer play an essential role in cell
 specific gene expression, altough Enhancer are the focus of much interest
 since methods of high throughput DNA sequencing became more available,
 although their mechanism and identification in the DNA is still not completely
 understood.
 They are short sequences, usually between 100-1000 bp, and when active,
 due to the DNA 3D folding they become spatially closer to other sequences
 called promotors which are adjacent to a gene.
 amd could be up to a megabase upstream or downstream and orientation independen
t of the enhancer.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

[enhancer status, chromatine methylation and accessibility]
\end_layout

\begin_layout Standard
It is known that multiple elements affect the activeness status of an enhancer
 and its promotor: accessibility of the sequences, the presence of TFs in
 the cell, histone modifications near the sequence, methilation in CpG sites
 on and next the sequence and the TAD confirmation.
\end_layout

\begin_layout Standard
[TFs, cofactors and PIC]
\end_layout

\begin_layout Standard
TFs bind both to the enhancers and to the promoters elements in specific
 locations in their sequences called TFBSs, which are motifs which are typical
 for a TF or a TF group.
 When the DNA is folded to allow the enhancer and promotor to interact,
 other cofactors proteins join upon attached TFs to form the transcription
 preinitiation complex (PIC).
 PIC are a very large assemblies of proteins, more than hundred in humans,
 which recruit the RNA Polymerase (RNA pol II) an enzyme which invokes the
 transcription process of the adjacent gene: it opens the double stranded
 DNA, so that one strand of exposed nucleotides becomes a template for RNA
 synthisation.
 
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

[importance of TFBS, genetic diseases]
\begin_inset Newline newline
\end_inset

In recent years, thousands of enhancers DNA sequence have been annotated
 in multiple organisms, and it was shown [citation: blue mice vista, ...] that
 the presence and accessibility of the TFBS is critical for the regulatory
 capability of enhancer elements.
 Multiple studies shows that genetic alternations in these elements, in
 some cases as little as a SNP, might affect the expression of it's target
 gene and are a major cause of human diseases 
\begin_inset CommandInset citation
LatexCommand citep
key "Soldner"

\end_inset

[more citations needed].
 
\end_layout

\begin_layout Standard

\bar under
[kmers, gc]
\end_layout

\begin_layout Standard
[epigenetic data to identify enhancers]
\end_layout

\begin_layout Standard
[identification of enhancers from sequence]
\end_layout

\begin_layout Standard
[sequence classification, generative models, HMM]
\end_layout

\begin_layout Standard
[sequences that could have been generated by HOP-HMM]
\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Section*
Methods
\end_layout

\begin_layout Standard
Generalized Hidden Markov Model (GHMM)
\end_layout

\begin_layout Standard
HOP-HMM is a type of Generalized Hidden Markov Model (GHMM), which is a
 generative model, meaning it relies on the assumption that the observed
 DNA sequence was generated by a parameterized model 
\begin_inset Formula $\theta$
\end_inset

.
 Our goal is to find a model that fits the set of training sequences or
 in other words a 
\begin_inset Formula $\theta$
\end_inset

 that maximizes the log likelihood of the observed sequence.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
l(x_{1},...,x_{L}|\theta) & =log\ P(x_{1},...,x_{L}|\theta)\\
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As in a standard HMM, we assume an underlying hidden variables are present,
 and these variables indicate the state of the model while creating the
 sequence.
 As seen in figure 2 and figure 3,
\end_layout

\begin_layout Standard
TOMMY:
\end_layout

\begin_layout Standard
Generative model.
 A set of sequences could have been generated by this model.
 Our goal is to optimize the model parameters such that the likelihood is
 optimized.
 While so, we would "annotate" the sequences (explain how and why).
 Begin by describing the model automaton (state machine) with a figure.
 Only then talk about the emissions.
 Wrap it up by describing how data is generated (according to the model)
 and how this would help you understand enhancer sequences.
\end_layout

\begin_layout Standard

\series bold
\bar under
Setup
\end_layout

\begin_layout Standard
Let us consider a high-order emission base-states and PWM emission sub-states
 HMM from a dataset of N observations sequences 
\begin_inset Formula $X=\left(X_{1},...,X_{N}\right)$
\end_inset

 where each observation sequence is L nucleotides long 
\begin_inset Formula $X_{i}=\left(x_{1}^{i},...,x_{L}^{i}\right)$
\end_inset

.
 We assume an underlying hidden variable sequences 
\begin_inset Formula $Y=\left(Y_{1},...,Y_{N}\right)$
\end_inset

 where each underlying sequence is also L variables long 
\begin_inset Formula $Y_{i}=y_{1}^{i},...,y_{L}^{i}$
\end_inset

.
 Let the space of underlying states be 
\begin_inset Formula $\Upsilon=\left\{ 1,2,...,m\right\} \times\left\{ 0,1,...,k\right\} $
\end_inset

 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
TOMMY:
\end_layout

\begin_layout Standard
quite abstract and hard to follow.
 try to be more concrete.
 See above.
 Add Figure!
\end_layout

\begin_layout Standard
not clear enough.
 I think your best option is to separate the figure into two parts, like
 I said before.
 Begin by a single "layer" and first describe the automaton and the transition
 probabilities (maybe with a matrix).
 Then show the generated sequence with the (hidden) states above.
 You can also plot the dependencies among them (Markovian model).
 Then make the model more complex, and keeping explaining with automaton
 figures.
\end_layout

\begin_layout Standard

\series bold
\bar under
Emission and Transition
\end_layout

\begin_layout Standard
Underlying states emit the observed sequence are of two types: base-states
 and their sub-states.
 We mark the j'th base-state as 
\begin_inset Formula $(j,0)$
\end_inset

 for 
\begin_inset Formula $j\in\{1,...,m\}$
\end_inset

 and its l'th sub-state as 
\begin_inset Formula $(j,l)$
\end_inset

 for 
\begin_inset Formula $l\in\{1,...,k\}$
\end_inset

.
 Denote the base-state emission order by o, meaning a base-state emits a
 letter sampled from an emission matrix 
\series bold

\begin_inset Formula $E$
\end_inset

 
\series default
that depends on previous 
\begin_inset Formula $o-1$
\end_inset

 letters.
\end_layout

\begin_layout Standard
Sub-state emits multiple letters sampled from a PWM that is fixed and isn't
 learned in the training.
 Denote
\begin_inset Formula $W_{l}$
\end_inset

 the PWM of the l'th sub-states, which is shared between the l'th sub-states
 of all base-states.
 
\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Graphics
	filename Figures/Slide4.eps
	scale 40

\end_inset


\begin_inset Newline newline
\end_inset

 
\series bold
\shape italic
Figure 4: emission and transition process between base-state.
 The upper flow represent transition from base-state to the same base-state,
 through a sub-state that emits a motif.
 The lower flow represent transition between two base-state using the T
 transition matrix, similar to the conventional HMM.
\series default
\shape default

\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
After emitting a single letter, the j'th base-state has a probability 
\begin_inset Formula $F_{j}$
\end_inset

 to make a transition into one of its sub-state and emit a motif and probability
 
\begin_inset Formula $1-F_{j}$
\end_inset

 to make a transition into one of the base-states and emit a single letter.
 The distribution of transitions between base-states is set by T matrix,
 and between base-state to its sub-states by G matrix.
 After emitting a motif in a sub-state, the next state will be the sub-state's
 base-state where it will emit a single letter.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Figures/Slide1.eps
	scale 50
	clip

\end_inset


\end_layout

\begin_layout Standard

\series bold
\shape italic
Figure 1: The hidden variable states graph of the HOP-HMM.
 The left hexagons represent base-states, and the circles in the right part
 of each row's represent its sub-states.
 
\series default
\shape default

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Figures/Slide2.JPG
	scale 50
	clip

\end_inset


\end_layout

\begin_layout Standard

\series bold
\shape italic
Figure 2: high-order emission of base-states.
 Each emission is dependent on the hidden base-state and o-1 previous observatio
ns.
\series default
\shape default

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Figures/Slide3.JPG
	scale 50

\end_inset


\end_layout

\begin_layout Standard

\series bold
\shape italic
Figure 3: PWM emission of sub-states.
\series default
\shape default

\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\series bold
\bar under
Parameters
\end_layout

\begin_layout Standard
An HOP-HMM 
\begin_inset Formula $\theta=\{\pi,E,T,G,F\}$
\end_inset

 is parameterized by: 
\end_layout

\begin_layout Itemize
\begin_inset Formula $\pi:\text{ }m\times1$
\end_inset

 initial base-state distribution vector 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi_{j}=P(y_{1}=j)
\]

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $E:\text{ }m\times\underset{o\ times}{\underbrace{4\times4\times...\times4}}$
\end_inset

 the base-state high-order emission probability matrix 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{j,x_{t-o+1},x_{t-o+2},...,x_{t}}=P\left(x_{t}|y_{t}=(j,0),x_{t-o+1},...,x_{t-1}\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $T:\text{ }m\times m$
\end_inset

 the transition probability matrix 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T_{j_{1},j_{2}}=P\left(y_{t+1}=(j_{2},0)|y_{t}=(j_{1},0)\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $G:\text{ }m\times k$
\end_inset

 the sub-state entry probability matrix 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G_{j,l}=P\left(y_{t+1:t+|W_{l}|}=(j,l)|y_{t}=(j,0)\right)
\]

\end_inset


\end_layout

\begin_layout Part*
HOP-EM Algorithm
\end_layout

\begin_layout Standard
(TODO: where should I put this?)
\end_layout

\begin_layout Standard
Denote 
\begin_inset Formula $L_{M}(\overline{x})$
\end_inset

 as the likelihood of motif 
\begin_inset Formula $\overline{x}$
\end_inset

 , i.e.
 the probability that 
\begin_inset Formula $\overline{x}$
\end_inset

 was generate by PWM M
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L_{M}(\overline{x})=P(\overline{x}|M)=\underset{i\in\{1,...,|\overline{x}|\}}{\prod}M_{\overline{x}_{i},i,}
\]

\end_inset


\end_layout

\begin_layout Standard
HMM problem:
\end_layout

\begin_layout Standard
Given the observation sequence X, and a model 
\begin_inset Formula $\theta=(\pi,E,T,G)$
\end_inset


\end_layout

\begin_layout Standard
How can we compute the probability of the hidden states at each position
 
\begin_inset Formula $P(y_{t}|X,\theta)$
\end_inset

?
\end_layout

\begin_layout Standard
How can we calculate 
\begin_inset Formula $P(X|\theta)$
\end_inset

, and what model 
\begin_inset Formula $\theta'$
\end_inset

 maximizes the 
\begin_inset Formula $P(X|\theta)$
\end_inset

?
\end_layout

\begin_layout Section*

\bar under
E-Step:
\bar default
 Forward Algorithm
\end_layout

\begin_layout Standard
As in the Forward Algorithm (Rabiner, 1989) we calculate the distribution
 of the t'th hidden-state, considering the observations from the beginning
 of the sequence until the t'th letter.
 In this version, it is enough to calculate only the probability of being
 in the base-states and not the sub-states, i.e.
 
\begin_inset Formula $\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)$
\end_inset

.
 We calculate 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 iterating over 
\begin_inset Formula $t=1,2,...,L$
\end_inset

 where the initial for 
\begin_inset Formula $t=1$
\end_inset

: 
\begin_inset Formula $\alpha_{j,1}=P\left(y_{1}=(j,0),x_{1}\right)=\pi_{j}\cdot\underset{i_{1},...,i_{o-1}}{\sum}E_{j,i_{1},...,i_{o-1},x_{1}}$
\end_inset


\end_layout

\begin_layout Standard
For 
\begin_inset Formula $t\in\{1...L\}$
\end_inset

 the table is filled dynamically:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\alpha_{j,t}= & P(y_{t}=(j,0),x_{1:t})=\\
= & \underset{\text{base-state transitions}}{\underbrace{\sum_{j'\in\{1,...,m\}}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1}^{i},...,x_{t}^{i}}}}\\
+ & \underset{\text{sub-state transitions}}{\underbrace{\sum_{l\in\{1,...,k\}}\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Explanation:
\end_layout

\begin_layout Standard
From the law of total probability, the probability 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 is the sum of probabilities of all the possible transition that ended in
 the base-state (j,0).
 The possible transitions are base-state to base-state transitions and sub-state
 to base-state transitions.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\underset{\text{base-state transitions}}{\underbrace{\underset{j'\in\{1,...,m\}}{\sum}P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)}}+\underset{\text{sub-state transitions}}{\underbrace{\underset{l\in\{1,...,k\}}{\sum}P\left(y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard
Develop of a sub-state transition using the chain rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t-|W_{l}|:t-1}=(j',l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)= & \,P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot\\
 & \cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\\
 & \cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\\
 & \cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1},y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because of 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent on only 
\begin_inset Formula $y_{t}$
\end_inset

 (and also 
\begin_inset Formula $x_{t-o:t-1}$
\end_inset

 if 
\begin_inset Formula $y_{t}$
\end_inset

 is a base-state) and 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent on only 
\begin_inset Formula $y_{t-1}$
\end_inset

, we can simplify the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t-|W_{l}|:t-1}=(j',l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)= & \,P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\\
 & \cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0)\right)\\
 & \cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l)\right)\\
 & \cdot P\left(x_{t}|y_{t}=(j,0),x_{t-o:t-1}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can now replace the received terms with the components of 
\begin_inset Formula $\theta$
\end_inset

 and with already filled 
\begin_inset Formula $\alpha$
\end_inset

 cells:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-|W_{l}|:t-1}^{i}=(j,l),y_{t-|W_{l}|-1}^{i}=(j,0),x_{1:t}^{i}\right)=\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
This process is similar to the base-state transition.
 Using the chain rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(x_{t}|y_{t}=(j,0),y_{t-1}=(j',0),x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
Using the conditional independencies to simplify the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P(y_{t-1}=(j',0),x_{1:t-1})\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1}\right)=\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Standard

\series bold
\bar under
Backward Algorithm
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\beta_{j,t}= & P\left(x_{t+1:L}|y_{t}=(j,0)\right)=\\
= & \underset{\text{base-state transitions}}{\underbrace{\sum_{j'\in\{1,...,m\}}\beta_{j',t+1}\cdot E_{u,x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}}}\\
+ & \underset{\text{sub-state transitions}}{\underbrace{\sum_{l\in\{1,...,k\}}\beta_{j,t+|W_{l}|+1}\cdot L_{W_{l}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t-o+|W_{l}|+2},...,x_{t+|W_{l}|+1}}\cdot G_{j,l}}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
TODO: how out of range is handled for the PWMs.
 The problem of peaking before the t when doing a high-order emission of
 the base-states
\end_layout

\begin_layout Standard
Law of total probabilty:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{t+1:L}|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\underset{\text{base-state transition}}{\underbrace{\sum_{j'}P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0)\right)}}+\underset{\text{sub-state transition}}{\underbrace{\sum_{l}P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard
For the base-state transition term,using the chain rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0)\right)= & P\left(x_{t+2:L}|y_{t+1}=(j',0),y_{t}=(j,0),x_{t+1}\right)\\
 & \cdot P\left(x_{t+1}|y_{t+1}=(j',0),y_{t}=(j,0)\right)\\
 & \cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using the conditional independencies to simplify the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0)\right)= & P\left(x_{t+2:L}|y_{t+1}=(j',0)\right)\\
 & \cdot P\left(x_{t+1}|y_{t+1}=(j',0),y_{t}=(j,0)\right)\\
 & \cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0)\right)=\\
= & \beta_{j',t+1}\cdot E_{u,x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $P\left(y_{t-|W_{l}|:t-1}=(j',l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)=\,P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot\cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1},y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0)\right)$
\end_inset


\end_layout

\begin_layout Standard
For the sub-state transition term, using the chain rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)= & P\left(x_{t+\left|W_{l}\right|+2:L}|x_{t+1:t+\left|W_{l}\right|+1},y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\\
 & \cdot P\left(x_{t+\left|W_{l}\right|+1}|x_{t+1:t+\left|W_{l}\right|},y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\\
 & \cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\\
 & \cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using the conditional independencies to simplify the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)= & P\left(x_{t+\left|W_{l}\right|+2:L}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\\
 & \cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\\
 & \cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\\
 & \cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)=\\
= & \beta_{j,t+|W_{l}|+1}\cdot E_{j,x_{t-o+|W_{l}|+2},...,x_{t+|W_{l}|+1}}\cdot L_{W_{l}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot G_{j,l}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\series bold
\bar under
M-Step
\end_layout

\begin_layout Standard
First we calculate auxiliary variables:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\psi_{i,j,l,t}= & P\left(y_{t}^{i}=(j,0),y_{t+1:t+|W_{l}|}^{i}=(j,l),y_{t+|W_{l}|+1}^{i}=(j,0),X_{i}\right)\\
= & \alpha_{i,j,t}\cdot F_{j}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1}^{i},...,x_{t+|W_{l}|}^{i}\right)\cdot E_{j,x_{t+|W_{l}|-o+2}^{i},...,x_{t+|W_{l}|+1}^{i}}\cdot\beta_{i,j,t+|W_{l}|+1}
\end{align*}

\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\gamma_{i,j,t}= & P\left(y_{t}^{i}=(j,0)|X_{i}\right)=\frac{P\left(y_{t}^{i}=(j,0),X_{i}\right)}{P\left(X_{i}\right)}\\
= & \frac{\alpha_{i,j,t}\cdot\beta_{i,j,t}}{\underset{j'\in\{1,...,m\}}{\sum}\left(\alpha_{i,j',t}\cdot\beta_{i,j',t}+\underset{l\in\{1,...,k\}}{\sum}\underset{s\in\{1,...,|W_{l}|\}}{\sum}\psi_{i,j',l,t-s}\right)}
\end{align*}

\end_inset


\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Formula 
\[
P\left(y_{t}=(j,0),x_{1:L}\right)=P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{1:t},y_{t}=(j,0)\right)\approx P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|y_{t}=(j,0)\right)=\alpha_{j.t}\cdot\beta_{j,t}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\approx=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $P\left(x_{1:L}\right)=\underset{j\in\{1,...,m\}}{\sum}\alpha_{j,1}\cdot\beta_{j,1}=\underset{j\in\{1,...,m\}}{\sum}P\left(y_{1}=(j,0)|x_{1}\right)\cdot P\left(x_{2:L}|y_{1}=(j,0)\right)=\underset{j\in\{1,...,m\}}{\sum}\frac{P\left(y_{1}=(j,0),x_{1}\right)}{P\left(x_{1}\right)}\cdot\frac{P\left(y_{1}=(j,0),x_{2:L}\right)}{P\left(y_{1}=(j,0)\right)}=$
\end_inset


\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
TODO: does different t gives different 
\begin_inset Formula $P\left(x_{1:L}\right)=\underset{j'\in\{1,...,m\}}{\sum}\alpha_{i,j',t}\cdot\beta_{i,j',t}$
\end_inset

? Should it?
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\xi_{i,j_{1},j_{2},t}= & P\left(y_{t}^{i}=(j_{1},0),y_{t+1}^{i}=(j_{2},0)|X_{i}\right)=\frac{P\left(y_{t}^{i}=(j_{1},0),y_{t+1}^{i}=(j_{2},0),X\right)}{P\left(X_{i}\right)}\\
\\
= & \frac{\alpha_{i,j_{1},t}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+2}^{i},...,x_{t+1}^{i}}\cdot\beta_{i,j_{2},t+1}}{\underset{j'_{1},j'_{2}\in\{1,...,N\}}{\sum}\alpha_{i,j'_{1},t}\cdot\left(1-F_{j'_{1}}\right)\cdot T_{j'_{1},j'_{2}}\cdot E_{j'_{2},x_{t-o+2}^{i},...,x_{t+1}^{i}}\cdot\beta_{i,j'_{2},t+1}+\underset{j',\in\{1,...,N\}\,l\in\{1,...,k\}}{\sum}\left(\underset{s\in\{0,...,|W_{l}|\}}{\sum}\psi_{i,j',l,t-s}\right)}
\end{align*}

\end_inset


\begin_inset Newline newline
\end_inset

 TODO: maybe denote a new variable to make above formula nicer?
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\eta_{i,j,l,t}= & P\left(y_{t}^{i}=(j,0),y_{t+1:t+|W_{l}|}^{i}=(j,l)|X_{i}\right)\\
= & \frac{P\left(y_{t}^{i}=(j,0),y_{t+1:t+|W_{l}|}^{i}=(j,l),X_{i}\right)}{P\left(X_{i}\right)}\\
= & \frac{\psi_{i,j,l,t}}{\underset{j'\in\{1,...,m\}}{\sum}\left(\alpha_{i,j',t}\cdot\beta_{i,j',t}+\underset{l\in\{1,...,k\}}{\sum}\underset{s\in\{1,...,|W_{l}|\}}{\sum}\psi_{i,j',l,t-s}\right)}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We use the temporary auxiliary variables to calculate the 
\begin_inset Formula $\theta_{max}$
\end_inset

 that maximizes likelihood of the observations.
\end_layout

\begin_layout Standard
TODO: add mid steps to the calculation to make more readable
\end_layout

\begin_layout Standard
\begin_inset Formula $E_{j,b_{1},b_{2},...,b_{o}}=\frac{\underset{i\in[N]\,t\in[L]}{\sum}\gamma_{i,j,t}\cdot\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1}^{i},...,x_{t}^{i})}{\underset{i\in[N]\,t\in[L]}{\sum}\gamma_{i,j,t}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $T_{j_{1},j_{2}}=\frac{\underset{i\in[N]\,t\in[L]}{\sum}\xi_{i,j_{1},j_{2},t}}{\underset{i\in[N]\,t\in[L]}{\sum}\gamma_{i,j_{1},t}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $F_{j}=\frac{\underset{i\in[N]\,t\in[L]\,l\in[k]}{\sum}\eta_{i,j,l,t}}{\underset{i\in[N]\,t\in[L]}{\sum}\gamma_{i,j,t}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $G_{j,l}=\frac{\underset{i\in[N]\,t\in[L]}{\sum}\eta_{i,j,l,t}}{\underset{i\in[N]\,t\in[L],\,l'\in[k]}{\sum}\eta_{i,j,l',t}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\pi_{j}=\frac{\gamma_{i,j,1}}{\underset{i\in[N]\,j'\in[m]}{\sum}\gamma_{i,j',1}}$
\end_inset


\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset

 
\begin_inset Newline newline
\end_inset

 [Roadmap enhancers preprocessing]
\end_layout

\begin_layout Standard
[training on roadmap data]
\end_layout

\begin_layout Standard
[classification of regulation modules]
\end_layout

\begin_layout Section*
Results
\end_layout

\begin_layout Standard
[test accuracy on roadmap enhancers]
\end_layout

\begin_layout Standard
[prediction on roadmap regulation modules]
\end_layout

\begin_layout Standard
[Whole genome classification?]
\end_layout

\begin_layout Standard
[Was HOP-HMM better?]
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\series bold
\bar under
Possible Applications
\end_layout

\begin_layout Standard
labeled enhancer seqs from multiple motifs-> EM to learn E M F per floor
 + setting 
\begin_inset Formula $T=\mathbb{I}_{m\times m}$
\end_inset

 -> posterior of whole genome with sliding window -> classify whole genome
\end_layout

\begin_layout Standard
learn E M F -> check correlation with TF expression
\end_layout

\begin_layout Standard
run EM on whole genome -> posterior of whole genome -> check correlation
 of posterior to ChIP-Seq of histone modifications
\end_layout

\begin_layout Standard
E M F T-> posterior of whole genome -> see if known critical SNPs are critical
 in classification
\end_layout

\begin_layout Section*
Discussion
\end_layout

\begin_layout Section*
References
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "Theses"
options "plainnat"

\end_inset


\end_layout

\end_body
\end_document
