#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{babel}
\usepackage{float}
\usepackage{fancyhdr}
\end_preamble
\use_default_options false
\begin_modules
logicalmkup
\end_modules
\maintain_unincluded_children false
\begin_local_layout
InsetLayout Flex:Code
    LyxType               charstyle
    LabelString           code
    LatexType             command
    LatexName             code
    Font
      Family              Typewriter
    EndFont
    Preamble
    \newcommand{\code}[1]{\texttt{#1}}
    EndPreamble
    InToc                 true
    HTMLTag               code
End
\end_local_layout
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "newtxmath" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\output_sync_macro "\synctex=1"
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize 11
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 1.5cm
\headheight 0cm
\headsep 0cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size larger
\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset

Classification of Regulatory Sequences 
\begin_inset Newline newline
\end_inset

in the Human Genome Using High-Order 
\begin_inset Newline newline
\end_inset

Generalized Hidden Markov Model 
\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center
by
\begin_inset Newline newline
\end_inset


\size larger
David Taub
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size larger
\begin_inset space ~
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center
Supervised by
\begin_inset Newline newline
\end_inset


\size larger
Prof.
 Tommy Kaplan
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center
A thesis submitted in partial fulfillment of the requirements for the
\begin_inset Newline newline
\end_inset

degree of Master of Science in Computer Science
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size large
April 2020
\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size larger
The Faculty of Computer Science and Engineering
\begin_inset Newline newline
\end_inset

The Hebrew University of Jerusalem, Israel
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Abstract
\end_layout

\begin_layout Standard
Enhancers are regulatory DNA sequences that, when bound to proteins called
 transcription factors, increase the likelihood of transcription of the
 enhancer target genes.
 Regulation of transcription is an important form of control of gene expression,
 and the activity of enhancers plays a significant role in the stage-specific
 and tissue-specific regulation of genes.
 It has been shown over the years that genetic variations within enhancer
 sequences might cause cell behavior modifications and diseases.
 The rules and nuances of enhancer structure is not fully understood yet,
 though it has been shown that transcription factors tend to attach to them
 at unique motifs called transcription factor binding sites, which are over-repr
esented in enhancer sequences.
 Enhancer activity can be detected by the epigenetic data from the local
 environment around its position.
 The main indicators for an enhancer lay in the adjacent histone modifications,
 around which the flanks of the enhancer are wrapped.
 The enhancer itself tends to be spatial accessible for biochemical interactions
 between the DNA and the proteins around it.
 Though useful, the epigenetic data are often noisy and require a costly
 extraction process of specific cells out of a tissue sample, which is not
 necessarily practical for all cell types and their different stages.
 An alternative approach to enhancer detection is to observe the genetic
 content of its sequence, since it contains all the essential information
 for the DNA to act as an enhancer.
 Over the years, it was demonstrated in vivo that the cell requires no other
 mechanism than the sequence in order to regulate its gene expression.
 With that idea in mind, we offer a computational approach for the detection
 of enhancers based on their sequences alone, and in an unsupervised manner.
 We created a high-order generalized hidden Markov model (HOP-HMM), with
 two kinds of states: one which emits transcription factor binding sites
 by using a positional weight matrix model, and one which emits single nucleotid
es with high order dependency on previously emitted nucleotides.
 Compared to a regular hidden Markov model, this model learns a more complex
 underlying structure of DNA sequences, containing both binding site motifs
 and high-order distribution of nucleotides in between them.
 We'll first review the biological background of enhancers, specifically
 in humans.
 Then we'll review in depth the background of Markov and hidden Markov models,
 and discuss how to calculate the likelihood of a sequence given this model.
 We'll describe our generalized model in detail and develop the expectation
 maximization and Viterbi algorithms for hidden Markov models, followed
 by the adjustments needed for our generalized model.
 These algorithms implementations are demonstrated by applying them to a
 synthetic dataset of enhancer-like sequences created by using the generative
 property of the generalized model.
 We simulate the model in a controlled way to evaluate its performance by
 inferring estimated parameters of the model and comparing them to the real
 parameters used to create the dataset.
 Finally, we apply the expectation maximization algorithm for training a
 HOP-HMM from human DNA enhancer sequences, selected by the epigenetic data
 of the Roadmap project.
 We demonstrate the capabilities of the model by comparing its estimation
 to the epigenetic tracks, showing it can predict the loci of enhancers
 and in which tissues they will be active, without exposure to epigenetic
 data.
 
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
The genome of every living organism contains the inherited information which
 defines its complex structure and function.
 The genome is built out of deoxyribonucleic acid (DNA) molecules, a structure
 of two chains of nucleotides units forming a double helix shape.
 Nucleotides are built out of 4 different basic elements: cytosine, guanine,
 adenine or thymine or in short A,C,G and T.
 The nucleotides are organized in pairs called base pairs, with each of
 the paired nucleotides being complementary to the other and providing redundanc
y.
 
\end_layout

\begin_layout Standard
Proteins are macromolecules, which ensure various roles and functions within
 organisms.
 They have the structure of a polymer built out of 20 different amino acids,
 whose order and structure are encoded in genes (genetic segments within
 the genome).
 Through transcription followed by translation processes, the genes are
 expressed and result in the formation of proteins.
 In the transcription process the gene is read and transcribed into a single
 strand sequence of RNA.
 Later, the formed RNA molecule, which at this stage is called messenger
 RNA (mRNA), is translated by a complex molecule called the ribosome.
 The mRNA sequence is built out of triplets of nucleotides called codons,
 which are read by the ribosome and instruct it how to generate a sequence
 of amino acids constituting the protein.
 
\end_layout

\begin_layout Standard
Gene sequences are built out of fragmented introns and exons, where only
 the exons mature into mRNA molecules which are translated into proteins,
 while the introns are spliced away beforehand.
 Counter intuitively, even though the exons hold the recipe for the construction
 of the proteins of the organism, its complexity is not a product of their
 number or their length.
 For example, both humans and Caenorhabditis elegans roundworms have about
 19,000 genes with roughly the same total exon length and number (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-57"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-16"

\end_inset

), even though the human body is much more diverse and complex.
 Although the genes are responsible for the variety of proteins a cell can
 produce, the source of organism complexity, with different cells performing
 different tasks while carrying the same genome, stems from the gene regulation
 mechanism.
 In the case of humans, the genome is 3.23 Gb long and it is estimated that
 the total length of gene regulation regions involves 10-20% of it (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-46"

\end_inset

), compared to exon regions which involve only 1% (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-45"

\end_inset

).
\end_layout

\begin_layout Standard
Enhancers are non-coding regulatory DNA sequences which play a key role
 in the regulation transcription of genes.
 In humans, there are hundreds of thousands of enhancers scattered over
 the non-coding regions of the genome, usually of a length between 100-1000
 base pairs (bp).
 When activated, the DNA folding draws the enhancer spatially closer to
 another type of regulatory element called promoter, resulting in the translatio
n of the gene adjacent to the promoter (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Transcription"

\end_inset

).
 The gene expressed by this activation process is the enhancer’s target
 gene, and it can be located up to one megabase pair (Mb) upstream or downstream
 from its activating enhancer as enhancers generally function independently
 of orientation (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-43"

\end_inset

).
 Moreover, the gene-enhancer connection is not exclusive, and it has been
 shown that the most common case is that each enhancer has several target
 genes and vice-versa (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-20"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Enhancer_gene_transcription.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Transcription"

\end_inset


\series bold
A)
\series default
 An enhancer and its distal target gene.
 
\series bold
B)
\series default
 The DNA folds and the attaches to transcription factors, which then draw
 other co-factor proteins that together form the transcription complex.
 
\series bold
C)
\series default
 The RNA Polymerase II is recruited and while moving along the gene, it
 generates a new RNA molecule which is transcribed off the gene.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
An enhancer is described as being in an active status when it is causing
 the expression of its target gene, which does not occur evenly across different
 types of cells.
 The activity of the enhancer sequence plays a critical role in the resulting
 type of cells.
 In the VISTA Project (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

), fertilized mouse eggs were injected with enhancer sequences adjacent
 to a LacZ reporter gene, encoding an enzyme protein with a blue color.
 Since they were synthesized, the injected DNA sequences containing the
 enhancer and reporter genes bore no epigenetic information, and they were
 integrated into the mouse genome in an arbitral position.
 The enhancers in the injected DNA sequences originated from the human genome,
 and each enhancer was injected into a different embryo.
 When the transgenic embryos were photographed after 11.5 days some had a
 distinctive anatomical pattern, such as blue limbs or blue spine, depending
 on the injected DNA sequence.
 These results imply that for many DNA sequences, the DNA code possesses
 by itself the potential to become a specific tissue enhancer, despite the
 absence of epigenetic information.
 
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/f735.jpg
	scale 15

\end_inset


\begin_inset Graphics
	filename Figures/experiment_process.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Mouse"

\end_inset

Transgenic mouse embryo on the 11.5 day.
 A fertilized egg was injected with a synthetic enhancer sequence known
 to be related to the dorsal root ganglia of spinal neurons.
 The enhancer became activated and caused the expression of the blue color
 marker gene that was coupled to it.
 Both images are taken from Vista Enhancer Browser, on the left is experiment
 hs-51 embryo 2.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Transcription factors (TF) are proteins that bind to the DNA, and together
 with other cofactor proteins initiate the gene transcription process of
 the DNA sequence.
 TFs tend to bind to their transcription factor binding sites (TFBS), which
 are motifs of nucleotides in the DNA sequence.
 The average length of TFBS in humans is 12 bp (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-36"

\end_inset

), and they are highly conserved between various species (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-12"

\end_inset

).
 When analyzing a tissue sample for TF interaction density, a chromatin
 immunoprecipitation sequencing (ChIP-seq) method is used to probe the amount
 of TFs in affinity to the DNA strands.
 Briefly, this method involved applying antibodies on cross-linked DNA,
 which attach to the TFs linked to the DNA.
 This antibody attachment is followed by massive parallel sequencing of
 the short DNA sequences around the TF and the antibody.
 Genome-wide association studies (GWAS) of ChIP-seq found that different
 TFs have different and distinct distributions of TFBS (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-32"

\end_inset

).
\end_layout

\begin_layout Standard
The TFBSs in both enhancers and promoters are critical for their correct
 regulatory activity.
 Multiple studies have shown that genetic alterations in enhancer’s TFBSs
 can affect the expression of their target genes and are a major cause of
 various human diseases (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-35"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-44"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-54"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-53"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-6"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-13"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-39"

\end_inset

).
 From the sequence aspect, enhancers and promoters have a similar structure:
 both have different nucleotide frequencies compared to other parts of the
 genome, and both contain TFBSs tiled inside background sequences.
\end_layout

\begin_layout Standard
Folding of the DNA allows enhancer-promoter interactions, in which the TFs
 play a major part.
 Once bounded to the DNA, the TFs recruit other protein cofactors, and together
 they form a transcription preinitiation complex (PIC), consisting of a
 very large assembly of proteins.
 Out of the tens of proteins constructing the PIC, the sub-unit RNA polymerase
 (RNA pol II) has the important role of transcribing the adjacent gene.
 It slides along the double-stranded DNA and opens it until one strand of
 nucleotides is exposed and becomes a template for RNA synthesis.
\end_layout

\begin_layout Standard
Though it is tempting to imagine each TF as having a corresponding TFBS
 with a single motif of nucleotides that fits it, modeling the kinetic and
 thermodynamic aspects involved in the DNA-protein interaction is far from
 simple (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-67"

\end_inset

), and each sequence of nucleotides has the likelihood to form a bond, which
 is not simple to calculate analytically.
 In order to generate a simplistic yet statistically accurate model representing
 the TF binding potential of a DNA sequence, i.e.
 
\begin_inset Formula $P\left(x_{1:n}|binding\right)$
\end_inset

, we need to assume an independence between positions as well as a small
 range of influence of the sequence around the binding site.
 For samples of such distribution, the peaks of the ChIP-seq readings marking
 the TF binding are often used, from which a binding site “grammar” can
 be modeled.
 Position weight matrix (PWM), as introduced in 
\begin_inset CommandInset citation
LatexCommand citet
key "key-7"

\end_inset

, is the most commonly used probabilistic model to address this task.
 The underlying assumption of the PWM model is that every position in the
 DNA sequence has an independent probability to attach to the TF, and therefore
 the total binding probability is a multiplication of all the per-position
 probabilities in the motif:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{1:J}|binding\right)=\prod_{j\in[n]}P\left(x_{j}|binding\right)
\]

\end_inset

Where J is the length of the relevant sequences affected by the binding
 event, and is derived from the physical characteristics of the TF.
 Practically, this size is often estimated from the observed motifs in the
 TF’s ChIP-seq peaks.
 For each j, 
\begin_inset Formula $P\left(x_{j}|binding\right)$
\end_inset

 is estimated by counting the frequency of the nucleotides in the j’th position
 of the observed binding sites which are situated in the ChIP-seq peaks.
 For a motif of length J, the estimation of this probability is stored in
 a position probability matrix (PPM) W as followed: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
W_{i,j}=\frac{1}{N}\sum_{n\in[N]}\boldsymbol{1}\left(x_{j}^{(n)}=i\right)
\]

\end_inset

where 
\begin_inset Formula $x^{(n)}$
\end_inset

 is the n’th sequence of the found binding sites, 
\begin_inset Formula $j\in[J]$
\end_inset

 the position in the motif and 
\begin_inset Formula $i\in[4]$
\end_inset

 the nucleotide index of A,C,G and T.
 To enable comparison between the binding likelihood of TFBS of different
 lengths, the use of the normalized form of PPM, the PWM, is more convenient:
\begin_inset Formula 
\begin{equation}
{\displaystyle M_{i,j}=\mathrm{log}\left(\frac{W_{i,j}}{b_{i}}\right)}\label{PPM}
\end{equation}

\end_inset

where 
\begin_inset Formula $b_{i}$
\end_inset

 is the prior background model, which is 0.25 in case of nucleotides.
 From a generative model point of view, the TFBS sequence is generated by
 an emission model of the PWM.
 When a convolution of M is applied on the one-hot encoding of the sequence
 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

), the result is the log likelihood of a TF binding to a sequence relative
 to a random sequence.
 In this work we'll use the more familiar term PWMs though we actually used
 the unnormalized PPMs for the TFBS emission model, since we required the
 likelihood of a TF binding and not a length-independent comparison between
 TFs.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/pwm_mult.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "PWM"

\end_inset

Sub-sequences out of the DNA are represented in a one-hot encoding, and
 multiplied entry-wise by a PWM.
 Then, the sum of the logs of the maximal values in each column of the resulting
 matrix is calculated, which represents the log likelihood of the TF binding
 to the sub-sequence.
 This log likelihood is calculated for each location in the sequence, in
 which locations with high values indicate a high likelihood of TF binding.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Detection of enhancers and of the tissues in which they are active has been
 the subject of much research in the last few decades.
 Specifically, an enhancer detection method relying only on their sequences
 and without need for biological experimentation is an especially sought-after
 goal.
 Such biological experiments, some of which are mentioned in this work,
 involve cells whose enhancers activate their target genes during the experiment
, which is usually an expensive and non-trivial requirement.
 All methods for detecting active enhancers “in the act” are inherently
 limited to the specific tissues we can extract and isolate in a lab.
 Furthermore, many enhancers are only active in specific cell types and
 at specific stages, and achieving a study of every cell type at every possible
 stage in complex organisms is not a practical requirement for the foreseeable
 future.
 On the other hand, the genome of organisms can be easily and inexpensively
 sequenced for later analysis in-silico.
 The ultimate goal of an efficient computational method which would predict
 and explain the functional nature of an enhancer sequence has produced
 positive, yet far from sufficient results over the last years, as reviewed
 in (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-33"

\end_inset

).
\end_layout

\begin_layout Standard
As an alternative, a potential way of detecting enhancers only by addressing
 their sequences, would consist in finding non-coding regions which are
 conserved across species.
 Conserved non-coding elements (CNE) have a tendency to reside in clusters,
 which usually have low gene density but are located in vicinity to genes
 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-11"

\end_inset

).
 Evidently, the overlap between CNEs and enhancers is imprecise.
 Some verified enhancers are weakly (or not) conserved between species (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-21"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-52"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-56"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-40"

\end_inset

) and some highly conserved areas in the mouse genome are not associated
 to regulatory activity, but their deletion still yields viable mice (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-1"

\end_inset

).
 Nevertheless, an assay of elements with 100% sequence identity of over
 200 bp between human and mouse found that 50% showed enhancer activity
 in mice (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

).
 The ultra-conservation of 200 bp enhancer sequences containing TFBSs that
 are usually shorter than 15 bp raises the possibility that these conserved
 iter-TFBS parts play a role which it is not yet fully clear.
\end_layout

\begin_layout Standard
Almost all cells in every organism contain their entire genomic payload,
 but only part of this genome is active in any specific cell.
 Essentially, cells of different type and state differ by gene expression
 patterns.
 The reason for this difference between cells lays in regulation components
 not included in the Watson and Crick model of the DNA sequence.
 The location and presence of TFBS, background nucleotides distribution
 and other sequence-related properties are not sufficient to explain the
 regulatory role of certain regions in the genome.
 
\end_layout

\begin_layout Standard
Several epigenetic features, which do not involve the nucleotide sequences
 themselves, correlate with enhancer regions in the genome: 
\end_layout

\begin_layout Itemize
Accessibility
\end_layout

\begin_layout Itemize
TF & cofactors binding
\end_layout

\begin_layout Itemize
Histone modifications
\end_layout

\begin_layout Itemize
DNA methylation
\end_layout

\begin_layout Standard
These mechanisms have measurable features that can be added as a data layer,
 on top of the genome.
 Their combination is the main source of identification and prediction for
 enhancer regions in the genome.
 A single cell has its own epigenetic features, often in binary form, e.g.
 a specific element of the genome can be either accessible or not.
 When several cells epigenetic properties are measured, usually a frequency
 or count of the measured feature per DNA locus is calculated along the
 reference genome.
 The epigenetic data is commonly further processed by calculating its p-value
 compared to a local environment, to which peak boundaries are determined
 (peak calling) using algorithms such as MACS2 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-73"

\end_inset

).
\end_layout

\begin_layout Standard
In eukaryotes, the DNA is packed around a structure of 8 histone proteins
 called a nucleosome, and they form together a chromatin complex.
 Similarly to the TFs, the nucleosome binding location in the DNA sequence
 is not arbitrary.
 Like them, it has a tendency for specific DNA binding sites (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-9"

\end_inset

).
 The DNA wrapped around a nucleosome has a lesser likelihood for interaction
 with proteins, because it is physically inaccessible.
 Accessibility enables the TFs and other proteins to bind to the DNA molecule,
 hence the enhancer, the promoter and the gene all need to be accessible
 for a successful transcription to occur.
 DNase-I hypersensitive (DHS) sites are regions of the DNA which are sensitive
 to cleavage by the DNase-I enzyme.
 In these regions the DNA loses the nucleosome, and becomes accessible and
 therefore potentially active.
 Measurement of DHS cleavages is available through DNase-seq (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-71"

\end_inset

), a high-throughput method for measuring the accessibility epigenetic data
 of the DNA, usually with a better resolution than histone modifications
 measurements.
 A faster and more sensitive technique for accessibility measurement is
 called ATAC-seq (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-70"

\end_inset

), and is currently more commonly used.
 
\end_layout

\begin_layout Standard
Histone modifications, also called histone marks and chromatin modifications,
 are chemical alterations which happen to the long tail-like section of
 the histone protein.
 Histones are numbered from 1 to 8, and for example, the acetylation of
 the lysine amino-acid situated in 14th position in the protein of the 3rd
 histone will be abbreviated as H3K14ac.
 Along many roles in the cell, such as DNA repair and mitosis, histone modificat
ions have a function in the gene regulation processes.
 In the past 20 years, a substantial body of research has shown that histone
 modifications are predictive of enhancer position and activity status (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-19"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-18"

\end_inset

).
 The histone modifications are considered to form a certain “histone code”
 along the genome, which encodes complex information underlying the genomic
 code and is connected to transcription regulation and other aspects.
 Compared to other epigenetic information, chromatin modifications have
 a shorter time scale ranging from seconds to hours (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-25"

\end_inset

), and are therefore considered related to the dynamic changes of the cell.
\end_layout

\begin_layout Standard
Measurement of histone modifications is also performed using the ChIP-seq
 method, similarly to the TF binding detection described above.
 In histone ChIP-seq, antibodies attach to the modifications in the histone
 tails (and not to the TF proteins).
 H3K4me1 and H3K27ac are among the predominant histone modifications of
 active enhancers; H3K4me1 is enriched on transcribed genes and enhancers
 prior to activation (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-7"

\end_inset

), and is thought to precede the H3K27ac modification (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-51"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-62"

\end_inset

) which is known to occur during activation.
 Other histone modifications present on active enhancers and used for their
 detection are H3K9ac (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-15"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-30"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-62"

\end_inset

) and H3K18ac (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-28"

\end_inset

).
 Even though H3K27ac has been identified as an important mark for the differenti
ation of active enhancers from poised enhancers (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

), it is not sufficient by itself since when present alongside H3K4me3 it
 is also an indication for active promoters (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-26"

\end_inset

).
 In contrast, absence of H3K27ac and enrichment of H3K4me1and H3K27me3 are
 typical of poised enhancers (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

).
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Enhancers_status.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Enhancer"

\end_inset

The accessibility of an enhancer’s sequence and its surrounding histone
 modifications are connected to its regulatory activity state.
 The upper diagram shows an active enhancer sequence accessible to the protein
 interaction needed for transcription, whereas the lower one shows an inactive
 enhancer wrapped around a nucleosome and therefore inaccessible.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
DNA methylation of cytosine nucleotides and cytosine guanine nucleotides
 pairs (CpG) has been involved in long-term genome silencing in multiple
 processes (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-29"

\end_inset

) and cell aging (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-48"

\end_inset

).
 It has been documented as widely correlated with inhibition of gene expression
 when present in promoters (
\begin_inset CommandInset citation
LatexCommand citet
key "key-3"

\end_inset

).
 In enhancer elements, an anti-correlation was found between DNA methylation
 density and enrichment of active enhancer histone modifications, and TF
 binding (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-55"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-58"

\end_inset

), although the cause and consequence relationships underlying these correlation
s is not yet clear.
 Currently, the most accurate method for the wide-scale prediction of the
 loci of enhancer sequences in a genome is the analysis of histone modifications
, and TF and cofactors presence using ChIP-seq from a cell line or from
 a tissue, combined with DNase-I hypersensitivity (DHS).
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/genome_browser.png
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "GenomeBrowser"

\end_inset

UCSC Genome Browser showing epigenetic features tracks, taken from the 10th
 chromosome of a H1-hESC cell line.
 Highlighted in light blue, the peaks of H3K27ac (1st green plot) and H3K4me1
 (2nd green plot) histone modifications and the DNase-I hypersensitivity
 features (4th green plot), together with the absence of H3K27me3 (3rd green
 plot) signal indicate an active enhancer, as also marked by the ChromHMM
 classification (bottom).
 Note that the decrease between the two peaks of H3K27ac and H3K4me1 is
 located on top of the increase of the DNase-I hypersensitivity, which implies
 a cleavage in between two nucleosomes with modifications.
 Taken from 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://genome-euro.ucsc.edu/cgi-bin/hgTracks
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Related Work
\end_layout

\begin_layout Standard
Several significant computational efforts were made in the last few years
 for predicting the epigenetic and regulatory properties of DNA elements
 based on the genetic sequence alone.
 DeepSEA (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-63"

\end_inset

) uses a deep convolutional neural network (DCNN) which receives an input
 of 1000 bp sequence, and outputs a prediction vector of 919 binary features
 representing the chromatin modifications of 200 bp in the center of the
 input sequence.
 The training labels used are the chromatin modifications extracted from
 ENCODE and Roadmap epigenetic data releases.
 Basset (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-32"

\end_inset

) also used DCNN on the same data, with known PWMs as weight initialization,
 to predict a binary vector representing accessibility in 164 cell types,
 based on 600 bp DNA sequences.
 In DeepBind (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-2"

\end_inset

) a DCNN was used to predict binding of 538 TFs and 194 RNA binding proteins
 from DNA sequences of varying lengths.
 In gkm-SVM (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-5"

\end_inset

), gapped 
\emph on
k
\emph default
-mers presence indicator vectors were used as features for a SVM classifier
 in order to predict the role of DNA sequences of varying lengths.
 ChromHMM (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-14"

\end_inset

) is a widely used software that tackles the problem of analyzing the epigenetic
 data to predict the role of fragments of genomic sequence.
 The algorithm converts to binary the chromatin modification values by whether
 or not it exceeded a threshold, which is then inserted as input to HMM
 that classifies the genome states.
 A disadvantage of these methods is their need for training data of known
 regulatory elements or epigenetic data which are commonly obtained from
 GWAS surveys, such as those that were done on 127 obtained human cell types
 in the Roadmap and ENCODE projects (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-37"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-15"

\end_inset

).
 
\end_layout

\begin_layout Standard
When a DNA sequence is read from a tissue sample, it is often stored as
 a sequence of letters A,C,G and T in FASTA format.
 For an algorithm to process it, these characters are mapped into a data
 structure of integers 1,2,3 and 4 respectively.
 For many algorithms, such as in DeepSEA, Basset, and our HOP-HMM, it is
 preferable to encode these sequences of integers as a sequence one-hot
 vectors (also called indicator vectors), as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

.
 A commonly used feature extraction technique of DNA sequences is to represent
 them as vectors of their in-sequence k-mer frequencies as used in gkm-SVM.
 In this technique, the order of the k-mer is sacrificed for a more meaning-orie
nted, structured and fixed-length data encoding, similarly to the bag of
 words technique in text analysis and natural language processing.
 
\end_layout

\begin_layout Subsubsection*
Machine Learning Models
\end_layout

\begin_layout Standard
The goal of machine learning classification models is to arrive from the
 observed X to its label Y.
 In the DNA classification case discussed in this work, the goal is deciding
 its role label Y for a given a DNA sequence X.
 There are two main approaches to this goal: generative models and discriminativ
e models.
 Both approaches assume observed variables X and target variables Y, also
 commonly referred to as data samples and labels.
 
\end_layout

\begin_layout Itemize
Generative models assume a joint probability 
\begin_inset Formula $P\left(X,Y\right)$
\end_inset

.
 Using dataset of 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 pairs, one can estimate the distribution 
\begin_inset Formula $P\left(X,Y\right)$
\end_inset

, then estimate from it 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

.
 The distinctive feature of these models is their ability to generate random
 instances of the data, either as pairs of 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 or as instances of x given y.
\end_layout

\begin_layout Itemize
Discriminative models assume conditional probability 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

, which is estimated directly from the dataset.
\end_layout

\begin_layout Standard
Both models eventually base their classification upon the 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

 estimation.
 Namely, classifying a data sample x by the most likely label: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{est}=argmax_{y}P\left(Y=y|X=x\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Discriminative models are more widely used than generative models, they
 are often easier to use and build since they require fewer assumptions
 on the origin and generation of the data.
 For instance, the deep neural network (DNN) is a model that has gained
 much interest lately in the machine learning field, and was also used for
 the task of classifying the role of DNA sequences.
 As a discriminative model it assumes very little regarding the way the
 DNA sequence is generated based on its role, but finds instead features
 in the sequence that imply its role.
 Hence it is often difficult to use such a model for a later understanding
 of the nature of the data generation process, or to generate new data from
 it.
 
\end_layout

\begin_layout Standard
Markov model (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-42"

\end_inset

), named after the Russian mathematician Andrey Markov, is a stochastic
 model which is applied to a system that changes randomly, such as the weather
 or car traffic.
 This model is at one of m states 
\begin_inset Formula $\left\{ S_{1},...,S_{m}\right\} $
\end_inset

 at any time, with the first state being sampled from a distribution 
\begin_inset Formula $\pi_{i}=P\left(y_{1}=S_{i}\right)$
\end_inset

 and the probability of transitions between the states being denoted by
 
\begin_inset Formula $T_{i,j}=P\left(y_{t}=S_{i}|y_{t-1}=S_{j}\right)$
\end_inset

.
 The travel of the model over the states is named a Markov process, and
 the sequence of the states visited in the process is called a Markov chain.
 The likelihood of a Markov chain X generated by a Markov Model 
\begin_inset Formula $\theta=\{\pi,T\}$
\end_inset

 is a joint probability of the first state and of all following transitions
 which, due to the independence between transition events, can be written
 as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{L}(\theta;X)=P_{\theta}(x_{0},x_{1},...,x_{L})=\pi_{x_{0}}\cdot T_{x_{0},x_{1}}\cdot T_{x_{1},x_{2}}\cdot...\cdot T_{x_{L-1},x_{L}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Markov_model.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Markov"

\end_inset


\series bold
A)
\series default
 Markov model with 3 states (a,b and c).
 
\series bold
B,C)
\series default
 The model starts with a state sampled from π, and travels between the states
 with a transition distribution T.
 
\series bold
D)
\series default
 The model can generate Markov chains of states, where the transition between
 the states is only conditioned by the previous state, causing the Markov
 process to be memoryless.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The hidden Markov model (HMM) is a Markov model extension which models a
 system that travels over hidden states as a Markov process, and while doing
 so emits variables called observed variables.
 Like the Markov model, HMM is a generative model, and therefore assumes
 the existence of a joint probability 
\begin_inset Formula $P\left(x_{1:L},y_{1:L}\right)$
\end_inset

 derived from the compact parameters 
\begin_inset Formula $\theta$
\end_inset

.
 HMM relies on the assumption that the observed DNA sequence 
\begin_inset Formula $X=x_{1},...,x_{L}$
\end_inset

 is generated by a parameterized model 
\begin_inset Formula $\theta$
\end_inset

, and has a hidden sequence 
\begin_inset Formula $Y=y_{1},...,y_{L}$
\end_inset

 that was generated alongside it.
 In this generation process, a single observed variable is emitted for every
 step of the model, and thus the observed sequence is generated with the
 same length as the hidden Markov chain.
 For an alphabet of variables 
\begin_inset Formula $\left\{ V_{1},...,V_{n}\right\} ,$
\end_inset

 and hidden state space 
\begin_inset Formula $\left\{ S_{1},...,S_{m}\right\} $
\end_inset

, the observed variable 
\begin_inset Formula $x_{t}$
\end_inset

 is sampled from an emission distribution conditioned on the hidden state
 of the model 
\begin_inset Formula $E_{i,j}=P\left(x_{t}=V_{j}|y_{t}=S_{i}\right)$
\end_inset

.
 Similarly to the Markov model, the distribution to the first hidden state
 is marked as 
\begin_inset Formula $\pi$
\end_inset

 and the transition distribution is marked as 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HMM_two_states.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "HMM"

\end_inset


\series bold
A)
\series default
 HMM with 2 hidden states.
 
\series bold
B)
\series default
 The observed variables (dark blue) are emitted by the hidden state at their
 location, sampled from the discrete conditional distribution E.
 
\series bold
C,D)
\series default
 The hidden states (yellow and green) behave as Markov model states with
 starting and transition probabilities 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

.
 
\series bold
E)
\series default
 The output of the model is an observable sequence with an underlying hidden
 sequence.
 The hidden sequence is a Markov chain, where on each step the hidden state
 emits a single observed variable.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
HMM is a very popular signal processing algorithm that has been adopted
 in the various fields of computational biology since the 1980’s.
 HMM was proposed by Leonard Baum (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-4"

\end_inset

) and is used for modeling regions with alternating frequencies of patterns
 and symbols.
 In a non-biological context, it was used extensively in various engineering
 fields, especially in speech recognition (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-49"

\end_inset

), handwriting recognition (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-27"

\end_inset

) and digital communication (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-59"

\end_inset

).
\end_layout

\begin_layout Standard
For example, in the case where the observable sequence is made out of DNA,
 a simplistic model can assume that the DNA sequence is composed out of
 4 states: genes, promoter enhancers and background regions.
 Each of these states will have a different nucleotide frequency, and we
 assume that the DNA sequence was generated by a HMM with underlying sequences
 of 4 hidden states, one for each region type.
 The emitted DNA sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

 is determined by the underlying hidden sequence y1:L that describes the
 “mode” of the sequence for each location.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
Having a HMM with 
\begin_inset Formula $θ$
\end_inset

 on hand and given an observed sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

, two questions arise: :
\end_layout

\begin_layout Itemize
What is the likelihood that 
\begin_inset Formula $x_{1:L}$
\end_inset

 was generated by the HMM with parameters 
\begin_inset Formula $\theta$
\end_inset

 or 
\begin_inset Formula $P_{\theta}\left(x_{1:L}\right)$
\end_inset

?
\end_layout

\begin_layout Itemize
What is the probability of a hidden state at every location or 
\begin_inset Formula $P_{\theta}\left(y_{t}=j|x_{1:L}\right)$
\end_inset

?
\end_layout

\begin_layout Standard
The two above-mentioned probabilities are named the likelihood function
 and the posterior probabilities of HMM.
 As in many generative models, HMM’s likelihood function 
\begin_inset Formula $\mathcal{L}\left(\theta|x_{1:L}\right)$
\end_inset

 relating to the first question can be split by the total probability law
 to the sum of all possible hidden sequences: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathcal{L}\left(\theta;x_{1:L}\right)=P_{\theta}\left(x_{1:L}\right)=\sum_{y_{1:L}\in\left[m\right]^{L}}P_{\theta}\left(x_{1:L},y_{1:L}\right)\label{Likelihoods}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The probability 
\begin_inset Formula $P_{\theta}\left(x_{1:L}\right)$
\end_inset

 is called the incomplete-data likelihood function and the probability 
\begin_inset Formula $P_{\theta}\left(x_{1:L},y_{1:L}\right)$
\end_inset

 is called the complete-data likelihood function.
 In the case of HMM with parameters 
\begin_inset Formula $\theta$
\end_inset

, the complete-data can be calculated by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P_{\theta}\left(x_{1:L},y_{1:L}\right)=P_{\theta}\left(y_{1}\right)\cdot P_{\theta}\left(x_{1}|y_{1}\right)\cdot\prod_{i=2}^{N}P_{\theta}\left(y_{i}|y_{i-1}\right)\cdot P_{\theta}\left(x_{i}|y_{i}\right)=\pi_{y_{1}}E_{y_{1},x_{1}}\prod_{i=2}^{L}T_{y_{i-1},y_{i}}E_{y_{i},x_{i}}\label{Complete-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Although the computation of the complete-data likelihood of 
\begin_inset Formula $\theta$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Complete-Likelihood"

\end_inset

 is linear-by-L, naively computing the incomplete-data likelihood as in
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Likelihoods"

\end_inset

 involves the summation of all possible hidden sequences, an impracticable
 exponential-by-L operation.
 A dynamic approach to overcome this gap uses the Markovian memorylessness
 of HMM, and answers both the likelihood and the posterior questions we
 raised above.
 This approach is called Forward-Backward algorithm: it was suggested as
 a step in the Baum-Welch algorithm (
\begin_inset CommandInset citation
LatexCommand citet
key "key-4"

\end_inset

), which is an EM algorithm for finding the unknown θ given an observed
 sequence, and will be described further in a later section.
 In the Forward-Backward algorithm, two matrices of size 
\begin_inset Formula $m × L$
\end_inset

 are dynamically calculated, holding the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P_{\theta}\left(y_{t}=j,x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Forward Algorithm
\end_layout

\begin_layout Standard
The forward probabilities matrix 
\begin_inset Formula $\alpha$
\end_inset

 holds the probability that a sequence 
\begin_inset Formula $x_{1:t}$
\end_inset

 was emitted and that the hidden sequence ended with the state j:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P_{\theta}\left(y_{t}=j,x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
It is calculated by the dynamic algorithm:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Forward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[2,...,L]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,t}=\sum_{j'\in[m]}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The building of the table is based on the HMM basic assumptions that each
 hidden state 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent only on the previous one 
\begin_inset Formula $y_{t-1}$
\end_inset

 and that each observed variable 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent only on the hidden state that emitted it, 
\begin_inset Formula $y_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P_{\theta}\left(y_{t}=j,x_{1:t}\right)=P_{\theta}\left(x_{t}|y_{t}=j,x_{1:t-1}\right)\cdot P_{\theta}\left(y_{t}=j,x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P_{\theta}\left(x_{t}|y_{t}=j\right)\cdot\sum_{j'\in[m]}P_{\theta}\left(y_{t}=j|y_{t-1}=j'\right)\cdot P_{\theta}\left(y_{t-1}=j',x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=E_{j,x_{t}}\cdot\sum_{j'\in[m]}T_{j',j}\cdot\alpha_{j',t-1}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HMM forward Algorithm.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "ForwAlg"

\end_inset

Forward algorithm dynamically calculates the probability stored in 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 by using the previously calculated 
\begin_inset Formula $\alpha_{j',t-1}$
\end_inset

 values.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Backward Algorithm
\end_layout

\begin_layout Standard
The backwards probabilities matrix 
\begin_inset Formula $\beta$
\end_inset

 holds the probability that a sequence 
\begin_inset Formula $x_{t+1:L}$
\end_inset

 was emitted given the hidden state at position t had value j:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)
\]

\end_inset


\end_layout

\begin_layout Standard
It is calculated by the dynamic algorithm:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Backward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{1:m,L}=1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[L-1,...,1]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{j,t}=\sum_{j'\in[m]}\beta_{j',t+1}\cdot T_{j,j'}\cdot E_{j',x_{t}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This matrix building process is similarly explained by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)=\sum_{j'\in[m]}P_{\theta}\left(y_{t+1}=j',x_{t+1:L}|y_{t}=j\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\sum_{j'\in[m]}P_{\theta}\left(x_{t+2:L}|y_{t+1}=j'\right)\cdot P_{\theta}\left(x_{t+1}|y_{t+1}=j'\right)\cdot P_{\theta}\left(y_{t+1}=j'|y_{t}=j\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{j'\in[m]}\beta_{j',t+1}\cdot E_{j',x_{t+1}}\cdot T_{j,j'}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HMM backward Algorithm.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "BackAlg"

\end_inset

Backward algorithm dynamically calculates the probability stored in 
\begin_inset Formula $\beta_{j,t}$
\end_inset

 by using the previously calculated 
\begin_inset Formula $\beta_{j',t+1}$
\end_inset

 values
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Once we obtain 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 probabilities, the incomplete-data likelihood of HMM can finally be easily
 calculated:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P_{\theta}\left(x_{1:L}\right)=\sum_{j\in[m]}P_{\theta}\left(y_{L}=j,x_{1:L}\right)=\sum_{j\in[m]}\alpha_{j,L}\label{Incomplete-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
And so can the posterior probability be computed:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P_{\theta}\left(y_{t}=j|x_{1:L}\right)=\frac{P_{\theta}\left(y_{t}=j,x_{1:L}\right)}{P\left(x_{1:L}\right)}=\frac{P_{\theta}\left(y_{t}=j,x_{1:t}\right)\cdot P_{\theta}\left(x_{t+1:L}|y_{t}=j\right)}{P\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{P_{\theta}\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
Although HMM is simple and efficient, applying it on DNA sequences has a
 major disadvantage: the inherit Markovian lack-of-memory property.
 That is, the model's next state is always dependent only on the previous
 state, without further history consideration.
 For the task of emitting a TFBS motif, where each position has a different
 emission distribution depending on the location in the motif, a HMM would
 need to different hidden states per position in the motif.
 This means that for an HMM to be able to emit even a small number of short
 motifs, it needs to hold a large number of states that require learning
 a large number of parameters, e.g.
 for the ability to emit 50 motifs of length 5, an HMM needs to have over
 60,000 parameters.
 Furthermore, the enhancer modeling task at hand is even more complex, since
 we would like to model multiple enhancers and backgrounds states, each
 having different probability of emitting motifs and unique k-order emission
 distribution when not in those motifs.
 For our data structure prior assumption the required number of model's
 parameters would have been about 
\begin_inset Formula $10^{7}$
\end_inset

, large enough to introduce problems such as unfeasible memory complexity
 and overfitting.
\end_layout

\begin_layout Standard
A common way to avoid overfitting the data when training machine learning
 models is reducing the model's complexity by fixing some of its parameters.
 Our proposed HOP-HMM addresses both the memory issue and the overfitting
 issue while remaining equivalent to a regularized HMM with a large number
 of states with fixed parameters.
 Namely, most of the transition probabilities are fixed to zero and therefore
 never stored in memory, and some of the emission probabilities are predetermine
d and are fixed during the training.
 This allows us to learn a model with the enhancer prior assumptions of
 motifs and high-order emission without overfitting, and with reasonable
 memory complexity.
\end_layout

\begin_layout Subsubsection*
Generalized HMM
\end_layout

\begin_layout Standard
In a generalized HMM (GHMM), the transition or the emission are sampled
 from a different distribution type assigned to each of the states in the
 model.
 Some of the states in the system may emit zero or multiple observable variables
, sampled from custom emission models specifically tailored for the expected
 scenario.
 Such models were used for genes prediction in the 1990's (
\begin_inset CommandInset citation
LatexCommand citet
key "key-24"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citet
key "key-22"

\end_inset

), where specific exon states emitted codons instead of single nucleotides
 and feed forward neural networks were used for evaluating the probability
 of certain transitions.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/sHMM_two_states.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "GHMM"

\end_inset


\series bold
A)
\series default
 GHMM with a TF-state which emits using a PWM.
 The model has one background hidden state (yellow) and one TF hidden state.
 
\series bold
B,C,D)
\series default
 Although the TF-state emits motifs with 5 bp, the rest of the emissions,
 transitions and start probabilities remain the same as in a regular HMM.
 
\series bold
E)
\series default
 An example output generated from the model, showing the TFBS motif sampled
 in an arbitrary location inside a sequence.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another generalization made to the HMM called higher-order HMM uses conditional
 distribution by making the transition and emission dependent on previous
 hidden states (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-17"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-41"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-47"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-38"

\end_inset

).
 Although these HMM variants are capable of expressing a more complex structure
 of DNA sequence (different 
\emph on
k
\emph default
-mers frequencies in the genomic regions), the number of parameters required
 for DNA analysis tends to rise with the increase of the assumed complexity
 of the DNA structure.
 The increase of hidden states needed may introduce overfitting in the learning
 process, when the data size is limited.
\end_layout

\begin_layout Standard
Instead of higher-order emission which depends on the previous hidden states
 was previous used, high-order emission which depends on previous emitted
 observable variables is a less researched field.
 Such a HMM variant fits better to the locality nature for the task of emission
 
\emph on
k
\emph default
-mer structures, but it only requires 
\begin_inset Formula $O\left(m^{2}+4^{K}\right)$
\end_inset

 compared to 
\begin_inset Formula $O$
\end_inset

 
\begin_inset Formula $\left(m^{K}\right)$
\end_inset

 parameters that would have been required for holding a 
\emph on
k
\emph default
-mer distribution in a regular HMM, where m is the number of hidden states
 of the HOP-HMM, and K is the number of previous states in the dependency.
 
\end_layout

\begin_layout Subsubsection*
HOP-HMM
\end_layout

\begin_layout Standard
HOP-HMM is a GHMM that is well fitted to utilize the structure of enhancers
 containing TFBSs inside them, due to the TFBS emitting TF-states that take
 part in the generation process of the sequence.
 Due to the assumed local physical nature of the TF binding of the DNA sequence
 and success of HMM in gene prediction, we think the memorylessness of HMMs
 fit well to the task of enhancer prediction.
 HOP-HMM balances between the Markovian memorylessness and the observed
 
\emph on
k
\emph default
-mer of the TFBS present in regulatory regions in the DNA.
\end_layout

\begin_layout Standard
HOP-HMM extends the GHMM model of 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-64"

\end_inset

, where some of the hidden states emit TFBS sampled from PWMs to predict
 enhancers location in the genome.
 In HOP-HMM we added the high order conditional emission probability on
 non-TF-states.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP_HMM_two_states.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM1"

\end_inset


\series bold
A)
\series default
 Small HOP-HMM that has one background-state and one TF-state.
 
\series bold
B) 
\series default
The background-state emits a single observable variable, and is has 2-order
 emission, meaning it is conditioned on the previous observable variable.
 
\series bold
C,D)
\series default
 Unlike GHMM, in HOP-HMM TF-state can transition into itself and cannot
 be the starting hidden state and the background-state.
 
\series bold
E)
\series default
 The TF-state emits multiple observable variable that represent a TFBS sampled
 from a PWM.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Transition_repack.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "TGCompact"

\end_inset

Instead of holding a single sparse 8
\begin_inset Formula $\times$
\end_inset

8 transition matrix, an alternative compact form holds only the non-fixed
 transition probabilities, split into T and G matrices.
 The non-fixed transition probabilities held in the compact form are the
 ones in between background-states, and between background-states to their
 TF-states (outlined with blue).
 A concatenation of a row in T and G holds the probability of the next hidden-st
ate given the current background-state.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP_HMM_multi_states.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\series bold
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM2"

\end_inset

A)
\series default
 A more complex HOP-HMM with two background-state 
\begin_inset Formula $BG_{1}$
\end_inset

 and 
\begin_inset Formula $BG_{2}$
\end_inset

, where each has 3 TF-states.
 
\series bold
B)
\series default
 each of the background-states has its own 2-order emission distribution
 in a 4x4 matrix.
 
\series bold
C)
\series default
 The start hidden state distribution 
\begin_inset Formula $\pi$
\end_inset

 allows only background-states to start the hidden sequence.
 
\series bold
D)
\series default
 The transition probability is held by matrices T and G.
 
\series bold
E)
\series default
 The example generated sequence is built out of two types of sequences,
 each has its own TFBS frequency and background nucleotide bigram frequency,
 representing two alternating types of enhancers.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We use two indices to describe a hidden-state in HOP-HMM:
\end_layout

\begin_layout Itemize
Background-states are indexed as 
\begin_inset Formula $(j,0)$
\end_inset

 where 
\begin_inset Formula $j\in[m]$
\end_inset

 and 
\begin_inset Formula $m$
\end_inset

 is the number background-states.
\end_layout

\begin_layout Itemize
TF-states are indexed as 
\begin_inset Formula $(j,l)$
\end_inset

 where 
\begin_inset Formula $j\in[m]$
\end_inset

, 
\begin_inset Formula $l\in[k]$
\end_inset

.
 and 
\begin_inset Formula $k$
\end_inset

 is the number of TF-states each of the background-states has.
\end_layout

\begin_layout Standard
For example, in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM2"

\end_inset

 we see a HOP-HMM with 
\begin_inset Formula $m=2$
\end_inset

 and 
\begin_inset Formula $k=3$
\end_inset

 and a total of 8 hidden-states.
 The TF-state indexed 
\begin_inset Formula $(j,l)$
\end_inset

 belongs to the 
\begin_inset Formula $(j,0)$
\end_inset

 background-state (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM3"

\end_inset

), and the only allowed transfer into 
\begin_inset Formula $(j,l)$
\end_inset

 only from its background-state 
\begin_inset Formula $(j,0)$
\end_inset

.
 Note that we used a simpler 
\begin_inset Formula $BG_{j}$
\end_inset

 notation in figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM1"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM2"

\end_inset

 for readability.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP_HMM_general_mk.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\shape italic
\emph on
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM3"

\end_inset

General hidden states graph of HOP-HMM.
 Each row represents a sequence type, where each of the 
\begin_inset Formula $m$
\end_inset

 background-states (yellow) has 
\begin_inset Formula $k$
\end_inset


\shape default
\emph default
 TF-state
\shape italic
\emph on
s (green).
 Not all transitions are possible, moving between the rows is possible only
 by a background-state to background-state transition.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
While most background-states 
\begin_inset Formula $(j,0)$
\end_inset

 represent an enhancer type, we also would like to model true background
 regions in between the enhancer that carry no regulatory role and have
 no TFBSs.
 For that end we predefine one or more background-states as non-enhancers
 by restricting their transfer probability into their TF-states, as seen
 in the results section.
\end_layout

\begin_layout Standard
HOP-HMM is defined with k PWMs 
\begin_inset Formula $W_{1},W_{2},...,W_{k}$
\end_inset

 that remain fixed during training.
 Each of the k PWMs is shared with m TF-states, e.g.
 the PWM 
\begin_inset Formula $W_{l}$
\end_inset

, where 
\begin_inset Formula $l\in[k]$
\end_inset

, is shared between subs-states 
\begin_inset Formula $(1,l),(2,l),...,(m,l)$
\end_inset

 and is used for the TF-state emission sampling.
 The PWMs vary in their column amounts (as the different TFBSs vary in length),
 where each column represents a nucleotide distribution at that position.
 When the model enters a TF-state, it emits a motif by sampling from a PWM
 column by column independently, as described in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "GHMM"

\end_inset

.
\end_layout

\begin_layout Standard
The background-states, denoted as 
\begin_inset Formula $(1,0),(2,0),...,(m,0)$
\end_inset

, are responsible for the emission of inter-TFBS parts of the enhancers
 lacking long motifs.
 Similarly to regular states in HMM, background-states emit single nucleotides,
 where their emission is conditional on the previous of letters emitted
 in the DNA sequence.
 The emission from background-states is done by sampling a nucleotide from
 the distributions stored in E tensor.
 E dimension is o+1, and its size is 
\begin_inset Formula $\text{ }m\times4\times4\times...\times4$
\end_inset

 (with o fours) and its values are describe the emission probability 
\begin_inset Formula $E_{j,x_{t-o+1},x_{t-o+2},...,x_{t}}=P\left(x_{t}|y_{t}=(j,0),x_{t-o+1},...,x_{t-1}\right)$
\end_inset

, meaning that when 
\begin_inset Formula $x_{t}$
\end_inset

 is sampled by the model, the preceding 
\begin_inset Formula $o-1$
\end_inset

 observed variables are used as indices of the tensor for getting emission
 probability vector 
\begin_inset Formula $E_{j,x_{t-o+1},x_{t-o+2},...,x_{t-1},*}$
\end_inset

.
\end_layout

\begin_layout Standard
For the first variables emitted in the sequence, the missing dimensions
 of the preceding variables are summed to form the probability vector, e.g.
 if 
\begin_inset Formula $t=o-1$
\end_inset

, a single variable is missing for emitting 
\begin_inset Formula $x_{t}$
\end_inset

 and the distribution used for emission sampling is 
\begin_inset Formula $\sum_{i\in[4]}\frac{E_{j,i,x_{1},...,x_{t-1}}}{4}$
\end_inset

.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
In HOP-HMM, the first hidden state in a sequence can only be a background-state.
 The first background-state, as in HMM, is chosen by sampling from 
\begin_inset Formula $\pi,$
\end_inset

 a probability vector 
\begin_inset Formula $\pi_{j}=P(y_{1}=(j,0))$
\end_inset

.
 Once in a background-state, the model can only transit into a small subset
 of states, and since most of the possible transition are not allowed, a
 single transition matrix from all states to all states would be sparse.
 Instead, as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "TGCompact"

\end_inset

, we hold only the possible transition probabilities in two matrices, representi
ng the two types of allowed transitions:
\end_layout

\begin_layout Itemize
T for background-state to background-state transitions, a 
\begin_inset Formula $m\times m$
\end_inset

 matrix where 
\begin_inset Formula $T_{j_{1},j_{2}}=P\left(y_{t+1}=(j_{2},0)|y_{t}=(j_{1},0)\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
G for background-state to TF-state transitions a 
\begin_inset Formula $m\times k$
\end_inset

 matrix where 
\begin_inset Formula $G_{j,l}=P\left(y_{t+1:t+|W_{l}|}=(j,l)|y_{t}=(j,0)\right)$
\end_inset

.
\end_layout

\begin_layout Standard
When in a background-state, after the observable variable emission, the
 model samples its next hidden state from a probability vector that is a
 concatenation of a row in T and a row in G.
 If a TF-state is chosen, after the TF-state's motif emission, the model
 returns back to the background-state to emit another single observable
 variable and so on.
\end_layout

\begin_layout Section*
Methods
\end_layout

\begin_layout Standard
When fitting a HMM to a DNA sequence, we seek the parameters 
\begin_inset Formula $\theta^{*}$
\end_inset

 that best explain the sequence via a algorithm called Baum-Welch algorithm,
 which is a special case of EM algorithm.
 Formally, given the observed DNA sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

, we would like to find the parameters that maximize the incomplete-likelihood:
 
\begin_inset Formula 
\[
\theta^{*}=argmax_{\theta}\mathcal{L}\left(\theta|x_{1:L}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Even though the incomplete-data likelihood of HMM in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Likelihoods"

\end_inset

 is derivable by 
\begin_inset Formula $\theta$
\end_inset

, optimizing it is as difficult as calculating it and therefore is also
 impractical.
 Instead, the strategy of the EM algorithm is to optimize the expected value
 of the complete-data log-likelihood 
\begin_inset Formula $log\left(P\left(x_{1:L},y_{1:L}|\theta^{'}\right)\right)$
\end_inset

 over all possible 
\begin_inset Formula $y_{1:L}$
\end_inset

 where 
\begin_inset Formula $\theta^{'}$
\end_inset

 is the model's parameters from previous EM iteration (or guessed parameters
 in the first iteration) and while assuming a fixed observed 
\begin_inset Formula $x_{1:L}$
\end_inset

, as it is the given DNA sequence.
 For this task we define our target function Q:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Q\left(\theta,\theta^{'}\right)=E_{Y}\left[log\left(P_{\theta}\left(x_{1:L},y_{1:L}\right)\right)|x_{1:L},\theta^{'}\right]=\sum_{y_{1:L}\in\left[m\right]^{L}}log\left(P_{\theta}\left(x_{1:L},y_{1:L}\right)\right)\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)\label{Q}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Here E is expressing an expected value, not to be confused with the HMM
 emission probability.
 Every EM iteration is built out of two parts called the E (expectation)
 step and the M (maximization) step.
 In the E-step we calculate the probabilities needed for the maximization
 of Q and in the M-step we infer the 
\begin_inset Formula $\theta$
\end_inset

 that maximizes it.
 We will update the 
\begin_inset Formula $\theta$
\end_inset

 for maximizing 
\begin_inset Formula $Q\left(\theta,\theta^{'}\right)$
\end_inset

 in every M-step of the EM algorithm until convergence.
 
\end_layout

\begin_layout Standard
Using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Complete-Likelihood"

\end_inset

 we will split the Q function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Q"

\end_inset

 into three independent parts:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{y_{1:L}\in\left[m\right]^{L}}log\pi_{y_{1}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)\\
+ & \sum_{y_{1:L}\in\left[m\right]^{L}}\left(\sum_{t\in2...L}logT_{y_{t-1},y_{t}}\right)\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)\\
+ & \sum_{y_{1:L}\in\left[m\right]^{L}}\left(\sum_{t\in[L]}logE_{y_{t},x_{t}}\right)\cdot P_{\theta^{'}}\left(x_{1:L},y_{1:L}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
then by manipulating the summation, the exponential state sequence summation
 could be simplified to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{j\in[m]}log\pi_{j}\cdot P_{\theta^{'}}\left(x_{1:L},y_{1}=j\right)\\
+ & \sum_{t\in2...L}\sum_{j_{1},j_{2}\in[m]}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)\\
+ & \sum_{t\in[L]}\sum_{j\in[m]}logE_{j,x_{t}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Each of the three parts above is a set of constraint linear functions that
 could be derived and maximized independently using a Lagrange multipliers,
 under the following probability constrains:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j\in[m]}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j_{2}\in[m]}T_{j_{1},j_{2}}=1$
\end_inset

 for all 
\begin_inset Formula $j_{1}\in[m]$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{b\in[n]}E_{j,b}=1$
\end_inset

 for all 
\begin_inset Formula $j\in[n]$
\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $m$
\end_inset

 is the number of different hidden states and 
\begin_inset Formula $n$
\end_inset

 is the number of different observed variables (4 in our case of DNA).
\end_layout

\begin_layout Standard
First, we start with maximizing the first 
\begin_inset Formula $\pi$
\end_inset

 part using Lagrange multiplier 
\begin_inset Formula $\lambda$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\pi_{j}}\left(\sum_{j'\in[m]}log\pi_{j'}P_{\theta^{'}}\left(x_{1:L},y_{1}=j'\right)+\lambda\left(1-\sum_{j'\in[m]}\pi_{j'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
we derive the term and get 
\begin_inset Formula $\frac{P_{\theta^{'}}\left(x_{1:L},y_{1}=j\right)}{\pi_{j}}=\lambda$
\end_inset

 for 
\begin_inset Formula $j\in[m]$
\end_inset

.
 Then we use these m equations to get 
\begin_inset Formula $\lambda=P_{\theta^{'}}\left(x_{1:L}\right)$
\end_inset

, which yields the reestimated 
\begin_inset Formula $\pi_{j}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\pi_{j}=\frac{P_{\theta^{'}}\left(x_{1:L},y_{1}=j\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=P_{\theta^{'}}\left(y_{1}=j|x_{1:L}\right)\label{Pi-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Second, we define a Lagrange multipliers 
\begin_inset Formula $\lambda_{j_{1}}$
\end_inset

 for each 
\begin_inset Formula $j_{1}\in[m]$
\end_inset

 for the 
\begin_inset Formula $T$
\end_inset

 part:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial T_{j_{1},j_{2}}}\left(\sum_{t\in2...L}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
which yields 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)}{T_{j_{1},j_{2}}}$
\end_inset

 for 
\begin_inset Formula $j_{2}\in[m]$
\end_inset

 
\end_layout

\begin_layout Standard
when the m equations are summed, gives 
\begin_inset Formula $\lambda_{j_{1}}=\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1}\right)$
\end_inset

 
\end_layout

\begin_layout Standard
therefore the update of 
\begin_inset Formula $T_{j_{1},j_{2}}$
\end_inset

 will be:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T_{j_{1},j_{2}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=j_{1}\right)}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=j_{1},y_{t}=j_{2}|x_{1:L}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=j_{1}|x_{1:L}\right)}\label{T-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Finally, we'll define multiplier 
\begin_inset Formula $\lambda_{j}$
\end_inset

 for every 
\begin_inset Formula $j\in[m]$
\end_inset

 for the 
\begin_inset Formula $E$
\end_inset

 part:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial E_{j,b}}\left(\sum_{t\in[L]}logE_{j,x_{t}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)+\lambda_{j}\left(1-\sum_{b'\in[n]}E_{j,b'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
this step is slightly trickier due to the derivation of 
\begin_inset Formula $\frac{\partial E_{j,x_{t}}}{\partial E_{j,b}}=\boldsymbol{1}_{b}(x_{t})$
\end_inset

 where 
\begin_inset Formula $\boldsymbol{1}_{b}(x_{t})=\begin{cases}
1 & b=x_{t}\\
0 & otherwise
\end{cases}$
\end_inset

.
\end_layout

\begin_layout Standard
we get 
\begin_inset Formula $\lambda_{j}=\frac{\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)\cdot\boldsymbol{1}_{b}(x_{t})}{E_{j,b}}$
\end_inset

 for 
\begin_inset Formula $b\in[n]$
\end_inset

 
\end_layout

\begin_layout Standard
when all n equations are summed, gives 
\begin_inset Formula $\lambda_{j}=\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)\cdot\boldsymbol{1}_{b}(x_{t})$
\end_inset

 
\end_layout

\begin_layout Standard
therefore the update of 
\begin_inset Formula $E_{j,b}$
\end_inset

 will be:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E_{j,b}=\frac{\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)\boldsymbol{\cdot1}_{b}(x_{t})}{\sum_{t\in[L]}P_{\theta^{'}}\left(x_{1:L},y_{t}=j\right)}=\frac{\sum_{t\in[L]}P_{\theta^{'}}\left(y_{t}=j|x_{1:L}\right)\boldsymbol{1}_{b}(x_{t})}{\sum_{t\in[L]}P_{\theta^{'}}\left(y_{t}=j|x_{1:L}\right)}\label{E-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For us to be able to calculate these reestimation of 
\begin_inset Formula $\theta$
\end_inset

 as written in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "E-Update"

\end_inset

, we are still left with the calculation of the two probabilities terms
 inside them.
 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
To resemble the notations coined in 
\begin_inset CommandInset citation
LatexCommand citet
key "key-50"

\end_inset

, the first widely accepted HMM application, we'll denote these as 
\begin_inset Formula $\gamma$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\gamma_{t,j}=P_{\theta^{'}}\left(y_{t}=j|x_{1:L}\right)\label{gamma}
\end{equation}

\end_inset

 
\begin_inset Formula 
\begin{equation}
\xi_{t,j_{1},j_{2}}=P_{\theta^{'}}\left(y_{t-1}=j_{1},y_{t}=j_{2}|x_{1:L}\right)\label{xi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We will use 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Incomplete-Likelihood"

\end_inset

 and the output of the Forward-Backward algorithm 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 for their calculation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\gamma_{t,j}=\frac{P_{\theta^{'}}\left(y_{t}=j,x_{1:L}\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=\frac{P_{\theta^{'}}\left(x_{1:L}|y_{t}=j\right)\cdot P_{\theta^{'}}\left(y_{t}=j\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=\frac{P_{\theta^{'}}\left(y_{t}=j,x_{1:t}\right)\cdot P_{\theta^{'}}\left(x_{t+1:L}|y_{t}=j\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{\sum_{j\in[m]}\alpha_{j,L}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\xi_{t,j_{1},j_{2}}=\frac{P\left(y_{t-1}=j_{1},y_{t]}=j_{2},x_{1:L}\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P_{\theta^{'}}\left(y_{t-1}=j_{1},x_{1:t-1}\right)\cdot P_{\theta^{'}}\left(y_{t}=j_{2}|y_{t-1}=j_{1}\right)\cdot P_{\theta^{'}}\left(x_{t}|y_{t}=j_{2}\right)\cdot P_{\theta^{'}}\left(x_{t+1:L}|y_{t}=j_{2}\right)}{P_{\theta^{'}}\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2},}\cdot E_{j_{2},x_{t}}\cdot\beta_{j',t}}{\sum_{j\in[m]}\alpha_{j,L}}
\]

\end_inset

The calculation of 
\begin_inset Formula $\alpha,\beta,\gamma$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset

 matrices is considered the E-step of Baum-Welch algorithm, and they allow
 us to update 
\begin_inset Formula $\theta$
\end_inset

 and finish the EM iteration.
\end_layout

\begin_layout Subsubsection*
Baum-Welch Algorithm for HOP-HMM
\end_layout

\begin_layout Standard
The transitions and emissions mechanisms of HOP-HMM are different, and therefore
 the complete-data likelihood of HOP-HMM requires different calculation
 for the Baum-Welch algorithm to hold.
 The Baum-Welch algorithm can be adjusted to infer the parameters of the
 HOP-HMM variant 
\begin_inset Formula $\theta=\{\pi,E,G,T\}$
\end_inset

 from a DNA sequence X.
 As in the regular Baum-Welch algorithm covered in the previous section,
 given a sequence X at each EM iteration we optimize the Q function in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Q"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{j\in[m]}log\pi_{j}\cdot P_{\theta^{'}}\left(x_{1:L},y_{1}=(j,0)\right)\\
+ & \sum_{t\in2...L}\sum_{j_{1},j_{2}\in[m]}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)\\
+ & \sum_{t\in2...L}\sum_{j\in[m],l\in[k]}logG_{j,l}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j,0),y_{t}=(j,l)\right)\\
+ & \sum_{t\in o,...,L}\sum_{j\in[m]}logE_{j,b_{1},...,x_{t}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t}=(j,0)\right)\\
+ & \sum_{t\in[L]}\sum_{l\in[k]}logL_{W}(x_{t:t+|W_{l}|-1})\cdot P_{\theta^{'}}\left(x_{1:L},y_{t:t+|W_{l}|-1S}=(j,l)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $L_{W}(\overline{x})$
\end_inset

 is the likelihood of the TFBS 
\begin_inset Formula $\overline{x}$
\end_inset

 to be emitted by PWM 
\begin_inset Formula $W$
\end_inset

: 
\begin_inset Formula $L_{M}(\overline{x})=P(\overline{x}|W)=\underset{i\in\{1,...,|\overline{x}|\}}{\prod}W_{\overline{x}_{i},i}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Note that the last addition component, which holds the TFBS log likelihood,
 does not contain elements from 
\begin_inset Formula $\theta$
\end_inset

 as the PWMs are not learned in HOP-HMM, and therefore it is not reestimated
 in the M-steps.
\end_layout

\begin_layout Standard
The 
\begin_inset Formula $\theta^{*}$
\end_inset

 which optimizes 
\begin_inset Formula $Q$
\end_inset

 here, 
\begin_inset Formula $\theta^{*}=argmax_{\theta}Q(\theta,\theta')$
\end_inset

, is archived by optimizing its 3 independent parts as well, each having
 its own constrain under which we optimize 
\begin_inset Formula $Q$
\end_inset

 are:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j\in[m]}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{j_{2}\in[m]}T_{j_{1},j_{2}}+\sum_{l\in[k]}G_{j_{1}l}=1$
\end_inset

 for all 
\begin_inset Formula $j_{1}\in[m]$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sum_{b_{o}\in[n]}E_{j,b_{1},...,b_{o}}=1$
\end_inset

 for all 
\begin_inset Formula $j\in[n]$
\end_inset


\end_layout

\begin_layout Subsubsection*
M-step
\end_layout

\begin_layout Standard
The 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $E$
\end_inset

 conditions produce almost exact same maximization as in regular Baum-Welch
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Pi-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "E-Update"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\pi_{j}=\frac{P_{\theta^{'}}\left(x_{1:L},y_{1}=(j,0)|\theta^{'}\right)}{P_{\theta^{'}}\left(x_{1:L}|\theta^{'}\right)}=P_{\theta^{'}}\left(y_{1}=(j,0)|x_{1:L}\right)\label{HOP-Pi-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E_{j,b_{1},...,b_{o}}=\frac{\sum_{t\in o,...,L}P_{\theta^{'}}\left(x_{1:L},y_{t}=(j,0)\right)\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1,...,t})}{\sum_{t\in o,...,L}P_{\theta^{'}}\left(x_{1:L},y_{t}=(j,0)\right)}\label{HOP-E-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
As for the second condition of 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

, we will define the Lagrange multipliers 
\begin_inset Formula $\lambda_{j_{1}}$
\end_inset

 for 
\begin_inset Formula $j_{1}\in[m]$
\end_inset

 and derive the two terms that contain 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial T_{j_{1,}j_{2}}}\left(\sum_{t\in2...L}logT_{j_{1},j_{2}}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}-\sum_{l\in[k]}G_{j_{1}l}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial G_{j_{1},l}}\left(\sum_{t\in2...L}logG_{j_{1},l}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l)\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}-\sum_{l\in[k]}G_{j_{1}l}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
which yields 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)}{T_{j_{1},j_{2}}}$
\end_inset

 and 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}\cdot P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l)\right)}{G_{j_{1}l}}$
\end_inset

 for 
\begin_inset Formula $j_{2}\in[m]$
\end_inset

 and 
\begin_inset Formula $l\in[k]$
\end_inset

.
 
\end_layout

\begin_layout Standard
When the 
\begin_inset Formula $m+k$
\end_inset

 equations are summed we receive:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lambda_{j_{1}}=\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)+\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
which gives us the updates 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T_{j_{1},j_{2}}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j_{1},0)\right)}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j_{1},0)|x_{1:L}\right)}\label{HOP-T-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
G_{j,l}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j,0),y_{t}=(j,l)\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(x_{1:L},y_{t-1}=(j,0)\right)}=\frac{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)}{\sum_{t\in2...L}P_{\theta^{'}}\left(y_{t-1}=(j,0)|x_{1:L}\right)}\label{HOP-G-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection*
E-step
\end_layout

\begin_layout Standard
Preceding the M-step where we update components of 
\begin_inset Formula $\theta$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-E-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-G-Update"

\end_inset

, we will calculate the three probability terms inside them in the E-step,
 denoted as 
\begin_inset Formula $\gamma,$
\end_inset

 
\begin_inset Formula $\xi$
\end_inset

 and 
\begin_inset Formula $\eta$
\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

 
\begin_inset Formula 
\begin{equation}
\gamma_{j,t}=P_{\theta^{'}}\left(y_{t}=(j,0)|x_{1:L}\right)\label{HOP-gamma}
\end{equation}

\end_inset

 
\begin_inset Formula 
\begin{equation}
\xi_{j_{1},j_{2},t}=P_{\theta^{'}}\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)\label{HOP-xi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\eta_{j,l,t}=P_{\theta^{'}}\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)\label{HOP-eta}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For the calculation of these probabilities, we first need to calculate the
 forward and backward probabilities output from an HOP-HMM adjusted Forward-Back
ward algorithm.
 In this HOP-Forward-Backward algorithm, we will only build the probabilities
 for being in background-states since the TF-states probabilities are not
 needed in the later parts of the E-step.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The adjustments for the forward and backward algorithm are straight forward,
 as the summation is composed of two parts.
 We calculate 
\begin_inset Formula $\alpha$
\end_inset

 of size 
\begin_inset Formula $m\times L$
\end_inset

, iterating over 
\begin_inset Formula $t=1,2,...,L$
\end_inset

 as following:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP Forward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[2,...,L]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,t}=\underset{\text{background-state transitions}}{\underbrace{\sum_{j'\in[m]}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $+\underset{\text{TF-state transitions}}{\underbrace{\sum_{l\in[k]}\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the beginning of the sequence, when 
\begin_inset Formula $1\leq t<o$
\end_inset

, part of the preceding observable variables are missing.
 Since E has 
\begin_inset Formula $o+1$
\end_inset

 dimensions, 
\begin_inset Formula $E_{j,x_{1},...,x_{t}}$
\end_inset

 is not defined, so we define it here as: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{j,x_{1},...,x_{t}}=\underset{b_{1},...,b_{o-t}\in\{A,C,G,T\}}{\sum}\frac{1}{4^{o-t}}\cdot E_{j,b_{1},..,.b_{o-t},x_{1},...,x_{t}}
\]

\end_inset

 
\end_layout

\begin_layout Standard
We used the fact that 
\begin_inset Formula $P(A)=\sum_{b\in B}P(b)\cdot P(A|b)$
\end_inset

 and the assumption that the observable variables preceding the sequence
 came from a uniform distribution.
 Also, when summing the TF-state transition part, PWMs 
\begin_inset Formula $W_{l}$
\end_inset

 with length equal or bigger than 
\begin_inset Formula $t+1$
\end_inset

 include out-of-sequence TFBS and are not part of the summation.
\end_layout

\begin_layout Standard
For 
\begin_inset Formula $\beta$
\end_inset

 of size 
\begin_inset Formula $m\times L$
\end_inset

, we iterating over 
\begin_inset Formula $t=L,L-1,...,1$
\end_inset

 as following:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP Backward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{1:m,L}=1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[L-1,...,1]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{j,t}=\underset{\text{background-state transitions}}{\underbrace{\sum_{j'\in[m]}\beta_{j',t+1}\cdot E_{j',x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $+\underset{\text{TF-state transitions}}{\underbrace{\sum_{l\in[k]}\beta_{j,t+|W_{l}|+1}\cdot L_{W_{l}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t-o+|W_{l}|+2},...,x_{t+|W_{l}|+1}}\cdot G_{j,l}}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that when 
\begin_inset Formula $t>L-|W_{l}|$
\end_inset

, there are missing observable variables to fully calculate the TF-state
 transition.
 In these situations this contribution of these component to the summation
 is zero, meaning our HOP-HMM as the behavior of avoiding a transition into
 a TF-state when the PWM is too long to fit into the sequence X length.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/HOP-EM forward Algorithm.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
In HOP-HMM, the Forward-Backward algorithm dynamic tables 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 cells are filled from both the adjacent background-states transitions and
 the background-states preceding or proceeding the motifs emitted by the
 TF-states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We will now explain why the described dynamic calculation result with 
\begin_inset Formula $\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)$
\end_inset

 and 
\begin_inset Formula $\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0)\right)$
\end_inset

, starting with the forward probabilities 
\begin_inset Formula $\alpha$
\end_inset

.
 From the law of total probability, the probability 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 is the sum of probabilities of all the possible transition that ended in
 the background-state (j,0):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\underset{\text{background-state transitions}}{\underbrace{\underset{j'\in[m]}{\sum}P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)}}+\underset{\text{TF-state transitions}}{\underbrace{\underset{l\in[k]}{\sum}P\left(y_{t-|W_{l}|-1}=(j,0),y_{t-|W_{l}|:t-1}=(j,l),x_{1:t}\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard
right-side term of a TF-state transition can be split with the chain rule
 to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\,P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1},y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent only on 
\begin_inset Formula $y_{t}$
\end_inset

 and 
\begin_inset Formula $x_{t-o:t-1}$
\end_inset

 and since 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent on only 
\begin_inset Formula $y_{t-1}$
\end_inset

, we can simplify the probabilities:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{t-o:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Standard
This process is similar to the background-state transition.
 Using the chain rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(x_{t}|y_{t}=(j,0),y_{t-1}=(j',0),x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Standard
For the backward probabilities 
\begin_inset Formula $\beta,$
\end_inset

 the explanation is similar.
 The main difference between the regular HMM backward probability is the
 condition on the 
\begin_inset Formula $o-1$
\end_inset

 preceding observable variables 
\begin_inset Formula $x_{t-o+2:t}$
\end_inset

, which are necessary for the background-state emission is conditional on
 them.
\end_layout

\begin_layout Standard
Using the law of total probability:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{t+1:L}|y_{t}=(j,0),x_{t-o+2:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\underset{\text{background-state transition}}{\underbrace{\sum_{j'\in[m]}P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0),x_{t-o+2:t}\right)}}+\underset{\text{TF-state transition}}{\underbrace{\sum_{l\in[k]}P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard
For the background-state transition term, we can use the chain rule and
 the Markovian independence of the transitions and emissions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0),x_{t-o+2:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{t+2:L}|y_{t+1}=(j',0),y_{t}=(j,0),x_{t-o+2:t+1}\right)\cdot P\left(x_{t+1}|y_{t+1}=(j',0),y_{t}=(j,0),x_{t-o+2:t}\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0),x_{t-o+2:t}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{t+2:L}|y_{t+1}=(j',0),x_{t-o+3:t+1}\right)\cdot P\left(x_{t+1}|y_{t+1}=(j',0),x_{t-o+2:t}\right)\cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\beta_{j',t+1}\cdot E_{j',x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}
\]

\end_inset


\end_layout

\begin_layout Standard
For the TF-state transition term, we use once more the chain rule, followed
 the simplification using the conditional independencies of HMM:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{t+\left|W_{l}\right|+2:L}|x_{t+1:t+\left|W_{l}\right|+1},y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|x_{t+1:t+\left|W_{l}\right|},y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{t+\left|W_{l}\right|+2:L}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\beta_{j,t+|W_{l}|+1}\cdot E_{j,x_{t-o+|W_{l}|+1},...,x_{t+|W_{l}|+1}}\cdot L_{W_{l}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot G_{j,l}
\]

\end_inset


\end_layout

\begin_layout Standard
Using the forward and the backward probability matrices 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

, we can calculate the auxiliary probabilities 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

.
 The first probability that will help us for that is 
\begin_inset Formula $\psi$
\end_inset

, a matrix of size 
\begin_inset Formula $m\times k\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\psi_{j,l,t}=P\left(y_{t}=(j,0),y_{t+1}=(j,l),x_{1:L}\right)=P\left(y_{t}=(j,0),y_{t+1}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:L}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(y_{t}=(j,0),y_{t+1}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)\cdot P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=P\left(x_{1:t},y_{t}=(j,0)\right)\cdot P\left(y_{t+1}=(j,l)|y_{t}=(j,0)\right)\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\cdot
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\text{\cdot}P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{t+|W_{l}|-o+3:t+|W_{l}|+1}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\alpha_{j,t}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t+|W_{l}|-o+2},...,x_{t+|W_{l}|+1}}\cdot\beta_{j,t+|W_{l}|+1}
\]

\end_inset


\end_layout

\begin_layout Standard
The second probability is likelihood of the observed sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P\left(x_{1:L}\right)=\underset{j\in[m]}{\sum}\left(\alpha_{j,t}\cdot\beta_{j,t}+\underset{l\in\left[k\right],\ t'\in\left[|W_{l}|\right]}{\sum}\psi_{j,l,t-s}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Now we can calculate probability 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 of the background-state at a given position given the sequence X, denoted
 as 
\begin_inset Formula $\gamma$
\end_inset

 of size 
\begin_inset Formula $m\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\gamma_{j,t}=P\left(y_{t}=(j,0)|x_{1:L}\right)=\frac{P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{1:t},y_{t}=(j,0)\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{t-o+1:t},y_{t}=(j,0)\right)}{P\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
The probability 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 is the background-state to background-state transition given the sequence
 X, denoted as 
\begin_inset Formula $\xi$
\end_inset

 of size 
\begin_inset Formula $m\times m\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\xi_{j_{1},j_{2},t}=P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)=\frac{P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0),x_{1:L}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P\left(x_{1:t-1},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)\cdot P\left(x_{t:L}|y_{t}=(j_{2},0),x_{1:t-1}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{P\left(x_{1:t-1},y_{t-1}=(j_{1},0)\right)\cdot P\left(y_{t}=(j_{2},0)|y_{t-1}=(j_{1},0)\right)\cdot P\left(x_{t}|y_{t}=(j_{2},0),x_{1:t-1}\right)\cdot P\left(x_{t+1:L}|y_{t}=(j_{2},0),x_{1:t-1}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+1},...,x_{t}}\cdot\beta_{j_{2},t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
Finally, the probability 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 is the background-state to background-state transition given the sequence
 X, denoted as 
\begin_inset Formula $\psi$
\end_inset

 of size 
\begin_inset Formula $m\times k\times L$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\eta_{j,l,t}=P\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)=\frac{\psi_{j,l,t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
Now with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 at hand, we can complete the M-step and update 
\begin_inset Formula $\theta$
\end_inset

 by assigning the updates of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-E-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-G-Update"

\end_inset

.
\end_layout

\begin_layout Standard
The Baum-Welch algorithm adaptation for HOP-HMM, as described in this section:
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP Baum-Welch
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for s=[1...MAX_EM_ITERATIONS]:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# E-step
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha=\text{hop\_forward\_algorithm(x_{1:L}) }$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta=\text{hop\_backward\_algorithm(x_{1:L}) }$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $l=[1,...,k]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\psi_{j,l,t}=\begin{cases}
\alpha_{j,t}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1:t+|W_{l}|}\right)\cdot E_{j,x_{t+|W_{l}|-o+2},...,x_{t+|W_{l}|+1}}\cdot\beta_{j,t+|W_{l}|+1} & |\,t+|W_{l}|+1\leq L\\
0 & |\,otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $Px=\underset{j\in[m]}{\sum}\alpha_{j,L}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\gamma_{j,t}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $l=[1,...,k]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\eta_{j,l,t}=\frac{\psi_{j,l,t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j_{1}=[1,...,m]$
\end_inset

, 
\begin_inset Formula $j_{2}=[1,...,m]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\xi_{j_{1},j_{2},t}=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+1},...,x_{t}}\cdot\beta_{j_{2},t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# M-step
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\pi_{j}=\gamma_{j,1}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $b_{1},...,b_{o}=[1,...,1]$
\end_inset

 
\begin_inset Formula $,...,[4,...,4]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $E_{j,b_{1},b_{2},...,b_{o}}=\frac{\sum_{t\in o,...,L}\gamma_{j,t}\cdot\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1},...,x_{t})}{\sum_{t\in o,...,L}\gamma_{j,t}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for  
\begin_inset Formula $l=[1,...,k]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $G_{j,l}=\frac{\underset{t\in2,...,L}{\sum}\eta_{j,l,t}}{\underset{t\in1,...,L-1}{\sum}\gamma_{j_{1},t}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j_{2}=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $T_{j,j_{2}}=\frac{\underset{t\in2,...,L}{\sum}\xi_{j,j_{2},t}}{\underset{t\in1,...,L-1}{\sum}\gamma_{j,t}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

If 
\begin_inset Formula $\theta$
\end_inset

 converged, break EM for loop 
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The algorithm is described with the input of a single sequence of observable
 variables 
\begin_inset Formula $x_{1:L}$
\end_inset

.
 In reality, we are faced with the task of learning 
\begin_inset Formula $\theta$
\end_inset

 from multiple sequences at once.
 In HOP-HMM we can use the multi-sequence method as in 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-50"

\end_inset

, where the E-step probabilities are calculated separately for each sequence,
 and in the M-step all positions from all sequences are summed for the parameter
s update.
\end_layout

\begin_layout Subsubsection*
Sequence States Inference
\end_layout

\begin_layout Standard
Acquiring the maximal likelihood 
\begin_inset Formula $\theta$
\end_inset

 opens the door to several wanted inferences given a sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

 :
\end_layout

\begin_layout Enumerate
Most likely hidden-state at any position in a sequence
\end_layout

\begin_layout Enumerate
Most likely hidden-state sequence
\end_layout

\begin_layout Enumerate
Dominant hidden-state in a short sequence
\end_layout

\begin_layout Standard
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 and 
\begin_inset Formula $\eta$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 can be used to solve the inference 1 for HOP-HMM.
 We aim to maximize here a posterior probability in a specific position:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{t}^{*}=\underset{j\in[m],l\in[k]\cup\{0\}}{argmax}P\left(y_{t}=(j,l)|x_{1:L}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
In regular HMM, we can approximate this by taking the max of the posterior
 probability held in 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "gamma"

\end_inset

 built by a 
\begin_inset Formula $\theta$
\end_inset

 that we learned with the Baum-Welch algorithm.
 In HOP-HMM 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 is not sufficient since it holds only the probability of background-state
 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,0)|x_{1:L}\right)$
\end_inset

.
 To calculate the posterior probability for TF-states, 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,l)|x_{1:L}\right)$
\end_inset

 where 
\begin_inset Formula $l>0$
\end_inset

 we sum all options of a TF-state 
\begin_inset Formula $(j,l)$
\end_inset

 that cover position 
\begin_inset Formula $t$
\end_inset

 as described in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PWM Posterior"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P_{\theta}\left(y_{t}=(j,l)|x_{1:L}\right)=\sum_{i\in\left[|W_{l}|\right]}P_{\theta}\left(y_{t-i+1:t-i+|W_{l}|}=(j,l)|x_{1:L}\right)=
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{i\in\left[|W_{l}|\right]}P_{\theta}\left(y_{t-i}=(j,0),y_{t-i+1}=(j,l)|x_{1:L}\right)=\sum_{i\in\left[|W_{l}|\right]}\eta_{t-i+1,j,l}
\]

\end_inset


\end_layout

\begin_layout Standard
Choosing the maximum value over 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,l)|x_{1:L}\right)$
\end_inset

 and 
\begin_inset Formula $P_{\theta}\left(y_{t}=(j,0)|x_{1:L}\right)$
\end_inset

 will give us the most likely state of 
\begin_inset Formula $\hat{y}_{t}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{y}_{t}=\underset{j\in[m],l\in[k]\cup\{0\}}{argmax}\gamma_{j,t}\cup\sum_{i\in\left[|W_{l}|\right]}\eta_{t-i+1,j,l}\label{PosteriorEstimation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/PWM_posterior_2.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "PWM Posterior"

\end_inset


\begin_inset Formula $P\left(y_{t}=(j,t)|x_{1:L}\right)$
\end_inset

 is the posterior probability to be in TF-state 
\begin_inset Formula $(j,l)$
\end_inset

 at position 
\begin_inset Formula $t$
\end_inset

, marked in dark green.
 It is equal to the sum of probabilities of entering into the TF-state before
 position 
\begin_inset Formula $y_{t}$
\end_inset

.
 In this example, 
\begin_inset Formula $W_{l}$
\end_inset

 is a PWM of length 5, therefore it has 5 different possible positions that
 include 
\begin_inset Formula $y_{t}$
\end_inset

 that are summed, marked in light green.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Inference 2 aims for reaching the most likely hidden sequence:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y_{1:L}^{*}=argmax_{y_{1:L}}P\left(y_{1:L}|x_{1:L}\right)\label{Viterbi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The main difference between inference 1 is the consideration to the dependency
 between adjacent states.
 In inference 1, for example, two adjacent positions may been individually
 inferred states which the transition probability between them equals 0.
 Even though each hidden state maximizes the likelihood at its position,
 as a sequence when accounting for the transitions the result might not
 be the same states.
\end_layout

\begin_layout Subsubsection*
HOP-Viterbi Algorithm
\end_layout

\begin_layout Standard
In HMM, deriving the maximal likelihood hidden sequence of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Viterbi"

\end_inset

 is done by the Viterbi algorithm, named after Andrew Viterbi who proposed
 it in 
\begin_inset CommandInset citation
LatexCommand citet
key "key-65"

\end_inset

.
 Viterbi algorithm resembles the Forward algorithm, with the two main difference
s:
\end_layout

\begin_layout Enumerate
Maximization replaces the summation over the possible transitions.
\end_layout

\begin_layout Enumerate
Traces of the maximal value chosen in the dynamic filling are kept in 
\begin_inset Formula $V^{2}$
\end_inset

, which used to back-trace the chosen state path at the end.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Viterbi Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\theta$
\end_inset

- HMM parameters 
\begin_inset Formula $\{\pi,T,E\}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{2}=0$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,t=[2,...,L]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{1}=max_{j'\in[m]}\left(V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{2}=argmax_{j'\in[m]}\left(V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# back tracing
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{L}=argmax_{j}V_{j,L}^{1}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
for 
\begin_inset Formula $t=[L,...,2]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\hat{y}_{t-1}=V_{y_{t},t}^{2}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\hat{y}_{1:L}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For HOP-HMM the Viterbi algorithm is adapted into a HOP-Viterbi algorithm,
 in two manners:
\end_layout

\begin_layout Itemize
Maximization is done over two types of state transition probabilities: backgroun
d to background and background to TF, held in A and B vectors.
\end_layout

\begin_layout Itemize
The traces held in 
\begin_inset Formula $V^{2}$
\end_inset

 tables are two indices, since states in HOP-HMM are described by two indices.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
HOP-Viterbi Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Input:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\theta$
\end_inset

- HOP-HMM parameters 
\begin_inset Formula $\{\pi,T,G,E\}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
Algorithm:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{2}=0$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,t=[2,...,L]$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $A=\left\{ V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}|j'\in[m]\right\} $
\end_inset


\emph on
 # background-state to background-state
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $B=\left\{ V_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot L_{W_{l}}\left(x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}|l\in[k]\right\} $
\end_inset

 
\emph on
# background-state to TF-state
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{1}=max\left(A\cup B\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{2}=\begin{cases}
\left(argmax(A),0\right) & \ensuremath{max(A)>max(B)}\\
\left(j,argmax(B)\right) & otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{L}=\left(argmax_{j}V_{j,L}^{1},0\right)$
\end_inset

 
\emph on
# mandatory background-state at the end of the sequence
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t=L$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
while 
\begin_inset Formula $t>1$
\end_inset

:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\left(j,l\right)=V_{y_{t}[0],t}^{2}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

if 
\begin_inset Formula $l=0:$
\end_inset


\emph on
 # if 
\begin_inset Formula $l=0$
\end_inset

 the hidden state at 
\begin_inset Formula $t-1$
\end_inset

 is a background-state
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{t-1}=\left(j,0\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $t=t-1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

else:
\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $y_{t-|W_{l}|:t-1}=\left(j,l\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $y_{t-|W_{l}|-1}=y_{t}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $t=t-|W_{l}|-1$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\hat{y}_{1:L}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Using the Viterbi state path, we can make a simplistic classifications of
 short DNA sequences by their dominant state.
 This simple classification made by choosing the most repeating state in
 the estimated Viterbi state path 
\begin_inset Formula $y_{1:L}:$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{class}=mode_{t\in[L]}y_{t}
\]

\end_inset


\end_layout

\begin_layout Section*
Results
\end_layout

\begin_layout Standard
For evaluating HOP-HMM, we first measure its capabilities on synthetic DNA
 data that was created in a controlled way.
 Afterwards, we see how does a HOP-HMM classify real human DNA sequences.
 The evaluation process on synthetic data is done by the following steps
 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

):
\end_layout

\begin_layout Enumerate
We generate parameters for a HOP-HMM 
\begin_inset Formula $\theta$
\end_inset

, which are treated as the true 
\begin_inset Formula $\theta$
\end_inset

.
 
\begin_inset Formula $\theta$
\end_inset

 is sampled in the following way:
\end_layout

\begin_deeper
\begin_layout Enumerate
Each cell T is sampled from the uniform distribution 
\begin_inset Formula 
\begin{equation}
T_{i,j}\sim U\left(minT_{i,j},maxT_{i,j}\right)\label{minTmaxT}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Each cell 
\begin_inset Formula $G_{i,j}$
\end_inset

 is sampled from a uniform and a Bernoulli distribution 
\begin_inset Formula 
\begin{equation}
G_{i,j}\sim U\left(minG,noiseG\right)+\boldsymbol{1}_{\left(i,0\right)\in Reg}\cdot Bern\left(\frac{k}{m}\right)\cdot maxG\label{noiseG}
\end{equation}

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
where 
\begin_inset Formula 
\[
\boldsymbol{1}_{\left(i,0\right)\in ENH}=\begin{cases}
1 & \left(i,0\right)\in ENH\\
0 & otherwise
\end{cases}
\]

\end_inset


\begin_inset Formula $ENH$
\end_inset

 is the set of 
\begin_inset Quotes eld
\end_inset

enhancer-mimicking
\begin_inset Quotes erd
\end_inset

 background-states, which are predefined background-states that have high
 probability of transitioning into TF-state.
 The rest of the background-states will have low probability to create TFBS,
 aiming to model the non-regulatory regions of the DNA with sparse TFBSs.
 In our experiments 
\begin_inset Formula $ENH$
\end_inset

 contained all but one state: 
\begin_inset Formula $\left(m,0\right)$
\end_inset

 meaning only one background-state had almost no TFBS and the rest 
\begin_inset Formula $m-1$
\end_inset

 background-states did have TFBSs.
\end_layout

\end_deeper
\begin_layout Enumerate
After being sampled, T and G are divided element-wise by their rows sum
 so their rows together become distributions:
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\begin{align}
T_{i,j}=\frac{T_{i,j}}{\sum_{j'\in[m]}T_{i,j'}+\sum_{j'\in[k]}G_{i,j'}} &  & G_{i,j}=\frac{G_{i,j}}{\sum_{j'\in[m]}T_{i,j'}+\sum_{j'\in[k]}G_{i,j'}}\label{GT_normalization}
\end{align}

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
E is sampled from a uniform distribution 
\begin_inset Formula $E_{j,b_{1},...,b_{o}}\sim U\left(0,1\right)$
\end_inset

 and divided by the sum of its last index to become a distribution array,
 similar to (c):
\begin_inset Formula 
\[
E_{j,b_{1},...,b_{o}}=\frac{E_{j,b_{1},...,b_{o}}}{\sum_{b'=[4]}E_{j,b_{1},...,b_{o-1},b'}}
\]

\end_inset


\end_layout

\begin_layout Enumerate
The start state distribution 
\begin_inset Formula $\pi$
\end_inset

 is non-random, and set so the first states are always one of the non-enhancer
 background-states: 
\begin_inset Formula 
\[
\pi_{i}=\frac{\boldsymbol{1}_{\left(i,0\right)\notin ENH}}{m-|ENH|}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Sequences are generated using the HOP-HMMs with the true 
\begin_inset Formula $\theta$
\end_inset

.
 Both the observed and the hidden sequences are used, denoted 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

.
 We split the 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 sequences into train and test for cross validation.
 
\end_layout

\begin_layout Enumerate
From the DNA sequences of 
\begin_inset Formula $X$
\end_inset

 train, we train a 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the HOP Baum-Welch algorithm.
\end_layout

\begin_layout Enumerate
Using the trained parameters 
\begin_inset Formula $\hat{\theta}$
\end_inset

, we estimate 
\begin_inset Formula $\hat{Y}$
\end_inset

 test from 
\begin_inset Formula $X$
\end_inset

 test and 
\begin_inset Formula $\hat{Y}$
\end_inset

 train from 
\begin_inset Formula $X$
\end_inset

 train by the HOP-Viterbi algorithm.
 We also calculate the posterior probability of 
\begin_inset Formula $P_{\hat{\theta}}\left(y_{t}|x_{1:L}\right)$
\end_inset

 from 
\begin_inset Formula $X$
\end_inset

 test and 
\begin_inset Formula $X$
\end_inset

 train.
 These results are then compared to the real 
\begin_inset Formula $Y$
\end_inset

 test and 
\begin_inset Formula $Y$
\end_inset

 train for accuracy measuring.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/Workflow.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Workflow"

\end_inset

Workflow of the evaluation process.
 A 
\begin_inset Formula $\theta$
\end_inset

 is sampled and a HOP-HMM model is created with which several fixed-length
 sequences are generated.
 A new model 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is then fitted to the train section of the observed sequences, via HOP-Baum-Wel
ch algorithm.
 With 
\begin_inset Formula $\hat{\theta},$
\end_inset

 a hidden sequence is then estimated by the HOP-Viterbi algorithm, and a
 posterior probability estimation is calculated by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PosteriorEstimation"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Baum-Welch algorithm is guaranteed to increase the likelihood in each
 step, however it is not guaranteed to converge to the optimal 
\begin_inset Formula $\theta^{*}$
\end_inset

 (
\begin_inset CommandInset citation
LatexCommand citet
key "key-50"

\end_inset

) as there is no known analytical way for reaching it.
 As a consequence, Baum-Welch algorithm converges into a local maximum 
\begin_inset Formula $\hat{\theta}$
\end_inset

 which could be a relatively low likelihood estimation, depending on the
 initialization point of the first 
\begin_inset Formula $\theta$
\end_inset

.
 The local maximum convergence issue is addressed in two ways:
\end_layout

\begin_layout Standard
1.
 We use regularization for faster and to a better 
\begin_inset Formula $\hat{\theta}$
\end_inset

 convergence (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization"

\end_inset

).
 Following each M-step update we draw the background-states transition probabili
ties 
\begin_inset Formula $T$
\end_inset

 to remain between 
\begin_inset Formula $maxT$
\end_inset

 and 
\begin_inset Formula $minT$
\end_inset

 matrices from 
\begin_inset CommandInset ref
LatexCommand eqref
reference "minTmaxT"

\end_inset

:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $T_{i,j}<minT_{i,j}$
\end_inset

 then we set 
\begin_inset Formula $T_{i,j}=minT_{i,j}$
\end_inset


\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $T_{i,j}>maxT_{i,j}$
\end_inset

 then we set 
\begin_inset Formula $T_{i,j}=maxT_{i,j}$
\end_inset


\end_layout

\begin_layout Itemize
T and G are divided by their row sum so their rows together remain a distributio
n as in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "GT_normalization"

\end_inset


\end_layout

\begin_layout Standard
2.
 Since Baum-Welch seek local maximum, running it multiple times with different
 initializations will cause convergence into different 
\begin_inset Formula $\hat{\theta}$
\end_inset

 results.
 As could be expected, we observed throughout multiple initializations that
 the higher the log likelihood of final 
\begin_inset Formula $\hat{\theta}$
\end_inset

 the lower its root mean square error (RMSE) compared to the true 
\begin_inset Formula $\theta$
\end_inset

 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "LikelihoodVsErr"

\end_inset

).
 This is important since on real observed sequences, only the estimated
 
\begin_inset Formula $\hat{\theta}$
\end_inset

 likelihood is known while the true 
\begin_inset Formula $\theta$
\end_inset

 is unknown.
 This correlation implies that for an estimation 
\begin_inset Formula $\hat{\theta}$
\end_inset

 that closer to the true 
\begin_inset Formula $\theta$
\end_inset

, one should redo several EM runs and choose the 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the highest likelihood.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "LikelihoodVsErr"

\end_inset

Over multiple runs of HOP-Baum-Welch, higher the sequences likelihood for
 the estimated 
\begin_inset Formula $\theta$
\end_inset

 resulted in lower errors compared to the true 
\begin_inset Formula $\theta$
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_likelihood.jpg
	scale 32

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_theta_error.jpg
	scale 32

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_theta_error_scatter.jpg
	scale 32

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/dec_viterbi.jpg
	scale 32

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "Regularization"

\end_inset


\series bold
A)
\series default
 The EM iterations draws the estimated 
\begin_inset Formula $\theta$
\end_inset

 values mostly closer to the values of the true 
\begin_inset Formula $\theta$
\end_inset

.
 
\series bold
B)
\series default
 The error between the true and estimated 
\begin_inset Formula $\theta$
\end_inset

 decrease, and after a few iterations converge to the same path regardless
 of the initialization.
 
\series bold
C)
\series default
 During the EM iterations, the learned 
\begin_inset Formula $\theta$
\end_inset

 yields a more accurate Viterbi estimation of the hidden states.
 Note that not even the true 
\begin_inset Formula $\theta$
\end_inset

 could produce Viterbi paths that is a perfect match to the true hidden
 sequences.
 
\series bold
D)
\series default
 The mean log likelihood of the sequences increases during the EM iterations.
 The experiment was done on 500 synthetic sequences (85% train, 15% test),
 1000 long.
 The trained model had 6 hidden background-states with emission order of
 2, each background-state had 25 TF-states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/synthetic_posterior_with_tfs.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "PostiriorProbability"

\end_inset

Posterior probability of sequences, estimated by a trained HOP-HMM 
\begin_inset Formula $\hat{\theta}$
\end_inset

 on test sequences that were synthetically generated by a HOP-HMM 
\begin_inset Formula $\theta$
\end_inset

.
 At the bottom of each posterior probability, there are the Viterbi hidden
 path by 
\begin_inset Formula $\hat{\theta}$
\end_inset

 and the true hidden states of each sequence.
 The black TFBS is the sum of all the probabilities of being in any of the
 TF-states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/confusion_matrix.jpg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "ConfutionMatrix"

\end_inset

Confusion matrix of true and estimated states by the Viterbi algorithm of
 HOP-HMM synthetic sequences.
 Rows are normalized so their sum is equal to 1.
 The majority of prediction are in the background-states 
\begin_inset Formula $(1,0)$
\end_inset

, 
\begin_inset Formula $(2,0)$
\end_inset

, 
\begin_inset Formula $(3,0)$
\end_inset

, 
\begin_inset Formula $(4,0)$
\end_inset

 and 
\begin_inset Formula $(5,0)$
\end_inset

, where TF-states are sometimes misclassified as their background-state
 state.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For testing of HOP-HMM on human genetic data, we manipulated the used the
 Roadmap project Bed files with BEDTools (
\begin_inset CommandInset citation
LatexCommand citet
key "key-68"

\end_inset

).
 We created a dataset of enhancer sequences around the intersection of DNase-I,
 H3K27ac and H3K4me1 peaks, while avoiding peaks of H3K27me3 and H3K4me3
 and sequences within 5000bp from known genes.
 Sequences were chosen 5000bp long sequences centered around their DNase-I
 peaks.
\end_layout

\begin_layout Standard
We wanted to evaluate if HOP-HMM can distinguish and detect enhancers active
 in two human tissues.
 For this we've built a set of 4000 bp fixed length sequences from the HG19
 in positions which were labeled as enhancers based on epigenetic data collected
 by Roadmap project from 57 tissues.
 Out of these enhancers, we chose only sequences of tissue-specific enhancers
 in one of two types of tissues, and not in the rest of the 57 tissues.
 We've added sequences with no known role, from random locations in the
 genome distal from genes or enhancers as background sequences.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
A HOP-HMM is trained by the HOP-Baum-Welch algorithm on the collected sequences.
 The trained model is then used to produce a Viterbi estimated hidden-states
 sequence and posterior probability, which can then be compared to the epigeneti
c tracks.
\end_layout

\begin_layout Standard
For the set of PWMs used by the TF-states of the HOP-HMM, we used JASPAR
 dataset of 519 vertebrates PWMs, out of which we selected 50 PWMs for a
 practical run-time.
 The selected PWMs are chosen by 3 methods, each method responsible for
 a third of the 50:
\end_layout

\begin_layout Itemize
PWMs of TFs which were relatively expressed in one tissue compared to the
 other, according to the Roadmap RNA-seq data.
 This method does not depend on the sequences themselves, but on epigenetic
 properties of the tissues.
\end_layout

\begin_layout Itemize
PWMs which are abundant in the sequences, i.e.
 PWMs with the highest mean likelihood to attach to the sequences.
 The likelihood of PWM 
\begin_inset Formula $W$
\end_inset

 to bind to a sequence 
\begin_inset Formula $x$
\end_inset

 is calculated as described mean is the average of 3 highest likelihood
 TFBS as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

.
 Note that here we use the PWM form as in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PPM"

\end_inset

 and not the PPM form for comparison between PWM likelihoods.
\end_layout

\begin_layout Itemize
PWMs that had strong presence in sequences from one tissue compared to the
 other.
 Specifically, the PWMs with sequence binding likelihood (as defined in
 the previous method) that can best distinguish between sequences from one
 tissue and the rest of the sequences in terms of AUC-ROC.
\end_layout

\begin_layout Standard
In our experiment, some sequences resulted posterior probability had good
 resemblance to the DNase-seq track, causing a good overlap between the
 Viterbi-path and the ChromeHMM classifications (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RealSequences"

\end_inset

), though this similarity was not always occurring.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq1.jpg
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq2.jpg
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeq3.jpg
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename Figures/realSeqLegend.jpg
	scale 30

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:RealSequences"

\end_inset

Examples of HOP-HMM classification of 5000pb long tissue specific enhancer
 sequences from the human genome.
 Each of the 3 graphs is the output of a different HOP-HMM with three background
-states (two enhancer states and one non-enhancer state) and 50 TF-states,
 each was trained on enhancers from the two tissues.
 The H3K27ac and DNase-I measurements are in 
\begin_inset Formula $-log_{10}(p-value)$
\end_inset

 units.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section*
Discussion and Conclusions
\end_layout

\begin_layout Standard
In this work I have aimed to develop a generalized HMM, HOP-HMM, tailored
 for the enhancer structure.
 I developed the mathematical adjustments to the different parts of the
 EM algorithm and provided and reasoning for the correctness of the inferring
 of the altered model from data.
 For evaluation on real and synthetic data as described in the results,
 I implemented the model and the algorithm in Matlab code.
 During the algorithm implementation, I overcame a few difficulties that
 origin from the scale of the data, such as caching the costly response
 of the PWMs to the sequences during the Forward Backward algorithms, and
 splitting to sequences into batches for holding and manipulating the large
 
\begin_inset Formula $\eta$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 matrix in memory.
 The implementation also includes the generation code for DNA sequences
 from a randomly selected HOP-HMM to which a different model can be fitted
 and compared.
 Naturally, in the synthetic data experiment, the more generated data is
 used to fit the model, the better the fitting performs.
 During the evaluation of the inference EM algorithm, many runs tend to
 overshoot the inter-states transition probability, resulting in a tendency
 for irregular Viterbi paths with frequent state changes.
 This resembles the known issue of HMM parameter overfitting on small training
 data.
 I therefore introduced a regularization technique that had a significant
 positive impact on the convergence rate and solution quality.
 Overall, the generated DNA sequences experiment results were positive and
 are evidence for the ability of the algorithm to train successfully on
 DNA sequences created under the HOP-HMM assumptions.
\end_layout

\begin_layout Standard
For applying the EM algorithm on real data, I designed a simplistic challenge
 of correctly recognizing enhancers where their true locations are known
 from epigenetic experiments.
 This challenge first required building a dataset of sequences containing
 tissue-specific enhancers from two tissues together with wide margins,
 and non-regulatory 
\begin_inset Quotes eld
\end_inset

background
\begin_inset Quotes erd
\end_inset

 sequences.
 When choosing the tissue-specific enhancers from the epigenetic data provided
 by the Roadmap project, the noisiness of the data should be considered.
 After some trail and error, I chose the somewhat arbitrary cutoff of the
 top 40% strongest DNase-seq peaks, which yielded enough sequences (around
 500 sequences per tissue on average) with distinguishable distributions
 between the tissues.
\end_layout

\begin_layout Standard
Though many real DNA sequences were correctly classified, some tissues caused
 the EM algorithm to consistently converge to parameters which gave mostly
 wrong Viterbi path classifications.
 This could stem from several reasons: wrong PWMs selection as hyperparameters,
 too small or noisy dataset building from the Roadmap data and a more complex
 structure than assumed by the HOP-HMM hypothesis.
 In further research, usage of updated data with cleaner more tissue-diverse
 experiments would likely provide better results.
 As a computational approach to improve the generalized HMM used in this
 work is to introduce learning of the PWMs preceding or during the EM iterations
, or to replace the PWMs emission entirely by a different TFBS modeling
 method.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Appendix: Source Code
\end_layout

\begin_layout Standard
The code for this research was written in Matlab, and can be found in 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/David-Taub/HOP-HMM
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="2">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top" width="10cm">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Variable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meaning
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
L
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DNA sequences length
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
N
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of DNA sequences
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
m
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of background-states
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
k
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Number of TF-states of each background-state
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
order
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Dependency order of the emission of the background-states done by 
\begin_inset Formula $E$
\end_inset

.
 For example, if 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
order
\end_layout

\end_inset

 equals 3, then the emission is conditional on 2 previous observable variables.
 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Flex Code
status open

\begin_layout Plain Layout
backgroundAmount
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none" width="10cm">
\begin_inset Text

\begin_layout Plain Layout
Number of background-states which are non-enhancers by having low transition
 probability into TF-states
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
The prominent code files in the project:
\end_layout

\begin_layout Itemize

\series bold
HOP-HMM/data/peaks/scripts/download_and_process_all.sh
\end_layout

\begin_deeper
\begin_layout Standard
Linux bash script which downloads data files of epigenetic from Roadmap
 website, JASPAR PWMs and hg19 genome.
 After downloading, the data is per-processed with Bedtools and bigWigToBedGraph.
 The only part in this project that requires Linux is the bigWigToBedGraph.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/+peaks/minimizeMergePeak.m
\end_layout

\begin_deeper
\begin_layout Standard
Reads downloaded bed files, process them and saves them into MAT-file v7.3.
 
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
 
\end_layout

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mergedPeaksMin = minimizeMergePeak(params, L)
\end_layout

\end_inset

;
\end_layout

\begin_layout Standard
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
doGTBound
\end_layout

\end_inset

 indicates whether or not to apply regularization on T and G transition
 probabilities and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
doESharing
\end_layout

\end_inset

 indicates whether or not to force 
\begin_inset Formula $E$
\end_inset

 to share the emission across all background-states 
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/misc/genSyntheticMergedPeaksMin.m
\end_layout

\begin_deeper
\begin_layout Standard
Generates DNA sequences X and hidden variables Y out of a random 
\begin_inset Formula $\theta$
\end_inset

, which was sampled by genTheta.m
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
\end_layout

\end_inset

 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mergedPeaksMin = genSyntheticMergedPeaksMin(N, L, params, startWithBackground,
 backgroundGNoise);
\end_layout

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
startWithBackground
\end_layout

\end_inset

 indicates whether or not to force 
\begin_inset Formula $\pi$
\end_inset

 to allow starting only from non-enhancer background-states and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
backgroundGNoise
\end_layout

\end_inset

 is the background rate of background-state to TF-state transition, marked
 as 
\begin_inset Formula $noiseG$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "noiseG"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/misc/genTheta.m
\end_layout

\begin_deeper
\begin_layout Standard
Generates a random 
\begin_inset Formula $\theta$
\end_inset

, with options to sample a total random 
\begin_inset Formula $T$
\end_inset

 and a total random 
\begin_inset Formula $\pi$
\end_inset

.
 Note that 
\begin_inset Formula $\pi$
\end_inset

 is called 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
theta.startT
\end_layout

\end_inset

 throughout the code.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
 
\end_layout

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
theta = genTheta(params, false, false);
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/mainRealData.m
\end_layout

\begin_deeper
\begin_layout Standard
Entry point of the code, reads data from human genome, trains HOP-HMMs model
 and compares posterior probability to real epigenetic data.
 Execution of mainRealData will produce figures similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "RealData"

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mainRealData();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/mainPosterior.m
\end_layout

\begin_deeper
\begin_layout Standard
Entry point of the code, follows the workflow of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

.
 Execution of mainPosterior plots random set of sequences with their Viterbi
 sequence and posterior probabilities similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PostiriorProbability"

\end_inset

 and a confusion matrix similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "ConfutionMatrix"

\end_inset

.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mainPosterior();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/mainDecErrorPlot.m
\end_layout

\begin_deeper
\begin_layout Standard
Entry point of the code, follows the workflow of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

, and at each iteration of the EM, likelihood and errors are collected to
 form plots similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization"

\end_inset

.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
mainDecErrorPlot();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
HOP-HMM/src/+EM/EM.m
\end_layout

\begin_deeper
\begin_layout Standard
The function actually trains the HOP-HMM model from a given DNA sequence
 is the EM().
 The neighboring code files residing in the +EM folder which contains it,
 are the implementations of the E and M steps described in the introduction
 part of this work.
\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
[test, train] = misc.crossValidationSplit(params, mergedPeaksMin, testTrainRatio)
;
\end_layout

\end_inset


\end_layout

\begin_layout Quote
\begin_inset Flex Code
status open

\begin_layout Plain Layout
[bestTheta, bestLikelihood, bestThetas] = EM(train, params, maxIter, patience,
 repeat);
\end_layout

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
maxIter
\end_layout

\end_inset

 is the maximal number of iterations allowed in a run, 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
parience
\end_layout

\end_inset

 is the number of iterations without likelihood increase that are allowed
 in a run and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout
repeat
\end_layout

\end_inset

 is the number of different runs with different initializations that are
 tried.
\end_layout

\end_deeper
\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ahituv et al.(2007)"
key "key-1"

\end_inset

 Ahituv, N., Zhu, Y., Visel, A., Holt, A., Afzal, V., Pennacchio, L.
 A., & Rubin, E.
 M.
 (2007).
 Deletion of ultraconserved elements yields viable mice.
 PLoS biology, 5(9), e234.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ainscough et al.(1998)"
key "key-57"

\end_inset

 Ainscough, R., Bardill, S., Barlow, K., Basham, V., Baynes, C., Beard, L., ...
 & Burrows, C.
 (1998).
 Genome sequence of the nematode C.
 elegans: a platform for investigating biology.
 Science, 282(5396), 2012-2018.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Alipanahi et al.(2015)"
key "key-2"

\end_inset

 Alipanahi, B., Delong, A., Weirauch, M.
 T., & Frey, B.
 J.
 (2015).
 Predicting the sequence specificities of DNA-and RNA-binding proteins by
 deep learning.
 Nature biotechnology, 33(8), 831.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Baum et al.(1966)"
key "key-4"

\end_inset

 Baum, L.
 E., & Petrie, T.
 (1966).
 Statistical inference for probabilistic functions of finite state Markov
 chains.
 The annals of mathematical statistics, 37(6), 1554-1563.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Benko et al.(2009)"
key "key-6"

\end_inset

 Benko, S., Fantes, J.
 A., Amiel, J., Kleinjan, D., Thomas, S., Ramsay, J., et al.
 (2009).
 Highly conserved non.
 Nature Genetics 64(2), p.
 10-12.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Boyle et al.(2008)"
key "key-71"

\end_inset

 Boyle, A.
 P., Davis, S., Shulha, H.
 P., Meltzer, P., Margulies, E.
 H., Weng, Z., ...
 & Crawford, G.
 E.
 (2008).
 High-resolution mapping and characterization of open chromatin across the
 genome.
 Cell, 132(2), 311-322.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Burge and Karlin(1997)"
key "key-22"

\end_inset

 Burge, C., & Karlin, S.
 (1997).
 Prediction of complete gene structures in human genomic DNA.
 Journal of molecular biology, 268(1), 78-94.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Buenrostro et al.(2013)"
key "key-70"

\end_inset

 Buenrostro, J.
 D., Giresi, P.
 G., Zaba, L.
 C., Chang, H.
 Y., & Greenleaf, W.
 J.
 (2013).
 Transposition of native chromatin for fast and sensitive epigenomic profiling
 of open chromatin, DNA-binding proteins and nucleosome position.
 Nature methods, 10(12), 1213.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Calo et al.(2013)"
key "key-7"

\end_inset

 Calo, E., & Wysocka, J.
 (2013).
 Modification of enhancer chromatin: what, how, and why?.
 Molecular cell, 49(5), 825-837.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Creyghton et al.(2010)"
key "key-8"

\end_inset

 Creyghton, M.
 P., Cheng, A.
 W., Welstead, G.
 G., Kooistra, T., Carey, B.
 W., Steine, E.
 J., ...
 & Boyer, L.
 A.
 (2010).
 Histone H3K27ac separates active from poised enhancers and predicts development
al state.
 Proceedings of the National Academy of Sciences, 107(50), 21931-21936.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Cutter et al.(2015)"
key "key-9"

\end_inset

 Cutter, A.
 R., & Hayes, J.
 J.
 (2015).
 A brief review of nucleosome structure.
 FEBS letters, 589(20), 2914-2922.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "De Beer et al.(2014)"
key "key-5"

\end_inset

 De Beer, Z.
 W., Duong, T.
 A., Barnes, I., Wingfield, B.
 D., & Wingfield, M.
 J.
 (2014).
 Redefining Ceratocystis and allied genera.
 Studies in Mycology, 79, 187-219.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Diehl et al.(2016)"
key "key-10"

\end_inset

 Diehl, A.
 D., Meehan, T.
 F., Bradford, Y.
 M., Brush, M.
 H., Dahdul, W.
 M., Dougall, D.
 S., ...
 & Van Slyke, C.
 E.
 (2016).
 The Cell Ontology 2016: enhanced content, modularization, and ontology
 interoperability.
 Journal of biomedical semantics, 7(1), 44.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Doniger et al.(2005)"
key "key-12"

\end_inset

 Doniger, S.
 W., Huh, J., & Fay, J.
 C.
 (2005).
 Identification of functional transcription factor binding sites using closely
 related Saccharomyces species.
 Genome research, 15(5), 701-709.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Du Preez(1998)"
key "key-47"

\end_inset

 Du Preez, J.
 A.
 (1998).
 Efficient training of high-order hidden Markov models using first-order
 representations.
 Computer speech & language, 12(1), 23-39.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Emison et al.(2005)"
key "key-13"

\end_inset

 Emison, E.
 S., McCallion, A.
 S., Kashuk, C.
 S., Bush, R.
 T., Grice, E., Lin, S., ...
 & Chakravarti, A.
 (2005).
 A common sex-dependent mutation in a RET enhancer underlies Hirschsprung
 disease risk.
 Nature, 434(7035), 857.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ernst and Kellis(2012)"
key "key-14"

\end_inset

 Ernst, J., & Kellis, M.
 (2012).
 ChromHMM: automating chromatin-state discovery and characterization.
 Nature methods, 9(3), 215.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ernst et al.(2011)"
key "key-15"

\end_inset

 Ernst, J., Kheradpour, P., Mikkelsen, T.
 S., Shoresh, N., Ward, L.
 D., Epstein, C.
 B., ...
 & Ku, M.
 (2011).
 Mapping and analysis of chromatin state dynamics in nine human cell types.
 Nature, 473(7345), 43.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ezkurdia et al.(2014)"
key "key-16"

\end_inset

 Ezkurdia, I., Juan, D., Rodriguez, J.
 M., Frankish, A., Diekhans, M., Harrow, J., ...
 & Tress, M.
 L.
 (2014).
 Multiple evidence strands suggest that there may be as few as 19 000 human
 protein-coding genes.
 Human molecular genetics, 23(22), 5866-5878.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ferguson(1980)"
key "key-17"

\end_inset

 Ferguson, J.
 D.
 (1980).
 pp.
 143–179, Variable duration models for speech.
 In Proc.
 of the Symposium on the applications of hidden Markov models to text and
 speech, JD Ferguson, Ed.
 Princeton: IDA-CRD.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Fishilevich et al.(2017)"
key "key-20"

\end_inset

 Fishilevich, S., Nudel, R., Rappaport, N., Hadar, R., Plaschkes, I., Iny Stein,
 T., ...
 & Lancet, D.
 (2017).
 GeneHancer: genome-wide integration of enhancers and target genes in GeneCards.
 Database, 2017.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Friedli et al.(2010)"
key "key-21"

\end_inset

 Friedli, M., Barde, I., Arcangeli, M., Verp, S., Quazzola, A., Zakany, J., ...
 & Duboule, D.
 (2010).
 A systematic enhancer screen using lentivector transgenesis identifies
 conserved and non-conserved functional elements at the Olig1 and Olig2
 locus.
 PLoS One, 5(12), e15741.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Galperin and Fernandez(2012)"
key "key-18"

\end_inset

 Galperin, M.
 Y., & Fernández-Suarez, X.
 M.
 (2011).
 The 2012 nucleic acids research database issue and the online molecular
 biology database collection.
 Nucleic acids research, 40(D1), D1-D8.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Haussler and Eeckman(1996)"
key "key-24"

\end_inset

 Haussler, D.
 K.
 D., & Eeckman, M.
 G.
 R.
 F.
 H.
 (1996).
 A generalized hidden Markov model for the recognition of human genes in
 DNA.
 In Proc.
 int.
 conf.
 on intelligent systems for molecular biology, st.
 louis (pp.
 134-142).
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Hayashi-Takanaka et al.(2011)"
key "key-25"

\end_inset

 Hayashi-Takanaka, Y., Yamagata, K., Wakayama, T., Stasevich, T.
 J., Kainuma, T., Tsurimoto, T., ...
 & Kimura, H.
 (2011).
 Tracking epigenetic histone modifications in single cells using Fab-based
 live endogenous modification labeling.
 Nucleic acids research, 39(15), 6475-6488.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Heintzman et al.(2007)"
key "key-26"

\end_inset

 Heintzman, N.
 D., Stuart, R.
 K., Hon, G., Fu, Y., Ching, C.
 W., Hawkins, R.
 D., ...
 & Wang, W.
 (2007).
 Distinct and predictive chromatin signatures of transcriptional promoters
 and enhancers in the human genome.
 Nature genetics, 39(3), 311.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Heintzman et al.(2009)"
key "key-19"

\end_inset

 Heintzman, N.
 D., Hon, G.
 C., Hawkins, R.
 D., Kheradpour, P., Stark, A., Harp, L.
 F., ...
 & Ching, K.
 A.
 (2009).
 Histone modifications at human enhancers reflect global cell-type-specific
 gene expression.
 Nature, 459(7243), 108.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Hu et al.(1996)"
key "key-27"

\end_inset

 Hu, J., Brown, M.
 K., & Turin, W.
 (1996).
 HMM based online handwriting recognition.
 IEEE Transactions on pattern analysis and machine intelligence, 18(10),
 1039-1045.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Jin et al.(2011)"
key "key-28"

\end_inset

 Jin Q, Yu L-R, Wang L, Zhang Z, Kasper LH, Lee J-E, Wang C, Brindle PK,
 Dent SYR, Ge K.
 2011.
 Distinct roles of GCN5/PCAF-mediated H3K9ac and CBP/p300-mediated H3K18/27ac
 in nuclear receptor transactivation.
 The EMBO Journal 30:249–262.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Jones et al.(2012)"
key "key-29"

\end_inset

 Jones, P.
 A.
 (2012).
 Functions of DNA methylation: islands, start sites, gene bodies and beyond.
 Nature Reviews Genetics, 13(7), 484.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kaplan et al.(2012)"
key "key-64"

\end_inset

 Kaplan, T., & Biggin, M.
 D.
 (2012).
 Quantitative models of the mechanisms that control genome-wide patterns
 of animal transcription factor binding.
 In Methods in cell biology (Vol.
 110, pp.
 263-283).
 Academic Press.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Karmodiya et al.(2012)"
key "key-30"

\end_inset

 Karmodiya, K., Krebs, A.
 R., Oulad-Abdelghani, M., Kimura, H., & Tora, L.
 (2012).
 H3K9 and H3K14 acetylation co-occur at many gene regulatory elements, while
 H3K14ac marks a subset of inactive inducible promoters in mouse embryonic
 stem cells.
 BMC genomics, 13(1), 424.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kelley et al.(2016)"
key "key-31"

\end_inset

 Kelley, D.
 R., Snoek, J., & Rinn, J.
 L.
 (2016).
 Basset: learning the regulatory code of the accessible genome with deep
 convolutional neural networks.
 Genome research, 26(7), 990-999.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Khan et al.(2018)"
key "key-32"

\end_inset

 Khan, A., Fornes, O., Stigliani, A., Gheorghe, M., Castro-Mondragon, J.
 A., van der Lee, R., ...
 & Baranasic, D.
 (2017).
 JASPAR 2018: update of the open-access database of transcription factor
 binding profiles and its web framework.
 Nucleic acids research, 46(D1), D260-D266.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kleftogiannis et al.(2016)"
key "key-33"

\end_inset

 Kleftogiannis, D., Kalnis, P., Arner, E., & Bajic, V.
 B.
 (2016).
 Discriminative identification of transcriptional responses of promoters
 and enhancers after stimulus.
 Nucleic acids research, 45(4), e25-e25.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kreimer et al.(2017)"
key "key-35"

\end_inset

 Kreimer, A., Zeng, H., Edwards, M.
 D., Guo, Y., Tian, K., Shin, S., ...
 & Li, Y.
 (2017).
 Predicting gene expression in massively parallel reporter assays: a comparative
 study.
 Human mutation, 38(9), 1240-1250.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kulakovskiy et al.(2011)"
key "key-36"

\end_inset

 Kulakovskiy, I.
 V., Belostotsky, A.
 A., Kasianov, A.
 S., Esipova, N.
 G., Medvedeva, Y.
 A., Eliseeva, I.
 A., & Makeev, V.
 J.
 (2011).
 A deeper look into transcription regulatory code by preferred pair distance
 templates for transcription factor binding sites.
 Bioinformatics, 27(19), 2621-2624.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kundaje et al.(2015)"
key "key-37"

\end_inset

 Kundaje, A., Meuleman, W., Ernst, J., Bilenky, M., Yen, A., Heravi-Moussavi,
 A., ...
 & Amin, V.
 (2015).
 Integrative analysis of 111 reference human epigenomes.
 Nature, 518(7539), 317.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lee and Lee(2006)"
key "key-38"

\end_inset

 Lee, L.
 M., & Lee, J.
 C.
 (2006, June).
 A study on high-order hidden Markov models and applications to speech recogniti
on.
 In International Conference on Industrial, Engineering and Other Applications
 of Applied Intelligent Systems (pp.
 682-690).
 Springer, Berlin, Heidelberg.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lettice et al.(2003)"
key "key-39"

\end_inset

 Lettice, L.
 A., Heaney, S.
 J., Purdie, L.
 A., Li, L., de Beer, P., Oostra, B.
 A., ...
 & de Graaff, E.
 (2003).
 A long-range Shh enhancer regulates expression in the developing limb and
 fin and is associated with preaxial polydactyly.
 Human molecular genetics, 12(14), 1725-1735.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lindblad-Toh et al.(2011)"
key "key-40"

\end_inset

 Lindblad-Toh, K., Garber, M., Zuk, O., Lin, M.
 F., Parker, B.
 J., Washietl, S., ...
 & Ward, L.
 D.
 (2011).
 A high-resolution map of human evolutionary constraint using 29 mammals.
 Nature, 478(7370), 476.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Mari et al.(1997)"
key "key-41"

\end_inset

 Mari, J.
 F., Haton, J.
 P., & Kriouile, A.
 (1997).
 Automatic word recognition based on second-order hidden Markov models.
 IEEE Transactions on speech and Audio Processing, 5(1), 22-25.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Markov(1906)"
key "key-42"

\end_inset

 Markov, A.
 A.
 (1906).
 Extension of the law of large numbers to dependent quantities.
 Izv.
 Fiz.-Matem.
 Obsch.
 Kazan Univ.(2nd Ser), 15, 135-156.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Miguel-Escalada et al.(2015)"
key "key-44"

\end_inset

 Miguel-Escalada, I., Pasquali, L., & Ferrer, J.
 (2015).
 Transcriptional enhancers: functional insights and role in human disease.
 Current opinion in genetics & development, 33, 71-76.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ng et al.(2009)"
key "key-45"

\end_inset

 Ng, S.
 B., Turner, E.
 H., Robertson, P.
 D., Flygare, S.
 D., Bigham, A.
 W., Lee, C., ...
 & Bamshad, M.
 (2009).
 Targeted capture and massively parallel sequencing of 12 human exomes.
 Nature, 461(7261), 272.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Pennacchio et al.(2006)"
key "key-11"

\end_inset

 Pennacchio, L.
 A., Ahituv, N., Moses, A.
 M., Prabhakar, S., Nobrega, M.
 A., Shoukry, M., ...
 & Plajzer-Frick, I.
 (2006).
 In vivo enhancer analysis of human conserved non-coding sequences.
 Nature, 444(7118), 499-502.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Pennacchio et al.(2015)"
key "key-46"

\end_inset

 Pennacchio, L.
 A., Bickmore, W., Dean, A., Nobrega, M.
 A., & Bejerano, G.
 (2013).
 Enhancers: five essential questions.
 Nature Reviews Genetics, 14(4), 288.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Przybilla et al.(2012)"
key "key-48"

\end_inset

 Przybilla, J., Galle, J., & Rohlf, T.
 (2012).
 Is adult stem cell aging driven by conflicting modes of chromatin remodeling?.
 Bioessays, 34(10), 841-848.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Quinlan and Hall(2010)"
key "key-68"

\end_inset

 Quinlan, A.
 R., & Hall, I.
 M.
 (2010).
 BEDTools: a flexible suite of utilities for comparing genomic features.
 Bioinformatics, 26(6), 841-842.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rabiner and Juang(1993)"
key "key-49"

\end_inset

 Rabiner, L., & Juang, B.
 H.
 (1993).
 Fundamentals of speech processing.
 Prantice Hall.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rabiner(1989)"
key "key-50"

\end_inset

 Rabiner, L.
 R.
 (1989).
 A tutorial on hidden Markov models and selected applications in speech
 recognition.
 Proceedings of the IEEE, 77(2), 257-286.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rada-Iglesias et al.(2011)"
key "key-51"

\end_inset

 Rada-Iglesias, A., Bajpai, R., Swigut, T., Brugmann, S.
 A., Flynn, R.
 A., & Wysocka, J.
 (2011).
 A unique chromatin signature uncovers early developmental enhancers in
 humans.
 Nature, 470(7333), 279.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rosin et al.(2013)"
key "key-52"

\end_inset

 Rosin, J.
 M., Abassah-Oppong, S., & Cobb, J.
 (2013).
 Comparative transgenic analysis of enhancers from the human SHOX and mouse
 Shox2 genomic regions.
 Human molecular genetics, 22(15), 3063-3076.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Smemo S(2012)"
key "key-53"

\end_inset

 Smemo, S., Campos, L.
 C., Moskowitz, I.
 P., Krieger, J.
 E., Pereira, A.
 C., & Nobrega, M.
 A.
 (2012).
 Regulatory variation in a TBX5 enhancer leads to isolated congenital heart
 disease.
 Human molecular genetics, 21(14), 3255-3263.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Soldner et al.(2016)"
key "key-54"

\end_inset

 Soldner, F., Stelzer, Y., Shivalila, C.
 S., Abraham, B.
 J., Latourelle, J.
 C., Barrasa, M.
 I., ...
 & Jaenisch, R.
 (2016).
 Parkinson-associated risk variant in distal enhancer of α-synuclein modulates
 target gene expression.
 Nature, 533(7601), 95.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Stadler et al.(2011)"
key "key-55"

\end_inset

 Stadler, M.
 B., Murr, R., Burger, L., Ivanek, R., Lienert, F., Schöler, A., ...
 & Tiwari, V.
 K.
 (2011).
 DNA-binding factors shape the mouse methylome at distal regulatory regions.
 Nature, 480(7378), 490.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Stormo et al.(1982)"
key "key-7"

\end_inset

 Stormo, G.
 D., Schneider, T.
 D., Gold, L., & Ehrenfeucht, A.
 (1982).
 Use of the ‘Perceptron’algorithm to distinguish translational initiation
 sites in E.
 coli.
 Nucleic acids research, 10(9), 2997-3011.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Staden(1984)"
key "key-8"

\end_inset

 Staden, R.
 (1984).
 Computer methods to locate signals in nucleic acid sequences.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Taher et al.(2011)"
key "key-56"

\end_inset

 Taher, L., McGaughey, D.
 M., Maragh, S., Aneas, I., Bessling, S.
 L., Miller, W., ...
 & Ovcharenko, I.
 (2011).
 Genome-wide identification of conserved regulatory function in diverged
 sequences.
 Genome research, 21(7), 1139-1149.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Tate and Bird(1993)"
key "key-3"

\end_inset

 Tate, P.
 H., & Bird, A.
 P.
 (1993).
 Effects of DNA methylation on DNA-binding proteins and gene expression.
 Current opinion in genetics & development, 3(2), 226-231.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Thurman et al.(2012)"
key "key-58"

\end_inset

 Thurman, R.
 E., Rynes, E., Humbert, R., Vierstra, J., Maurano, M.
 T., Haugen, E., ...
 & Garg, K.
 (2012).
 The accessible chromatin landscape of the human genome.
 Nature, 489(7414), 75.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Turin and Sondhi(1993)"
key "key-59"

\end_inset

 Turin, W., & Sondhi, M.
 M.
 (1993).
 Modeling error sources in digital channels.
 IEEE Journal on Selected Areas in Communications, 11(3), 340-347.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2007)"
key "key-60"

\end_inset

 Visel, A., Minovitsky, S., Dubchak, I., & Pennacchio, L.
 A.
 (2007).
 VISTA Enhancer Browser—a database of tissue-specific human enhancers.
 Nucleic Acids Research, 35(Database issue), D88.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2009)"
key "key-61"

\end_inset

 Visel, A., Blow, M.
 J., Li, Z., Zhang, T., Akiyama, J.
 A., Holt, A., ...
 & Afzal, V.
 (2009).
 ChIP-seq accurately predicts tissue-specific activity of enhancers.
 Nature, 457(7231), 854.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Viterbi(1967)"
key "key-65"

\end_inset

 Viterbi, A.
 (1967).
 Error bounds for convolutional codes and an asymptotically optimum decoding
 algorithm.
 IEEE transactions on Information Theory, 13(2), 260-269.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Williamson et al.(2011)"
key "key-43"

\end_inset

 Williamson, I., Hill, R.
 E., & Bickmore, W.
 A.
 (2011).
 Enhancers: from developmental genetics to the genetics of common human
 disease.
 Developmental cell, 21(1), 17-19.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Winter et al.(1981)"
key "key-67"

\end_inset

 Winter, R.
 B., Berg, O.
 G., & Von Hippel, P.
 H.
 (1981).
 Diffusion-driven mechanisms of protein translocation on nucleic acids.
 3.
 The Escherichia coli lac repressor-operator interaction: kinetic measurements
 and conclusions.
 Biochemistry, 20(24), 6961-6977.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Yang and Wainwright(2015)"
key "key-66"

\end_inset

Yang, F., Balakrishnan, S., & Wainwright, M.
 J.
 (2015, December).
 Statistical and computational guarantees for the Baum-Welch algorithm.
 In 2015 53rd Annual Allerton Conference on Communication, Control, and
 Computing (Allerton) (pp.
 658-665).
 IEEE.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zentner et al.(2011)"
key "key-62"

\end_inset

 Zentner, G.
 E., Tesar, P.
 J., & Scacheri, P.
 C.
 (2011).
 Epigenetic signatures distinguish multiple classes of enhancers with distinct
 cellular functions.
 Genome research, 21(8), 1273-1283.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zhang et al.(2008)"
key "key-73"

\end_inset

 Zhang, Y., Liu, T., Meyer, C.
 A., Eeckhoute, J., Johnson, D.
 S., Bernstein, B.
 E., ...
 & Liu, X.
 S.
 (2008).
 Model-based analysis of ChIP-Seq (MACS).
 Genome biology, 9(9), R137.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zhou and Troyanskaya(2015)"
key "key-63"

\end_inset

 Zhou, J., & Troyanskaya, O.
 G.
 (2015).
 Predicting effects of noncoding variants with deep learning–based sequence
 model.
 Nature methods, 12(10), 931.
\end_layout

\end_body
\end_document
