#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[nottoc,numbib]{tocbibind}
\usepackage{babel}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{wrapfig}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\captionsetup{justification=justified,singlelinecheck=false}
\end_preamble
\use_default_options false
\begin_modules
logicalmkup
\end_modules
\maintain_unincluded_children false
\begin_local_layout
InsetLayout Flex:Code
    LyxType               charstyle
    LabelString           code
    LatexType             command
    LatexName             code
    Font
      Family              Typewriter
    EndFont
    Preamble
    \newcommand{\code}[1]{\texttt{#1}}
    EndPreamble
    InToc                 true
    HTMLTag               code
End
\end_local_layout
\language hebrew
\language_package default
\inputencoding cp1255
\fontencoding T1
\font_roman "times" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "newtxmath" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\output_sync_macro "\synctex=1"
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic true
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 1.5cm
\headheight 0cm
\headsep 0cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size larger
\lang english
\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size huge

\begin_inset space ~
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hrulefill
\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

Classification of Regulatory Sequences 
\begin_inset Newline newline
\end_inset

in the Human Genome Using High-Order 
\begin_inset Newline newline
\end_inset

Generalized Hidden Markov Models 
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Newline newline
\end_inset


\lang hebrew
סיווג קטעי בקרה מהגנום האנושי על ידי
\begin_inset Newline newline
\end_inset

מודל מרקוב חבוי מוכלל מסדר גבוה
\lang english

\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hrulefill
\end_layout

\end_inset


\begin_inset space ~
\end_inset


\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\lang english
by
\begin_inset Newline newline
\end_inset


\size larger
David Taub 
\size small
(302546163)
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\lang english
Supervised by
\begin_inset Newline newline
\end_inset


\size larger
Prof.
 Tommy Kaplan
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size huge

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\lang english
A thesis submitted in partial fulfillment of the requirements for the
\begin_inset Newline newline
\end_inset

degree of Master of Science in Computer Science
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size large
\lang english
April 2020
\begin_inset Newline newline
\end_inset


\size larger
\lang hebrew
ניסן תש"פ
\lang english

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\size larger

\begin_inset space ~
\end_inset


\size large

\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center

\size larger
\lang english
The Faculty of Computer Science and Engineering
\begin_inset Newline newline
\end_inset

The Hebrew University of Jerusalem, Israel
\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*

\lang english
Acknowledgments
\end_layout

\begin_layout Standard

\lang english
My deepest gratitude goes to my supervisor, professor Tommy Kaplan, who
 sparked my curiosity for the nature of DNA in one of the open lectures
 I attended when I was an undergraduate computer science student.
 In our many talks since then, professor Kaplan's insights in the field
 of computational biology through the prism of the machine learning paradigm
 grew my interest even more.
 He taught me that patience and methodological work are irreplaceable properties
 of any good researcher,
\emph on
 
\begin_inset Quotes eld
\end_inset

As a man sows, so shall he reap
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
Thank you for your guidance, advice and ideas during my participation in
 the research, your support and understanding gave me confidence through
 the hard parts of this road.
 It is well known among your students that your unique character always
 conveys a merry and pleasant atmosphere in your research group.
\end_layout

\begin_layout Standard

\lang english
I  would also wish to thank my mother, Dr.
 Jenny Taub and my sister Matty Ariel for their careful review of this work.
 I am in debt for the many helpful suggestions they provided, which greatly
 improved the language and content of this thesis.
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
תקציר
\end_layout

\begin_layout Standard
מעצמים )srecnahne( הם קטעי בקרה גנטיים אשר מגבירים את סיכוי השעתוק של גן
 המטרה שלהם בהקשרם לחלבונים גורמי שעתוק )srotcaf noitpircsnart( והצמדות
 לאזור הגן.
 בקרת השעתוק היא צורת שליטה חשובה בביטוי הגנים וממלאת תפקיד משמעותי בבקרת
 הגנים על פי מצב התא והרקמה לה הוא שייך.
 במשך השנים נצטברו עדויות לכך ששינויים גנטיים ברצפי המעצמים עלולים לגרום
 לשינויים בהתנהגותם של תאים וכתוצאה מכך, למחלות.
 הכללים והדקויות של מבנה המעצם טרם הובנו לחלוטין, אף כי ניסויים הראו כי
 גורמי שעתוק נוטים להצמד לאתרי קשירה של גורמי שעתוק, שהם מוטיבים יחודיים
 אשר נפוצים יחסית בקטעי המעצמים.
 ניתן לאתר את פעילות המעצם לפי מידע אפיגנטי בסביבתו, כשהסימנים העיקריים
 הם השינויי בהיסטונים )snoitacifidom enotsih( אשר סביבם כרוכים אגפי המעצם.
 המעצם נוטה להיות נגיש מרחבית עבור אינטראקציות ביוכימיות בין ה-AND לחלבונים
 שסביבו.
 על אף תועלתו הרבה, המידע האפיגנטי לעיתים קרובות רועש ומצריך תהליכים יקרים
 של חילוץ תאים ספציפיים מתוך רקמותיהם, פעולה אשר אינה תמיד ברת ביצוע לכלל
 סוגי התאים בשלביהם השונים.
 דרך נוספת לזיהוים של מעצמים היא בחינת תוכנם של ריצפם הגנטי, משום שבהם נמצא
 כל המידע הדרוש ל-AND על מנת שיתחיל לפעול כמעצם.
 ניסויים אשר נערכו בחיות מעבדה הראו כי התא איננו זקוק למנגנון נוסף מעבר
 לרצף הגנטי על מנת לגרום לבקרת הגנים שבו.
 בשל תפישה זו, אנו מציעים גישה חישובית לזיהוי של מעצמים על בסיס ריצפם הגנטי
 בלבד, בדרך למידה לא מונחית.
 יצרנו מודל מרקוב חבוי מסדר גבוה מבוסס מטריצות משקול מיקום, בעל שני סוגי
 מצבים: מצב אחד אשר פולט אתרי קשירה של גורמי שעתוק מתוך מטריצות משקול מקום,
 ואחד אשר פולט נוקלאוטידים בודדים תוך תלות מסדר גבוה באלה שנפלטו לפניהם.
 בהשוואה למודל מרקוב חבוי רגיל, מודל זה לומד מבנה מורכב יותר של הרצף הגנטי,
 אשר מכיל מוטיבים של אתרי קשירה והתפלגות מסדר גבוה של נוקלאוטידים המצויים
 בינהם.
 אנו נבחן תחילה את הרקע הביולוגי של המעצמים, תוך התרכזות בבני אדם.
 לאחר מכן נסקור לעומק את הרקע של מודלי מרקוב חבויים, ונדון בדרך לחישוב הנראות
 )doohilekil( של רצפים בהינתן המודל.
 נתאר לפרטים את המודל המוכלל שלנו ונפתח את אלגוריתם מיקסום התוחלת )noitazimixam
 noitatcepxe( ואת אלגוריתם ויטרבי עבור מודלי מרקוב חבויים, ולאחר מכן את
 ההתאמות הנדרשות עבור המודל המוכלל שלנו.
 מימושי האלגוריתמים הללו מוצגים על ידי הפעלתם על מידע סינטטי של רצפים דמויי-מעצמ
ים אשר נוצרו תוך שימוש ביכולת הגנרטיבית של מודל המרקוב החבוי המוכלל.
 אנו מדמים למודל סביבה מבוקרת על מנת להעריך את ביצועיו בשיערוך פרמטרי המודל
 והשוואתם לפרמטרים האמיתיים בהם היה שימוש בעת יצירת המידע.
 לסיום, אנו משתמשים באלגוריתם מיקסום התוחלת על מנת לאמן את המודל שיצרנו
 על רצפים גנטיים של מעצמים אנושיים, אשר נבחרו לפי המידע האפיגנטי של פרוייקט
 pamdaoR.
 אנו מדגימים את יכולות המודל על ידי השוואת שיערוכו למידע האפיגנטי של הרצפים,
 ומביאים ראיה ליכולת המודל לחזות את מיקום המעצמים בגנום ואת הריקמה בהם יופעלו,
 ללא חשיפה מוקדמת למידע אפיגנטי.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*

\lang english
Abstract
\end_layout

\begin_layout Standard

\lang english
Enhancers are regulatory DNA sequences that, when bound to proteins called
 transcription factors, increase the likelihood of transcription of the
 enhancer target genes.
 Regulation of transcription is an important form of control of gene expression,
 and the activity of enhancers plays a significant role in the stage-specific
 and tissue-specific regulation of genes.
 It has been shown over the years that genetic variations within enhancer
 sequences might cause cell behavior modifications and diseases.
 The structural rules and nuances of enhancers are not fully understood
 yet, though it has been shown that transcription factors tend to bind to
 them at unique and over-represented motifs called transcription factor
 binding sites.
 Enhancer activity can be detected by the epigenetic data from the local
 environment around its position.
 The main indicators for an enhancer lay in the adjacent histone modifications,
 around which the flanks of the enhancer are wrapped.
 The enhancer itself tends to be spatially accessible for biochemical interactio
ns between the DNA and the proteins around it.
 Though useful, the epigenetic data are often noisy and require a costly
 extraction process of specific cells from a tissue sample, which is not
 necessarily practical for all cell types and their different stages.
 An alternative approach to enhancer detection is to observe the genetic
 content of its sequence, since it contains all the essential information
 for the DNA to act as an enhancer.
 Over the years, it was demonstrated 
\emph on
in vivo
\emph default
 that the cell requires no other mechanism than the genetic sequence in
 order to regulate its gene expression.
 With that idea in mind, in this work we offer a computational approach
 for the detection of enhancers based only on their sequences, and in an
 unsupervised manner.
 We created a higher-order positional weight matrix-based hidden Markov
 model (HOP-HMM), with two kinds of states: one which emits transcription
 factor binding sites by using a positional weight matrix model, and one
 which emits single nucleotides with high-order dependency on previously
 emitted nucleotides.
 Compared to a regular hidden Markov model, this model learns a more complex
 underlying structure of DNA sequences, containing both binding site motifs
 and high-order distribution of nucleotides in between them.
 We will first review the biological background of enhancers, specifically
 in humans.
 Then we will review in depth the background of Markov and hidden Markov
 models, and discuss how to calculate the likelihood of a sequence based
 on these models.
 We will describe our generalized model in detail and develop the expectation-ma
ximization and Viterbi algorithms for hidden Markov models, followed by
 the adjustments needed for our generalized model.
 The implementations of these algorithms are demonstrated by applying them
 to a synthetic dataset of enhancer-like sequences created by using the
 generative property of the generalized model.
 We will simulate the model in a controlled way to evaluate it by inferring
 estimated parameters of the model and comparing them to the real parameters
 used to create the dataset.
 Finally, we will apply the expectation-maximization algorithm to train
 a HOP-HMM on human enhancer sequences, which were selected  based on the
 epigenetic data of the Roadmap project.
 We demonstrate the capabilities of the model by comparing its estimation
 to the epigenetic tracks, showing it can predict both the loci of enhancers
 and the in which tissues they will be active, without exposure to epigenetic
 data.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section

\lang english
Introduction
\end_layout

\begin_layout Subsection

\lang english
Background
\end_layout

\begin_layout Standard

\lang english
The genome of every living organism contains the inherited information which
 defines its complex structure and function.
 The genome is built out of two intertwined strands of deoxyribonucleic
 acid (DNA) molecules called nucleotides, that form that form a double helical
 structure.
 Nucleotides can be one of 4 different basic bases: cytosine, guanine, adenine,
 and thymine or in short A,C,G and T respectively.
 The nucleotides are organized in pairs called base pairs, with each of
 the paired nucleotides being complementary to the other and providing redundanc
y.
 
\end_layout

\begin_layout Standard

\lang english
Proteins are macromolecules, which play various roles and functions within
 organisms.
 They have the structure of a polymer built out of 20 different amino acids,
 whose order and configuration are encoded in genes (genetic segments within
 the genome).
 Through transcription followed by translation processes, the genes are
 expressed and result in the formation of proteins.
 During the transcription process the gene is read and transcribed into
 a single strand sequence of ribonucleic acids (RNA).
 Next, the formed RNA strand, which at this stage is called messenger RNA
 (mRNA), is translated by a complex molecule called the ribosome.
 The mRNA sequence is built out of triplets of nucleotides called codons,
 which are read by the ribosome and instruct it how to generate the sequence
 of amino acids constituting the required protein.
 
\end_layout

\begin_layout Standard

\lang english
Gene sequences are composed of fragmented coding regions (exons) and noncoding
 regions (introns).
 Following its formation, the RNA molecule undergoes splicing, during which
 the introns are removed from the strand, and only the exons mature into
 mRNA molecules which are then translated into proteins.
 Counter intuitively, even though the exons hold the instructions for proteins
 formation, the complexity of the organism is not correlated to the number
 of exons or their total length in its genome.
 For example, both humans and Caenorhabditis elegans roundworms have about
 19,000 genes with roughly the same total exon length and number (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-57"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-16"

\end_inset

), despite the greater diversity and complexity of the former.
 Although the genes are responsible for the variety of proteins a cell is
 able to produce, the complexity of an organism (i.e.
 the number of different cell types specializing in different tasks) stems
 from the gene regulation mechanisms.
 In the case of humans, the genome is 3.23 Gb-long and it is estimated that
 the total length of gene-regulating regions involves 10-20% of it (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-46"

\end_inset

), compared to only 1% for exon regions (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-45"

\end_inset

).
\end_layout

\begin_layout Standard

\lang english
Enhancers are non-coding regulatory DNA sequences which play a key role
 in the regulation of gene expression.
 In humans, there are hundreds of thousands of enhancers scattered over
 the non-coding regions of the genome, usually of a length between 100-1000
 base pairs (bp).
 When the enhancer is activated, the DNA folding draws it spatially closer
 to another type of regulatory element called promoter, resulting in the
 translation of the gene adjacent to the promoter (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Transcription"

\end_inset

).
 The gene expressed by this activation process, also known as the target
 gene of the enhancer, can be located up to one megabase pair (Mb) upstream
 or downstream from its activating enhancer, since enhancers generally function
 independently of orientation (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-43"

\end_inset

).
 Moreover, the gene-enhancer connection is not exclusive, and it has been
 shown that the most common case is that each enhancer has several target
 genes and vice-versa (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-20"

\end_inset

).
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/Enhancer_gene_transcription.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Transcription"

\end_inset

The stages of the activation process of an enhancer.
 
\series bold
A)
\series default
 A distal enhancer and upstream promoter and gene, positioned on a DNA strand.
 The sequences of both the enhancer and the promoter contain multiple TFBSs.
 
\series bold
B)
\series default
 The DNA folds and recruits TFs from its surrounding environment.

\series bold
 C) 
\series default
Other cofactor proteins are recruited and form the transcription initiation
 complex, binding the two parts of the folded DNA strand to each other.
 
\series bold
D)
\series default
 The RNA Polymerase II is bound to the formed complex and starts moving
 along the gene, while generating a new RNA molecule.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent

\lang english
An enhancer is described as being in an active status when it is causing
 the expression of its target gene, which does not occur evenly across different
 types of cells.
 The activity of the enhancer sequence plays a critical role in the resulting
 type of cells.
 In a large 
\emph on
in vivo
\emph default
 enhancer assay by 
\begin_inset CommandInset citation
LatexCommand citet
key "key-60"

\end_inset

, fertilized mouse eggs were injected with enhancer sequences adjacent to
 a minimal promoter and a LacZ reporter gene, encoding an enzyme protein
 with a blue color.
 Since the injected DNA were synthesized, the enhancer, the promoter and
 the reporter gene bore no epigenetic information, and they were integrated
 into the mouse genome in an arbitrary position.
 The enhancer sequences in the injected DNA originated from the human and
 mouse genomes, and each enhancer was injected into a different mouse egg.
 When the transgenic embryos were photographed after 11.5 days some had a
 distinctive anatomical pattern, such as blue limbs or blue spine, depending
 on the injected DNA sequence.
 These results imply that for many DNA sequences, the DNA code possesses
 by itself the potential to become a specific tissue enhancer, despite the
 absence of epigenetic information.
\end_layout

\begin_layout Standard
\noindent

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/f735.jpg
	scale 13

\end_inset


\begin_inset Graphics
	filename Figures/experiment_process.png
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Mouse"

\end_inset

Transgenic mouse embryo on the 11.5 day with distinct anatomical pattern
 of enhancer activation in specific tissue types.
 In a large enhancer assay, fertilized eggs were injected 
\emph on
in vivo 
\emph default
with synthetic DNA sequences which contained an enhancer, a minimal promoter
 and a LacZ reporter gene.
 On the left, a human enhancer known to be related to neurons in the dorsal
 root of the spinal nerve became activated in these tissues and caused to
 the expression of the reporter gene that was coupled to it.
 Embryo 2 of experiment hs51, taken from the VISTA Enhancer Browser [
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://enhancer.lbl.gov/
\end_layout

\end_inset

] (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
Transcription factors (TF) are proteins that bind to the DNA, and together
 with other cofactor proteins initiate the gene transcription process of
 the DNA sequence.
 TFs tend to bind to their transcription factor binding sites (TFBS), which
 are motifs of nucleotides in the DNA sequence.
 The average length of TFBSs in humans is 12 bp (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-36"

\end_inset

), and they are highly conserved between various species (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-12"

\end_inset

).
 When analyzing a tissue sample for TF and cofactors interaction density
 with the DNA, the chromatin immunoprecipitation sequencing (ChIP-seq) method
 is used to probe the amount of proteins in affinity to the DNA strands.
 Briefly, this method involves applying antibodies on cross-linked DNA,
 which bind to the proteins linked to the DNA.
 The antibodies binding is then followed by a massive parallel sequencing
 of the short DNA strands around the TF and the bound antibody.
 A ChIP-seq assay 
\emph on
in vivo 
\emph default
by 
\begin_inset CommandInset citation
LatexCommand citet
key "key-61"

\end_inset

 has shown that ChIP-seq mapping of p300/CBP cofactors can accurately predict
 the location of enhancers.
 Genome-wide association studies (GWAS) of ChIP-seq found that different
 TFs have different and distinct distributions of TFBS (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-32"

\end_inset

).
\end_layout

\begin_layout Standard

\lang english
The TFBSs in both enhancers and promoters are critical for their correct
 regulatory activity.
 Multiple studies have shown that genetic alterations in TFBSs inside enhancers
 can affect the expression of their target genes and are a major cause of
 various human diseases (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-35"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-44"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-54"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-53"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-6"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-13"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-39"

\end_inset

).
 From the sequence aspect, enhancers and promoters have a similar structure:
 both have different nucleotide frequencies compared to other parts of the
 genome, and both contain TFBSs tiled inside background sequences.
\end_layout

\begin_layout Standard

\lang english
Folding of the DNA allows enhancer-promoter interactions, in which the TFs
 play a major part.
 Once bounded to the DNA, the TFs recruit other protein cofactors, and together
 they form a transcription preinitiation complex (PIC) consisting of a very
 large assembly of proteins.
 Out of the tens of proteins constructing the PIC, the sub-unit RNA polymerase
 (RNA pol II) has the important role of transcribing the adjacent gene.
 It slides along the double-stranded DNA and opens it until one strand of
 nucleotides is exposed and becomes a template for RNA synthesis.
\end_layout

\begin_layout Standard

\lang english
Though it is tempting to imagine each TF as having a corresponding TFBS
 with a single motif of nucleotides that fits it, modeling the kinetic and
 thermodynamic aspects involved in the DNA-protein interaction is far from
 simple (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-67"

\end_inset

).
 Each sequence of nucleotides has the likelihood to form a bond, which is
 not simple to calculate analytically.
 In order to generate a simplistic yet statistically accurate model representing
 the TF binding potential of a DNA sequence, i.e.
 
\begin_inset Formula $P\left(x_{1:n}|binding\right)$
\end_inset

, we need to assume an independence between positions, as well as a small
 range of influence of the sequence around the binding site.
 For samples of such distribution, the peaks of the ChIP-seq readings marking
 the TF binding are often used, from which a binding site “grammar” can
 be modeled.
 Position weight matrix (PWM), as introduced by 
\begin_inset CommandInset citation
LatexCommand citet
key "key-7"

\end_inset

, is the most commonly used probabilistic model to address this task.
 The underlying assumption of the PWM model is that the probability of every
 position at a TFBS is calculated independently, and therefore the total
 motif probability is a multiplication of its per-position probabilities:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(x_{1:J}|binding\right)=\prod_{j\in[n]}P\left(x_{j}|binding\right)
\]

\end_inset

Where 
\begin_inset Formula $J$
\end_inset

 is the length of the relevant sequences affected by the binding event,
 and is derived from the physical characteristics of the TF.
 Practically, this size is often estimated from the observed motifs in the
 ChIP-seq peaks of the TF.
 For each 
\begin_inset Formula $j$
\end_inset

, 
\begin_inset Formula $P\left(x_{j}|binding\right)$
\end_inset

 is estimated by counting the frequency of the nucleotides in the 
\begin_inset Formula $j$
\end_inset

’th position of the observed binding sites which are situated in the ChIP-seq
 peaks.
 For a motif of length 
\begin_inset Formula $J$
\end_inset

, the estimation of this probability distribution is stored in a PWM 
\begin_inset Formula $W$
\end_inset

 as followed: 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
W_{i,j}=\frac{1}{N}\sum_{n\in[N]}\boldsymbol{1}\left(x_{j}^{(n)}=i\right)
\]

\end_inset

where 
\begin_inset Formula $x^{(n)}$
\end_inset

 is the 
\begin_inset Formula $n$
\end_inset

’th sequence of the found binding sites, 
\begin_inset Formula $j\in[J]$
\end_inset

 the position in the motif and 
\begin_inset Formula $i\in[4]$
\end_inset

 the nucleotide index of A,C,G and T.
 To enable comparison between the binding likelihood of TFBS of different
 lengths, the use of the normalized form of PWM, the position-specific scoring
 matrix (PSSM), is more convenient:
\begin_inset Formula 
\begin{equation}
{\displaystyle M_{i,j}=\mathrm{log_{2}}\left(\frac{W_{i,j}}{b_{i}}\right)}\label{PSSM}
\end{equation}

\end_inset

where 
\begin_inset Formula $b_{i}$
\end_inset

 is the prior background model, which is 0.25 in case of nucleotides.
 From a generative model point of view, the TFBS sequence is generated by
 an emission model of the PWM.
 When a correlation is applied on 
\begin_inset Formula $M$
\end_inset

 and the one-hot encoding of the sequence (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

), the result is the log likelihood of a TF binding to a sequence relative
 to a random sequence.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/pwm_mult.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\series bold
\lang english
\begin_inset CommandInset label
LatexCommand label
name "PWM"

\end_inset


\series default
Calculation of a PWM log likelihood.
 The 2-dimensional correlation between the one-hot encoding of the DNA sequence
 and the log of the PWM matrix result in the log likelihood of the TF binding
 at every location in the sequence.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
Detection of enhancers and of the tissues in which they are active has been
 the subject of much research in the last few decades.
 Specifically, an enhancer detection method relying only on their sequences
 and without need for biological experimentation is an especially sought-after
 goal.
 Such biological experiments, some of which are mentioned in this work,
 involve cells whose enhancers would need to activate their target genes
 during the experiment, which is usually an expensive and non-trivial requiremen
t.
 All methods for detecting active enhancers “in the act” are inherently
 limited to the specific tissues we can extract and isolate in a lab.
 Furthermore, many enhancers are only active in specific cell types and
 at specific stages, and achieving a study of every cell type at every possible
 stage in complex organisms is not a practical requirement for the foreseeable
 future.
 On the other hand, the genome of organisms can be easily and inexpensively
 sequenced for later analysis 
\emph on
in silico
\emph default
.
 The ultimate goal of an efficient computational method which would predict
 and explain the functional nature of an enhancer sequence has produced
 positive, yet far from sufficient results over the last years, as reviewed
 by 
\begin_inset CommandInset citation
LatexCommand citet
key "key-33"

\end_inset

.
\end_layout

\begin_layout Standard

\lang english
As an alternative, a potential way of detecting enhancers only by addressing
 their sequences, would consist in finding non-coding regions which are
 conserved across species.
 Conserved non-coding elements (CNE) have a tendency to reside in clusters,
 which usually have low gene density but are located in vicinity to genes
 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-11"

\end_inset

).
 Evidently, the overlap between CNEs and enhancers is imprecise.
 Some verified enhancers are weakly (or not) conserved between species (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-21"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-52"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-56"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-40"

\end_inset

) and some highly conserved areas in the mouse genome are not associated
 with regulatory activity, but their deletion still yields viable mice (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-1"

\end_inset

).
 Nevertheless, an assay of over 200 bp elements with sequence identity of
 100% between human and mouse found that less than half showed enhancer
 activity in mice (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-23"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-70"

\end_inset

).
 The ultra-conservation of 200 bp enhancer sequences containing TFBSs that
 are usually shorter than 15 bp raises the possibility that these conserved
 iter-TFBS parts play a role which it is not yet fully clear.
\end_layout

\begin_layout Standard

\lang english
Almost all cells in every organism contain their entire genomic payload,
 but only part of this genome is active in any specific cell.
 Essentially, cells of different type and state differ by gene expression
 patterns.
 The reason for this difference between cells lays in regulation components
 not included in the Watson and Crick model of the DNA sequence.
 The location and presence of TFBS, background nucleotides distribution
 and other sequence-related properties are not sufficient to explain the
 regulatory role of certain regions in the genome.
 
\end_layout

\begin_layout Standard

\lang english
Several epigenetic features, correlate with enhancer regions in the genome:
 
\end_layout

\begin_layout Itemize

\lang english
Accessibility
\end_layout

\begin_layout Itemize

\lang english
TF & cofactors binding
\end_layout

\begin_layout Itemize

\lang english
Histone modifications
\end_layout

\begin_layout Itemize

\lang english
DNA methylation
\end_layout

\begin_layout Standard

\lang english
These mechanisms have measurable features that can be added as a data layer,
 on top of the genome.
 Their combination is the main source of identification and prediction for
 enhancer regions in the genome.
 Every cell has its own epigenetic features at any element of the genome,
 often in binary form (e.g.
 it is either accessible or not, methylated or not).
 When the epigenetic properties of several cells are measured, a frequency
 or count of the measured features per DNA locus is usually calculated along
 the reference genome (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "GenomeBrowser"

\end_inset

).
 The epigenetic data are commonly further processed by calculating their
 p-value compared to a local environment, to which peak boundaries are determine
d (peak calling) using algorithms such as MACS2 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-73"

\end_inset

).
\end_layout

\begin_layout Standard

\lang english
In eukaryotes, the DNA is packed around a structure of 8 histone proteins
 called a nucleosome, forming together a chromatin complex.
 Similarly to the TFs, the nucleosome binding location in the DNA sequence
 is not arbitrary.
 Like them, it has a tendency for specific DNA binding sites (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-9"

\end_inset

).
 The DNA wrapped around a nucleosome has a lesser likelihood of interaction
 with proteins, because it is physically inaccessible.
 Accessibility enables the TFs and other proteins to bind to the DNA molecule,
 hence the enhancer, the promoter and the gene all need to be accessible
 for a successful transcription to occur.
 DNase-I hypersensitive (DHS) sites are regions of the DNA which are sensitive
 to cleavage by the DNase-I enzyme.
 In these regions the DNA loses the nucleosome, and becomes accessible and
 therefore potentially active.
 Measurement of DHS cleavages is available through DNase-seq (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-71"

\end_inset

), a high-throughput method for measuring the accessibility epigenetic data
 of the DNA, usually with a better resolution than histone modifications
 measurements.
 A faster and more sensitive technique for accessibility measurement is
 called ATAC-seq (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-70"

\end_inset

), and is currently more commonly used.
 
\end_layout

\begin_layout Standard

\lang english
Histone modifications, also called histone marks or chromatin modifications,
 are chemical alterations which happen to the long tail-like section of
 the histone protein.
 Histones are numbered from 1 to 8, and for example, the acetylation of
 the lysine amino-acid situated in 14th position in the protein of the 3rd
 histone is abbreviated as H3K14ac.
 Along many roles in the cell, such as DNA repair and mitosis, histone modificat
ions have a function in the gene regulation processes.
 In the past 20 years, a substantial body of research has shown that histone
 modifications are predictive of enhancer position and activity status (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-60"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-19"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-18"

\end_inset

).
 The histone modifications are considered to form a certain 
\begin_inset Quotes eld
\end_inset

histone code” along the genome, which encodes complex information underlying
 the genomic code and is connected to transcription regulation and other
 aspects.
 Compared to other epigenetic information, chromatin modifications have
 a shorter time scale ranging from seconds to hours (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-25"

\end_inset

), and are therefore considered as being related to the dynamic changes
 of the cell.
\end_layout

\begin_layout Standard

\lang english
Measurement of histone modifications is also performed using the ChIP-seq
 method, similarly to the TF binding detection described above.
 In histone ChIP-seq, antibodies bind to the modifications in the histone
 tails (and not to the TF proteins).
 H3K4me1 and H3K27ac are among the predominant histone modifications of
 active enhancers; H3K4me1 is enriched on transcribed genes and enhancers
 prior to activation (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-34"

\end_inset

), and is thought to precede the H3K27ac modification (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-51"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-62"

\end_inset

) which is known to occur during activation.
 Other histone modifications present on active enhancers and used for their
 detection are H3K9ac (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-15"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-30"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-62"

\end_inset

) and H3K18ac (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-28"

\end_inset

).
 Even though H3K27ac has been identified as an important marker for the
 differentiation of active enhancers from poised enhancers (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

), it is not sufficient by itself since when present alongside H3K4me3 it
 is also an indication for active promoters (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-26"

\end_inset

).
 In contrast, absence of H3K27ac and enrichment of H3K4me1 and H3K27me3
 are typical of poised enhancers (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-8"

\end_inset

).
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/Enhancers_status.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Enhancer"

\end_inset

The accessibility of the enhancer and its surrounding histone modifications
 are connected to its regulatory activity state.
 The upper diagram shows an active enhancer sequence accessible to the protein
 interaction needed for transcription, whereas the lower one shows an inactive
 enhancer wrapped around a nucleosome and therefore inaccessible.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
DNA methylation of cytosine nucleotides and cytosine guanine nucleotides
 pairs (CpG) has been involved in long-term genome silencing in multiple
 processes (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-29"

\end_inset

) and in cell aging (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-48"

\end_inset

).
 It has been documented as widely correlated with inhibition of gene expression
 when present in promoters (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-3"

\end_inset

).
 In enhancer elements, an anti-correlation was found between DNA methylation
 density and enrichment of active enhancer histone modifications, and TF
 binding (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-55"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-58"

\end_inset

), although the causes and consequences relationships underlying these correlati
ons are not yet clear.
 Currently, the most accurate method for wide-scale prediction of the loci
 of enhancer sequences in a genome is the analysis of histone modifications,
 and TF and cofactors presence using ChIP-seq from a cell line or from a
 tissue, combined with DNase-I hypersensitivity (DHS).
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/genome_browser.png
	scale 40

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "GenomeBrowser"

\end_inset

UCSC Genome Browser showing epigenetic features of the 10th chromosome of
 a H1-hESC cell line.
 Highlighted in light blue, the peaks of H3K27ac (1st green plot) and H3K4me1
 (2nd green plot) histone modifications and the DNase-I hypersensitivity
 features (4th green plot), together with the absence of H3K27me3 (3rd green
 plot) signal indicate an active enhancer, as also marked by the ChromHMM
 classification (bottom).
 Note that the decrease between the two peaks of H3K27ac and H3K4me1 is
 located on top of the increase of the DNase-I hypersensitivity, which implies
 a cleavage between two histone modifications.
 Taken from [
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://genome-euro.ucsc.edu/cgi-bin/hgTracks
\end_layout

\end_inset

].
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\lang english
Related Work
\end_layout

\begin_layout Standard

\lang english
The advent of automated DNA sequencing techniques in the 1990s, caused a
 surge of genomic databases, with the most notable Human Genome Project
 among them.
 This great increase of available data led to the development of many computatio
nal methods for the analysis of genetic sequences.
 The main focus of research of these years was on the prediction of genes
 location, expression and structure using techniques such as hidden Markov
 model (HMM), decision trees, and dynamic programming as reviewed by 
\begin_inset CommandInset citation
LatexCommand citet
key "key-69"

\end_inset

.
 In the 2000s new techniques for sequence-based high-resolution, genome-scale
 emerged and resulted in large epigenetic datasets that contributed to the
 understanding of gene regulation and other interactions between the genome
 and its environment.
 In the last few years, several significant computational efforts were made
 for the prediction of the epigenetic and regulatory properties of DNA elements
 based on the genetic sequence alone.
 DeepSEA (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-63"

\end_inset

) used a deep convolutional neural network (DCNN) which receives an input
 of 1000 bp sequence, and outputs a prediction vector of 919 binary features
 representing the chromatin modifications of 200 bp in the center of the
 input sequence.
 The training labels used were the chromatin modifications extracted from
 ENCODE and Roadmap epigenetic data releases.
 Basset (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-31"

\end_inset

) also used DCNN on the same data, with known PWMs as weight initialization,
 to predict a binary vector representing accessibility in 164 cell types,
 based on 600 bp DNA sequences.
 In DeepBind (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-2"

\end_inset

) a DCNN was used to predict binding of 538 TFs and 194 RNA binding proteins
 from DNA sequences of varying lengths, based on data from 
\emph on
in vitro
\emph default
 assays.
 In gkm-SVM (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-5"

\end_inset

), gapped 
\emph on
k
\emph default
-mers presence indicator vectors were used as features for a SVM classifier
 in order to predict the p300 ChIP-seq signal of DNA sequences of varying
 lengths.
 ChromHMM (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-14"

\end_inset

) is a widely used software which tackles the problem of analyzing the epigeneti
c data to predict the role of fragments of genomic sequence.
 The algorithm converts the input data of chromatin modification values
 to a binary form by whether or not they exceed a defined threshold.
 The binary input is then inserted to an HMM that classifies the genome
 states.
 The disadvantage of these methods is their need for training data of known
 regulatory elements or epigenetic data which are commonly obtained from
 GWAS surveys, such as those that were done on 127 obtained human cell types
 in the Roadmap and ENCODE projects (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-37"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-15"

\end_inset

).
 
\end_layout

\begin_layout Standard

\lang english
When a DNA sequence is read from a tissue sample, it is often stored as
 a sequence of the characters A,C,G and T in FASTA format.
 For an algorithm to process it, these characters are mapped into a data
 structure of integers 1,2,3 and 4 respectively.
 For many algorithms, such as in DeepSEA, Basset, and our HOP-HMM, it is
 preferable to encode these sequences of integers as a sequence of one-hot
 vectors (also called indicator vectors), as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

.
 A commonly used feature extraction technique of DNA sequences is to represent
 them as vectors of their in-sequence 
\emph on
k
\emph default
-mer frequencies as used in gkm-SVM.
 In this technique, the order of the 
\emph on
k
\emph default
-mer is sacrificed for a more meaning-oriented, structured and fixed-length
 data encoding, similarly to the bag of words technique in text analysis
 and natural language processing.
 
\end_layout

\begin_layout Subsection

\lang english
Classification of Sequences
\end_layout

\begin_layout Standard

\lang english
The goal of machine learning classification models is to arrive from the
 observed 
\begin_inset Formula $X$
\end_inset

 to its label 
\begin_inset Formula $Y$
\end_inset

.
 In the DNA classification case discussed in this work, the goal is to decide
 the role 
\begin_inset Formula $Y$
\end_inset

 of a DNA sequence 
\begin_inset Formula $X$
\end_inset

.
 There are two main approaches to this goal: generative models and discriminativ
e models.
 Both approaches assume observed variables 
\begin_inset Formula $X$
\end_inset

 and target variables 
\begin_inset Formula $Y$
\end_inset

, also commonly referred to as data samples and labels.
 
\end_layout

\begin_layout Itemize

\lang english
Generative models assume a joint probability 
\begin_inset Formula $P\left(X,Y\right)$
\end_inset

.
 Using dataset of 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 pairs, one can estimate the distribution 
\begin_inset Formula $P\left(X,Y\right)$
\end_inset

, then estimate 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

.
 The distinctive feature of these models is their ability to generate random
 instances of the data, either as pairs of 
\begin_inset Formula $\left(x,y\right)$
\end_inset

 or as instances of 
\begin_inset Formula $x$
\end_inset

 given 
\begin_inset Formula $y$
\end_inset

.
\end_layout

\begin_layout Itemize

\lang english
Discriminative models assume a conditional probability 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

, which is estimated directly from the dataset.
\end_layout

\begin_layout Standard

\lang english
Both models eventually base their classifications upon the 
\begin_inset Formula $P\left(Y|X\right)$
\end_inset

 estimation.
 Namely, classifying a data sample 
\begin_inset Formula $x$
\end_inset

 by the most likely label: 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
y_{est}=argmax_{y}P\left(Y=y|X=x\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Discriminative models are more widely used than generative models, and they
 are often easier to use and build since they require fewer assumptions
 on the origin and generation of the data.
 For instance, the deep neural network (DNN) is a model that has gained
 much interest lately in the machine learning field, and has also been used
 for the task of DNA sequences classification.
 As a discriminative model it assumes very little regarding the way the
 DNA sequence is generated based on its role, but instead finds features
 in the sequence which imply its role.
 Hence it is often difficult to use such a model for later understanding
 of the nature of the data generation process, or to generate new data from
 it.
 
\end_layout

\begin_layout Standard

\lang english
Markov model (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-42"

\end_inset

), named after the Russian mathematician Andrey Markov, is a stochastic
 model which is applied to a system that changes randomly, such as the weather
 or car traffic.
 This model is at one of 
\begin_inset Formula $m$
\end_inset

 states 
\begin_inset Formula $\left\{ S_{1},...,S_{m}\right\} $
\end_inset

 at any time, with the first state being sampled from a distribution 
\begin_inset Formula $\pi_{i}=P\left(y_{1}=S_{i}\right)$
\end_inset

 and the probability distribution of transitions between the states being
 denoted by 
\begin_inset Formula $T_{i,j}=P\left(y_{t}=S_{i}|y_{t-1}=S_{j}\right)$
\end_inset

.
 The travel of the model over the states is named a Markov process, and
 the sequence of the states visited in the process is called a Markov chain.
 
\begin_inset Newline newline
\end_inset


\begin_inset Newpage newpage
\end_inset

The likelihood of a Markov chain 
\begin_inset Formula $X$
\end_inset

 generated by a Markov Model 
\begin_inset Formula $\theta=\{\pi,T\}$
\end_inset

 is a joint probability of the first state and of all following transitions
 which, due to the independence between transition events, can be written
 as:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\mathcal{L}\left(\theta;X\right)=P\left(x_{0},x_{1},...,x_{L};\theta\right)=\pi_{x_{0}}\cdot T_{x_{0},x_{1}}\cdot T_{x_{1},x_{2}}\cdot...\cdot T_{x_{L-1},x_{L}}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/Markov_model.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Markov"

\end_inset

Makrov model and 
\series bold
A)
\series default
 Markov model with 3 states (a, b and c).
 
\series bold
B,C)
\series default
 The model starts with a state sampled from 
\begin_inset Formula $π$
\end_inset

, and travels between the states with a transition distribution 
\begin_inset Formula $T$
\end_inset

.
 
\series bold
D)
\series default
 The model can generate Markov chains of states, where the transition between
 the states is only conditioned by the previous state, causing the Markov
 process to be memoryless.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
The HMM is a Markov model extension which models a system that travels over
 hidden states as a Markov process, and while doing so emits variables called
 observed variables.
 Like the Markov model, HMM is a generative model, and therefore assumes
 the existence of a joint probability 
\begin_inset Formula $P\left(x_{1:L},y_{1:L}\right)$
\end_inset

 derived from the compact parameters 
\begin_inset Formula $\theta$
\end_inset

.
 HMM relies on the assumption that the observed DNA sequence 
\begin_inset Formula $X=x_{1},...,x_{L}$
\end_inset

 is generated by a parameterized model 
\begin_inset Formula $\theta$
\end_inset

, and has a hidden sequence 
\begin_inset Formula $Y=y_{1},...,y_{L}$
\end_inset

 that was generated alongside it.
 In this generation process, a single observed variable is emitted for every
 step of the model, and thus the observed sequence is generated with the
 same length as the hidden Markov chain.
 For an alphabet of variables 
\begin_inset Formula $\left\{ V_{1},...,V_{n}\right\} ,$
\end_inset

 and hidden state space 
\begin_inset Formula $\left\{ S_{1},...,S_{m}\right\} $
\end_inset

, the observed variable 
\begin_inset Formula $x_{t}$
\end_inset

 is sampled from an emission distribution conditioned on the hidden state
 of the model 
\begin_inset Formula $E_{i,j}=P\left(x_{t}=V_{j}|y_{t}=S_{i}\right)$
\end_inset

.
 Similarly to the Markov model, the distribution to the first hidden state
 is marked as 
\begin_inset Formula $\pi$
\end_inset

 and the transition distribution is marked as 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HMM_two_states.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "HMM"

\end_inset

HMM with 2 hidden states.

\series bold
 A,B)
\series default
 The observed variables (dark blue) are emitted by the hidden state at their
 location, sampled from the discrete conditional distribution 
\begin_inset Formula $E$
\end_inset

.
 
\series bold
C,D)
\series default
 The hidden states (yellow and green) behave as Markov model states with
 starting and transition probabilities 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $T$
\end_inset

.
 
\series bold
E)
\series default
 The output of the model is an observable sequence with an underlying hidden
 sequence.
 The hidden sequence is a Markov chain, where the hidden state emits a single
 observed variable on each step.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
HMM is a very popular signal processing algorithm that has been adopted
 in the various fields of computational biology since the 1980s.
 HMM was proposed by Leonard Baum (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-4"

\end_inset

) and is used for modeling regions with alternating frequencies of patterns
 and symbols.
 In a non-biological context, it was used extensively in various engineering
 fields, especially in speech recognition (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-49"

\end_inset

), handwriting recognition (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-27"

\end_inset

) and digital communication (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-59"

\end_inset

).
\end_layout

\begin_layout Standard

\lang english
For example, in the case of an observable DNA sequence, a simplistic model
 can assume that the sequence is composed of 4 states: genes, promoters,
 enhancers and background regions.
 Each of these states would have a different nucleotide frequency, and we
 assume that the DNA sequence was generated by an HMM with underlying sequences
 of 4 hidden states, one for each region type.
 The emitted DNA sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

 is determined by the underlying hidden sequence 
\begin_inset Formula $y_{1:L}$
\end_inset

 which describes the 
\begin_inset Quotes eld
\end_inset

mode” of the sequence for each location.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\lang english
Having an HMM with 
\begin_inset Formula $θ$
\end_inset

 on hand and given an observed sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

, two questions arise:
\end_layout

\begin_layout Itemize

\lang english
What is the likelihood that 
\begin_inset Formula $x_{1:L}$
\end_inset

 was generated by the HMM with parameters 
\begin_inset Formula $\theta$
\end_inset

 or 
\begin_inset Formula $P\left(x_{1:L};\theta\right)$
\end_inset

?
\end_layout

\begin_layout Itemize

\lang english
What is the probability of a hidden state at every location or 
\begin_inset Formula $P\left(y_{t}=j|x_{1:L};\theta\right)$
\end_inset

?
\end_layout

\begin_layout Standard

\lang english
The two above-mentioned probabilities are named the likelihood function
 and the posterior probabilities of HMM.
 As in many generative models, HMM likelihood function 
\begin_inset Formula $\mathcal{L}\left(\theta|x_{1:L}\right)$
\end_inset

 relating to the first question can be split by the total probability law
 to the sum of all possible hidden sequences: 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
\mathcal{L}\left(\theta;x_{1:L}\right)=P\left(x_{1:L};\theta\right)=\sum_{y_{1:L}\in\left[m\right]^{L}}P\left(x_{1:L},y_{1:L};\theta\right)\label{Likelihoods}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
The probability 
\begin_inset Formula $P\left(x_{1:L};\theta\right)$
\end_inset

 is called the incomplete data likelihood function and the probability 
\begin_inset Formula $P\left(x_{1:L},y_{1:L};\theta\right)$
\end_inset

 is called the complete-data likelihood function.
 
\begin_inset Newpage newpage
\end_inset

In the case of HMM with parameters 
\begin_inset Formula $\theta$
\end_inset

, the complete-data can be calculated by:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
P\left(x_{1:L},y_{1:L};\theta\right)=P\left(y_{1};\theta\right)\cdot P\left(x_{1}|y_{1};\theta\right)\cdot\prod_{i=2}^{N}P\left(y_{i}|y_{i-1};\theta\right)\cdot P\left(x_{i}|y_{i};\theta\right)=\pi_{y_{1}}E_{y_{1},x_{1}}\prod_{i=2}^{L}T_{y_{i-1},y_{i}}E_{y_{i},x_{i}}\label{Complete-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
Although the computation of the complete-data likelihood of 
\begin_inset Formula $\theta$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Complete-Likelihood"

\end_inset

 is linear-by-L, naively computing the incomplete data likelihood as in
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Likelihoods"

\end_inset

 involves the summation of all possible hidden sequences, an impracticable
 exponential-by-L operation.
 A dynamic programming approach to overcome this gap uses the Markovian
 memorylessness of HMM, and answers both the likelihood and the posterior
 questions raised above.
 This approach is called the forward-backward algorithm: it was suggested
 as a step in the Baum-Welch algorithm (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-4"

\end_inset

), which is an expectation-maximization (EM) algorithm used to find an unknown
 
\begin_inset Formula $θ$
\end_inset

 given an observed sequence, and will be described further in a later section.
 In the forward-backward algorithm, two matrices of size 
\begin_inset Formula $m × L$
\end_inset

 are calculated, holding the probabilities:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=j,x_{1:t};\theta\right)
\]

\end_inset


\begin_inset Formula 
\[
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=j;\theta\right)
\]

\end_inset


\end_layout

\begin_layout Subsection

\lang english
Forward Algorithm
\end_layout

\begin_layout Standard

\lang english
The forward probabilities matrix 
\begin_inset Formula $\alpha$
\end_inset

 holds the probability that a sequence 
\begin_inset Formula $x_{1:t}$
\end_inset

 was emitted and that the hidden sequence ended with the state 
\begin_inset Formula $j$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=j,x_{1:t};\theta\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
It is calculated by the dynamic programming:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Forward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[2,...,L]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,t}=\sum_{j'\in[m]}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset

The building of the table is based on the HMM basic assumptions that each
 hidden state 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent only on the previous one 
\begin_inset Formula $y_{t-1}$
\end_inset

 and that each observed variable 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent only on the hidden state that emitted it, 
\begin_inset Formula $y_{t}$
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=j,x_{1:t};\theta\right)=P\left(x_{t}|y_{t}=j,x_{1:t-1};\theta\right)\cdot P\left(y_{t}=j,x_{1:t-1};\theta\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{t}|y_{t}=j;\theta\right)\cdot\sum_{j'\in[m]}P\left(y_{t}=j|y_{t-1}=j';\theta\right)\cdot P\left(y_{t-1}=j',x_{1:t-1};\theta\right)=
\]

\end_inset


\begin_inset Formula 
\[
=E_{j,x_{t}}\cdot\sum_{j'\in[m]}T_{j',j}\cdot\alpha_{j',t-1}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HMM forward Algorithm.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "ForwAlg"

\end_inset

The forward algorithm calculations.
 The probability stored in 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 is calculated with the 
\begin_inset Formula $\alpha_{j',t-1}$
\end_inset

 values of the previous steps.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\lang english
Backward Algorithm
\end_layout

\begin_layout Standard

\lang english
The backward probabilities matrix 
\begin_inset Formula $β$
\end_inset

 holds the probability that a sequence 
\begin_inset Formula $x_{t+1:L}$
\end_inset

 was emitted given the hidden state at position 
\begin_inset Formula $t$
\end_inset

 had value 
\begin_inset Formula $j$
\end_inset

: 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=j;\theta\right)\label{eq:BackwardProp}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
It is calculated by the dynamic algorithm:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Backward Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{1:m,L}=1$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[L-1,...,1]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{j,t}=\sum_{j'\in[m]}\beta_{j',t+1}\cdot T_{j,j'}\cdot E_{j',x_{t}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
This matrix building process is similarly explained by:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=j;\theta\right)=\sum_{j'\in[m]}P\left(y_{t+1}=j',x_{t+1:L}|y_{t}=j;\theta\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\sum_{j'\in[m]}P\left(x_{t+2:L}|y_{t+1}=j';\theta\right)\cdot P\left(x_{t+1}|y_{t+1}=j';\theta\right)\cdot P\left(y_{t+1}=j'|y_{t}=j;\theta\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\sum_{j'\in[m]}\beta_{j',t+1}\cdot E_{j',x_{t+1}}\cdot T_{j,j'}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HMM backward Algorithm.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "BackAlg"

\end_inset

The backward algorithm calculations.
 The probability stored in 
\begin_inset Formula $\beta_{j,t}$
\end_inset

 is calculated with the 
\begin_inset Formula $\beta_{j',t+1}$
\end_inset

 values of the previous steps.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
Once 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 probabilities are obtained, the incomplete data likelihood of HMM can be
 easily calculated:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
P\left(x_{1:L};\theta\right)=\sum_{j\in[m]}P\left(y_{L}=j,x_{1:L};\theta\right)=\sum_{j\in[m]}\alpha_{j,L}\label{Incomplete-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
And so can the posterior probability:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(y_{t}=j|x_{1:L};\theta\right)=\frac{P\left(y_{t}=j,x_{1:L};\theta\right)}{P\left(x_{1:L};\theta\right)}=\frac{P\left(y_{t}=j,x_{1:t};\theta\right)\cdot P\left(x_{t+1:L}|y_{t}=j;\theta\right)}{P\left(x_{1:L};\theta\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{P\left(x_{1:L};\theta\right)}
\]

\end_inset


\end_layout

\begin_layout Subsection

\lang english
Generalized HMM
\end_layout

\begin_layout Standard

\lang english
Although HMM is simple and efficient, applying it to DNA sequences has a
 major inherited disadvantage: the Markovian lack of memory property.
 The next state of the model always depends only on the previous state,
 without further historical consideration.
 For the task of emitting a TFBS motif where each position has a different
 emission distribution depending on the location in the motif, an HMM would
 need to differentiate multiple hidden states according to their positions
 in the motif.
 This means that for an HMM to be able to emit even a small number of short
 motifs, it needs to hold a large number of states which require learning
 a large number of parameters, e.g.
 for the ability to emit 50 motifs of length 5, an HMM would need to have
 over 60,000 parameters (
\begin_inset Formula $50\times5$
\end_inset

 states and 
\begin_inset Formula $\left(50\times5\right)^{2}$
\end_inset

 transitions).
 Furthermore, the enhancer modeling task at hand is even more complex, since
 we wish to model multiple enhancers and backgrounds states, each having
 a different probability of emitting motifs and an unique k-order emission
 distribution when not in these motifs.
 For the prior assumption of our data structure, the required number of
 model parameters would have been about 
\begin_inset Formula $10^{7}$
\end_inset

, large enough to generate problems such as unfeasible memory complexity
 and overfitting.
 
\end_layout

\begin_layout Standard

\lang english
A common way to avoid overfitting the data when training machine learning
 models is to reduce the complexity of the model by fixing some of its parameter
s.
 Our proposed HOP-HMM addresses both the memory issue and the overfitting
 issue, while remaining equivalent to a regular HMM with a large number
 of states having fixed parameters.
 Namely, most of the transition probabilities are fixed to zero and therefore
 never stored in the memory, and some of the emission probabilities are
 predetermined and remain fixed during the training.
 This allows us to train a model with the enhancer prior assumptions of
 motifs and high-order emission, without overfitting and with reasonable
 memory complexity.
 
\end_layout

\begin_layout Standard

\lang english
In a generalized HMM (GHMM), the transition or the emission are sampled
 from a different distribution type assigned to each of the states in the
 model.
 Some of the states in the system may emit zero or multiple observable variables
, sampled from custom emission models specifically tailored for the expected
 scenario.
 Such models were used for gene prediction in the 1990s (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-24"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-22"

\end_inset

), in which specific exon states emitted codons instead of single nucleotides,
 and feed forward neural networks were used to evaluate the probability
 of certain transitions.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/sHMM_two_states.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "GHMM"

\end_inset

GHMM that can emit TFBSs as described by 
\begin_inset CommandInset citation
LatexCommand citet
key "key-64"

\end_inset

 
\series bold
A)
\series default
 The GHMM contains a TF state which emits a motif using a PWM.
 The model has one background hidden state (yellow) and one TF hidden state.
 
\series bold
B,C,D)
\series default
 Although the TF state emits motifs with 5 bp, the rest of the emissions,
 transitions and start probabilities remain the same as in a regular HMM.
 
\series bold
E)
\series default
 An example output generated from the model, showing the TFBS motif sampled
 in an arbitrary location inside a sequence.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
Another generalization made to the HMM and called high-order HMM uses conditiona
l distribution by making the transition and emission dependent on previous
 hidden states (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-17"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-41"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-47"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-38"

\end_inset

).
 Although these HMM variants are capable of expressing a more complex structure
 of DNA sequence (different 
\emph on
k
\emph default
-mers frequencies in the genomic regions), the number of parameters required
 for DNA analysis tends to rise with the increase of the assumed complexity
 of the DNA structure.
 The increase of hidden states needed may introduce overfitting in the learning
 process, when the data size is limited.
 
\end_layout

\begin_layout Standard

\lang english
Instead of high-order emission which depends on the previous hidden states,
 the less researched field of high-order emission depending on previously
 emitted observable variables was used.
 Such an HMM variant is better suited to the local span nature of the emission
 of 
\emph on
k
\emph default
-mer structures, but it only requires 
\begin_inset Formula $O\left(m^{2}+4^{k}\right)$
\end_inset

 parameters compared to 
\begin_inset Formula $O$
\end_inset

 
\begin_inset Formula $\left(m^{k}\right)$
\end_inset

 parameters that would have been required for holding a 
\emph on
k
\emph default
-mer distribution in a regular HMM, where 
\begin_inset Formula $m$
\end_inset

 is the number of hidden states of the HOP-HMM, and 
\begin_inset Formula $k$
\end_inset

 is the number of previous states in the dependency.
 
\end_layout

\begin_layout Subsection

\lang english
HOP-HMM
\end_layout

\begin_layout Standard

\lang english
HOP-HMM is a GHMM well adapted to the structure of enhancers containing
 TFBSs, due to the TFBS emitting TF states that take part in the generation
 process of the sequence.
 In view of the assumed local physical nature of the TF binding of DNA sequences
 and of the success of HMM in gene prediction, we think the memorylessness
 of HMMs fits well the task of enhancer prediction.
 HOP-HMM balances between the Markovian memorylessness and the observed
 
\emph on
k
\emph default
-mer of the TFBS present in regulatory regions in the DNA.
 
\end_layout

\begin_layout Standard

\lang english
HOP-HMM extends the GHMM of 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-64"

\end_inset

, where some of the hidden states emit TFBS sampled from PWMs in order to
 predict enhancer locations in the genome.
 In HOP-HMM we added a high-order conditional emission probability distribution
 to the background states.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HOP_HMM_two_states.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM1"

\end_inset

Small HOP-HMM
\series bold
 
\series default
with two states.
 
\series bold
A)
\series default
 The model has one background state that emits single nucleotides and one
 TF state that emits a TFBS and return to the background state.
 
\series bold
B)
\series default
 The background state has second-order emission, meaning its emission probabilit
y distribution is conditioned on the previous nucleotide.
 
\series bold
C,D)
\series default
 Unlike GHMM, in HOP-HMM a TF state cannot transition into itself and cannot
 be the starting hidden state and the background state.
 
\series bold
E)
\series default
 The TF state emits multiple observable variables that represent a TFBS
 sampled from a PWM.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/Transition_repack.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "TGCompact"

\end_inset

Compact form pf HOP-HMM for holding the transition probability distributions.
 Instead of holding a single sparse 8
\begin_inset Formula $\times$
\end_inset

8 transition matrix, we hold only the non-fixed transition probabilities,
 split into 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

 matrices.
 The non-fixed transition probabilities held in the compact form are those
 between background states, and between background states to their TF states
 (outlined with blue).
 The concatenation of a row in 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

 holds the probability distribution of the next hidden state given the current
 background state.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HOP_HMM_multi_states.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\series bold
\lang english
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM2"

\end_inset

A)
\series default
 A more complex HOP-HMM with two background states 
\begin_inset Formula $BG_{1}$
\end_inset

 and 
\begin_inset Formula $BG_{2}$
\end_inset

, where each has three TF states.
 
\series bold
B) 
\series default
Each of the background states has its own second-order emission distribution
 in a 
\begin_inset Formula $4\times4$
\end_inset

 matrix.
 
\series bold
C)
\series default
 The start hidden state distribution 
\begin_inset Formula $π$
\end_inset

 allows only background states to start the hidden sequence.
 
\series bold
D)
\series default
 The transition probability distribution is held by matrices 
\begin_inset Formula $T$
\end_inset

 and G.
 
\series bold
E)
\series default
 The example-generated sequence is built out of two types of sequences,
 each with its own TFBS frequency and background nucleotide bigram frequency,
 representing two alternating types of enhancers.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset

We use two indices to describe a hidden state in HOP-HMM: 
\end_layout

\begin_layout Itemize

\lang english
background states are indexed as 
\begin_inset Formula $(j,0)$
\end_inset

 where 
\begin_inset Formula $j\in[m]$
\end_inset

, and 
\begin_inset Formula $m$
\end_inset

 is the number of background states.
\end_layout

\begin_layout Itemize

\lang english
TF states are indexed as 
\begin_inset Formula $(j,l)$
\end_inset

 where 
\begin_inset Formula $j\in[m]$
\end_inset

, 
\begin_inset Formula $l\in[k]$
\end_inset

, and 
\begin_inset Formula $k$
\end_inset

 is the number of TF states which are associated to each of the background
 states.
\end_layout

\begin_layout Standard

\lang english
For example, in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM2"

\end_inset

 we see a HOP-HMM with 
\begin_inset Formula $m=2$
\end_inset

 and 
\begin_inset Formula $k=3$
\end_inset

 and a total of 8 hidden states (
\begin_inset Formula $2+3\times2$
\end_inset

).
 The TF state 
\begin_inset Formula $(j,l)$
\end_inset

 belongs to the 
\begin_inset Formula $(j,0)$
\end_inset

 background state (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM3"

\end_inset

), and the only allowed transfer into 
\begin_inset Formula $(j, l)$
\end_inset

 is from its background state 
\begin_inset Formula $(j,0)$
\end_inset

.
 Note that we used a simpler 
\begin_inset Formula $BG_{j}$
\end_inset

 notation in figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM1"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "HOPHMM2"

\end_inset

 for readability.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HOP_HMM_general_mk.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\shape italic
\emph on
\lang english
\begin_inset CommandInset label
LatexCommand label
name "HOPHMM3"

\end_inset

General hidden states graph of HOP-HMM.
 Each row represents a sequence type, where each of the 
\begin_inset Formula $m$
\end_inset

 background states (yellow) has 
\begin_inset Formula $k$
\end_inset


\shape default
\emph default
 TF state
\shape italic
\emph on
s (green).
 Not all transitions are possible: moving between the rows is possible only
 through a background-to-background state transition.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
While most background states 
\begin_inset Formula $(j,0)$
\end_inset

 represent an enhancer type, we also wish to model true background regions
 between enhancers, which carry no regulatory role and have no TFBSs.
 To that end, we predefine one or more background states as non-enhancers
 by restricting their transfer probability into their TF states, as seen
 in the results section.
 
\end_layout

\begin_layout Standard

\lang english
HOP-HMM is defined with 
\begin_inset Formula $k$
\end_inset

 PWMs 
\begin_inset Formula $W_{1},W_{2},...,W_{k}$
\end_inset

 that remain fixed during training.
 Each of the 
\begin_inset Formula $k$
\end_inset

 PWMs is shared with 
\begin_inset Formula $m$
\end_inset

 TF states, e.g.
 the PWM 
\begin_inset Formula $W_{l}$
\end_inset

, where 
\begin_inset Formula $l\in[k]$
\end_inset

 is shared between subs-states 
\begin_inset Formula $(1,l),(2,l),...,(m,l)$
\end_inset

 and is used for the TF state emission sampling.
 The PWMs vary in their column amounts (as the different TFBSs vary in length),
 and each column represents a nucleotide distribution at that position.
 When the model enters a TF state, it emits a motif by sampling independently
 from a PWM column by column, as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "GHMM"

\end_inset

.
\end_layout

\begin_layout Standard

\lang english
The background states, denoted as 
\begin_inset Formula $(1,0),(2,0),...,(m,0)$
\end_inset

, are responsible for the emission of inter-TFBS parts of the enhancers
 lacking long motifs.
 Similarly to regular states in HMM, background states emit single nucleotides
 whose emission is conditional on the previous nucleotides emitted in the
 DNA sequence.
 The emission from background states is performed by sampling a nucleotide
 from the distributions stored in 
\begin_inset Formula $E$
\end_inset

 array.
 
\begin_inset Formula $E$
\end_inset

 dimension is 
\begin_inset Formula $o+1$
\end_inset

, its size is 
\begin_inset Formula $\text{ }m\times4\times4\times...\times4$
\end_inset

 (with 
\begin_inset Formula $o$
\end_inset

 fours) and its values describe the emission probability distribution 
\begin_inset Formula $E_{j,x_{t-o+1},x_{t-o+2},...,x_{t}}=P\left(x_{t}|y_{t}=(j,0),x_{t-o+1},...,x_{t-1}\right)$
\end_inset

, meaning that when 
\begin_inset Formula $x_{t}$
\end_inset

 is sampled by the model, the preceding 
\begin_inset Formula $o-1$
\end_inset

 observed variables are used as indices of the array to obtain the emission
 probability distribution vector 
\begin_inset Formula $E_{j,x_{t-o+1},x_{t-o+2},...,x_{t-1},*}$
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
For the first variables emitted in the sequence, the missing dimensions
 of the preceding variables are summed to form the probability distribution
 vector, e.g.
 at position 
\begin_inset Formula $t=o-1$
\end_inset

, a single variable is missing to emit 
\begin_inset Formula $x_{t}$
\end_inset

 and the probability vector that is used instead for the emission is 
\begin_inset Formula $\sum_{i\in[4]}\frac{E_{j,i,x_{1},...,x_{t-1}}}{4}$
\end_inset

.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\lang english
In HOP-HMM, the first hidden state in a sequence can only be a background
 state.
 As in HMM, the first background state is chosen by sampling from 
\begin_inset Formula $\pi,$
\end_inset

 a probability vector 
\begin_inset Formula $\pi_{j}=P\left(y_{1}=(j,0)\right)$
\end_inset

.
 Once in a background state, the model can only transit into a small subset
 of states, and since most of the possible transitions are not allowed,
 a single transition matrix from all states to all states would be sparse.
 Instead, as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "TGCompact"

\end_inset

, we only hold the possible transition probabilities in two matrices, representi
ng the two types of allowed transitions: 
\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $T$
\end_inset

 is a 
\begin_inset Formula $m\times m$
\end_inset

 matrix for background-to-background state transitions 
\begin_inset Formula 
\[
T_{j_{1},j_{2}}=P\left(y_{t+1}=(j_{2},0)|y_{t}=(j_{1},0)\right)
\]

\end_inset


\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $G$
\end_inset

 is a 
\begin_inset Formula $m\times k$
\end_inset

 matrix for background-to-TF state transitions 
\begin_inset Formula 
\[
G_{j,l}=P\left(y_{t+1:t+|W_{l}|}=(j,l)|y_{t}=(j,0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
When in a background state, after its observable variable emission the model
 samples its next hidden state from a probability vector which is composed
 of the concatenation of the row in 
\begin_inset Formula $T$
\end_inset

 and the row in 
\begin_inset Formula $G$
\end_inset

, both rows are of the index of the background state.
 If the next hidden state is chosen to be a TF state, it emits its TFBS
 from the PWM associated with the TF state.
 After that, the model will return back to the preceding background state,
 which will emit another observable variable and so on.
\end_layout

\begin_layout Section

\lang english
Methods
\end_layout

\begin_layout Subsection

\lang english
Baum-Welch Algorithm
\end_layout

\begin_layout Standard

\lang english
When fitting an HMM to a DNA sequence, we seek the parameters 
\begin_inset Formula $\text{\hat{\theta}}$
\end_inset

 that best explain the sequence via an algorithm called Baum-Welch algorithm,
 which is a specific case of EM algorithm.
 Formally, given the observed DNA sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

, we would like to find the parameters that maximize the incomplete data
 likelihood: 
\begin_inset Formula 
\[
\hat{\theta}=argmax_{\theta}\mathcal{L}\left(\theta|x_{1:L}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Even though the incomplete data likelihood of HMM in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Likelihoods"

\end_inset

 is derivable by 
\begin_inset Formula $\theta$
\end_inset

, optimizing it is as difficult as calculating it, and is therefore impractical.
 Instead, the strategy of the EM algorithm is to iteratively optimize the
 expected value of the complete data log-likelihood 
\begin_inset Formula $log\left(P\left(x_{1:L},y_{1:L}|\theta^{'}\right)\right)$
\end_inset

 over all possible 
\begin_inset Formula $y_{1:L}$
\end_inset

 where 
\begin_inset Formula $\theta^{'}$
\end_inset

 is the model parameters from the previous EM iteration (or guessed parameters
 in the first iteration) and while assuming a fixed observed 
\begin_inset Formula $x_{1:L}$
\end_inset

, as it is in the given DNA sequence.
 For this task, we define our target function Q:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
Q\left(\theta,\theta^{'}\right)=E_{Y}\left[log\left(P\left(X,Y;\theta\right)\right)|X=x_{1:L},\theta^{'}\right]=\sum_{y_{1:L}\in\left[m\right]^{L}}log\left(P\left(x_{1:L},y_{1:L};\theta\right)\right)\cdot P\left(x_{1:L},y_{1:L};\theta^{'}\right)\label{Q}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
Here 
\begin_inset Formula $E$
\end_inset

 is expressing an expected value, not to be confused with the HMM emission
 probability distribution.
 Every EM iteration is built out of two parts called the 
\begin_inset Formula $E$
\end_inset

 (expectation) step and the 
\begin_inset Formula $M$
\end_inset

 (maximization) step.
 In the E-step we calculate the probabilities needed for the maximization
 of 
\begin_inset Formula $Q$
\end_inset

 and in the M-step we infer the 
\begin_inset Formula $\theta$
\end_inset

 that maximizes it.
 We will update 
\begin_inset Formula $\theta$
\end_inset

 to the maximum of 
\begin_inset Formula $Q\left(\theta,\theta^{'}\right)$
\end_inset

 in every M-step of the EM algorithm until convergence.
 
\end_layout

\begin_layout Standard

\lang english
Using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Complete-Likelihood"

\end_inset

 we will split the Q function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Q"

\end_inset

 into three independent parts:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
Q\left(\theta,\theta^{'}\right)=\sum_{y_{1:L}\in\left[m\right]^{L}}log\pi_{y_{1}}\cdot P\left(x_{1:L},y_{1:L};\theta^{'}\right)+
\]

\end_inset


\begin_inset Formula 
\[
+\sum_{y_{1:L}\in\left[m\right]^{L}}\left(\sum_{t\in2...L}logT_{y_{t-1},y_{t}}\right)\cdot P\left(x_{1:L},y_{1:L};\theta^{'}\right)+\sum_{y_{1:L}\in\left[m\right]^{L}}\left(\sum_{t\in[L]}logE_{y_{t},x_{t}}\right)\cdot P\left(x_{1:L},y_{1:L};\theta^{'}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Then by manipulating the summation, the exponential hidden sequence summation
 could be simplified with the law of total probability to:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
Q\left(\theta,\theta^{'}\right)=\sum_{j\in[m]}log\pi_{j}\cdot P\left(x_{1:L},y_{1}=j;\theta^{'}\right)+
\]

\end_inset


\begin_inset Formula 
\[
+\sum_{t\in2...L}\sum_{j_{1},j_{2}\in[m]}logT_{j_{1},j_{2}}\cdot P\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2};\theta^{'}\right)+\sum_{t\in[L]}\sum_{j\in[m]}logE_{j,x_{t}}\cdot P\left(x_{1:L},y_{t}=j;\theta^{'}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\lang english
Each of the three parts above is a set of constraint linear functions that
 could be derived and maximized independently using Lagrange multipliers,
 and under the following probability distribution constraints: 
\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $\sum_{j\in[m]}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $\sum_{j_{2}\in[m]}T_{j_{1},j_{2}}=1$
\end_inset

 for all 
\begin_inset Formula $j_{1}\in[m]$
\end_inset


\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $\sum_{b\in[n]}E_{j,b}=1$
\end_inset

 for all 
\begin_inset Formula $j\in[n]$
\end_inset


\end_layout

\begin_layout Standard

\lang english
where 
\begin_inset Formula $m$
\end_inset

 is the number of different hidden states and 
\begin_inset Formula $n$
\end_inset

 is the number of different observed variables (4 in our case of DNA).
\end_layout

\begin_layout Standard

\lang english
First, we start with maximizing the first 
\begin_inset Formula $\pi$
\end_inset

 part using Lagrange multiplier 
\begin_inset Formula $\lambda$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\frac{\partial}{\partial\pi_{j}}\left(\sum_{j'\in[m]}log\pi_{j'}P\left(x_{1:L},y_{1}=j';\theta^{'}\right)+\lambda\left(1-\sum_{j'\in[m]}\pi_{j'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
we derive the term and get 
\begin_inset Formula $\frac{P\left(x_{1:L},y_{1}=j;\theta^{'}\right)}{\pi_{j}}=\lambda$
\end_inset

 for 
\begin_inset Formula $j\in[m]$
\end_inset

.
 Then we use these 
\begin_inset Formula $m$
\end_inset

 equations to get 
\begin_inset Formula $\lambda=P\left(x_{1:L};\theta^{'}\right)$
\end_inset

, which yields the reestimated 
\begin_inset Formula $\pi_{j}$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
\pi_{j}=\frac{P\left(x_{1:L},y_{1}=j;\theta^{'}\right)}{P\left(x_{1:L};\theta^{'}\right)}=P\left(y_{1}=j|x_{1:L};\theta^{'}\right)\label{Pi-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
Then, we define a Lagrange multiplier 
\begin_inset Formula $\lambda_{j_{1}}$
\end_inset

 for each 
\begin_inset Formula $j_{1}\in[m]$
\end_inset

 for the 
\begin_inset Formula $T$
\end_inset

 part:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\frac{\partial}{\partial T_{j_{1},j_{2}}}\left(\sum_{t\in2...L}logT_{j_{1},j_{2}}\cdot P\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2};\theta^{'}\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
which yields 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2};\theta^{'}\right)}{T_{j_{1},j_{2}}}$
\end_inset

 for 
\begin_inset Formula $j_{2}\in[m]$
\end_inset

 
\end_layout

\begin_layout Standard

\lang english
and when all 
\begin_inset Formula $m$
\end_inset

 equations are summed, gives 
\begin_inset Formula $\lambda_{j_{1}}=\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=j_{1};\theta^{'}\right)$
\end_inset

 
\end_layout

\begin_layout Standard

\lang english
Therefore the update of 
\begin_inset Formula $T_{j_{1},j_{2}}$
\end_inset

 will be:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
T_{j_{1},j_{2}}=\frac{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=j_{1},y_{t}=j_{2};\theta^{'}\right)}{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=j_{1};\theta^{'}\right)}=\frac{\sum_{t\in2...L}P\left(y_{t-1}=j_{1},y_{t}=j_{2}|x_{1:L};\theta^{'}\right)}{\sum_{t\in2...L}P\left(y_{t-1}=j_{1}|x_{1:L};\theta^{'}\right)}\label{T-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
Finally, we will define a Lagrange multiplier 
\begin_inset Formula $\lambda_{j}$
\end_inset

 for every 
\begin_inset Formula $j\in[m]$
\end_inset

 for the 
\begin_inset Formula $E$
\end_inset

 part:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\frac{\partial}{\partial E_{j,b}}\left(\sum_{t\in[L]}logE_{j,x_{t}}\cdot P\left(x_{1:L},y_{t}=j;\theta^{'}\right)+\lambda_{j}\left(1-\sum_{b'\in[n]}E_{j,b'}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
This step is slightly trickier due to the derivation of 
\begin_inset Formula $\frac{\partial E_{j,x_{t}}}{\partial E_{j,b}}=\boldsymbol{1}_{b}(x_{t})$
\end_inset

 where 
\begin_inset Formula $\boldsymbol{1}_{b}(x_{t})=\begin{cases}
1 & b=x_{t}\\
0 & otherwise
\end{cases}$
\end_inset

.
\end_layout

\begin_layout Standard

\lang english
We get 
\begin_inset Formula $\lambda_{j}=\frac{\sum_{t\in[L]}P\left(x_{1:L},y_{t}=j;\theta^{'}\right)\cdot\boldsymbol{1}_{b}(x_{t})}{E_{j,b}}$
\end_inset

 for 
\begin_inset Formula $b\in[n]$
\end_inset

 
\end_layout

\begin_layout Standard

\lang english
and when all 
\begin_inset Formula $n$
\end_inset

 equations are summed, gives 
\begin_inset Formula $\lambda_{j}=\sum_{t\in[L]}P\left(x_{1:L},y_{t}=j;\theta^{'}\right)\cdot\boldsymbol{1}_{b}(x_{t})$
\end_inset

 
\end_layout

\begin_layout Standard

\lang english
Therefore the update of 
\begin_inset Formula $E_{j,b}$
\end_inset

 will be:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
E_{j,b}=\frac{\sum_{t\in[L]}P\left(x_{1:L},y_{t}=j;\theta^{'}\right)\boldsymbol{\cdot1}_{b}(x_{t})}{\sum_{t\in[L]}P\left(x_{1:L},y_{t}=j;\theta^{'}\right)}=\frac{\sum_{t\in[L]}P\left(y_{t}=j|x_{1:L};\theta^{'}\right)\boldsymbol{1}_{b}(x_{t})}{\sum_{t\in[L]}P\left(y_{t}=j|x_{1:L};\theta^{'}\right)}\label{E-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
In order to be able to calculate these reestimations of 
\begin_inset Formula $\theta$
\end_inset

 as written in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "E-Update"

\end_inset

, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
we still need to calculate the two probability terms they contain.
 To resemble the notations coined in 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-50"

\end_inset

, the first widely accepted HMM application, we will denote these as 
\begin_inset Formula $\gamma$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
\gamma_{t,j}=P\left(y_{t}=j|x_{1:L};\theta^{'}\right)\label{gamma}
\end{equation}

\end_inset

 
\begin_inset Formula 
\begin{equation}
\xi_{t,j_{1},j_{2}}=P\left(y_{t-1}=j_{1},y_{t}=j_{2}|x_{1:L};\theta^{'}\right)\label{xi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
We will use 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Incomplete-Likelihood"

\end_inset

 and the output of the forward-backward algorithm 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 for their calculation:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\gamma_{t,j}=\frac{P\left(y_{t}=j,x_{1:L};\theta^{'}\right)}{P\left(x_{1:L};\theta^{'}\right)}=\frac{P\left(x_{1:L}|y_{t}=j;\theta^{'}\right)\cdot P\left(y_{t}=j;\theta^{'}\right)}{P\left(x_{1:L};\theta^{'}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{P\left(y_{t}=j,x_{1:t};\theta^{'}\right)\cdot P\left(x_{t+1:L}|y_{t}=j;\theta^{'}\right)}{P\left(x_{1:L};\theta^{'}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{\sum_{j\in[m]}\alpha_{j,L}}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\xi_{t,j_{1},j_{2}}=\frac{P\left(y_{t-1}=j_{1},y_{t]}=j_{2},x_{1:L}\right)}{P\left(x_{1:L};\theta^{'}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{P\left(y_{t-1}=j_{1},x_{1:t-1};\theta^{'}\right)\cdot P\left(y_{t}=j_{2}|y_{t-1}=j_{1};\theta^{'}\right)\cdot P\left(x_{t}|y_{t}=j_{2};\theta^{'}\right)\cdot P\left(x_{t+1:L}|y_{t}=j_{2};\theta^{'}\right)}{P\left(x_{1:L};\theta^{'}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2},}\cdot E_{j_{2},x_{t}}\cdot\beta_{j',t}}{\sum_{j\in[m]}\alpha_{j,L}}
\]

\end_inset

The calculation of 
\begin_inset Formula $\alpha,\beta,\gamma$
\end_inset

 and 
\begin_inset Formula $\xi$
\end_inset

 matrices is considered the E-step of the Baum-Welch algorithm and allows
 us to update 
\begin_inset Formula $\theta$
\end_inset

 in the M-step and finish the EM iteration.
\end_layout

\begin_layout Subsection

\lang english
Baum-Welch Algorithm Adaptation
\end_layout

\begin_layout Standard

\lang english
The transition and emission mechanisms of HOP-HMM are different and therefore
 the complete data likelihood of HOP-HMM requires a different calculation
 for the Baum-Welch algorithm to hold.
 The Baum-Welch algorithm can be adjusted to infer the parameters of the
 HOP-HMM variant 
\begin_inset Formula $\theta=\{\pi,E,G,T\}$
\end_inset

 from a DNA sequence 
\begin_inset Formula $X$
\end_inset

.
 As in the regular Baum-Welch algorithm covered in the previous section,
 given a sequence 
\begin_inset Formula $X$
\end_inset

 at each EM iteration we optimize the Q function in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Q"

\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{align*}
Q\left(\theta,\theta^{'}\right)= & \sum_{j\in[m]}log\pi_{j}\cdot P\left(x_{1:L},y_{1}=(j,0);\theta^{'}\right)\\
+ & \sum_{t\in2...L}\sum_{j_{1},j_{2}\in[m]}logT_{j_{1},j_{2}}\cdot P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0);\theta^{'}\right)\\
+ & \sum_{t\in2...L}\sum_{j\in[m],l\in[k]}logG_{j,l}\cdot P\left(x_{1:L},y_{t-1}=(j,0),y_{t}=(j,l);\theta^{'}\right)\\
+ & \sum_{t\in o,...,L}\sum_{j\in[m]}logE_{j,b_{1},...,x_{t}}\cdot P\left(x_{1:L},y_{t}=(j,0);\theta^{'}\right)\\
+ & \sum_{t\in[L]}\sum_{l\in[k]}log\mathcal{L}\left(W_{l};x_{t:t+|W_{l}|-1}\right)\cdot P\left(x_{1:L},y_{t:t+|W_{l}|-1S}=(j,l);\theta^{'}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\lang english
where 
\begin_inset Formula $\mathcal{L}\left(W;\overline{x}\right)$
\end_inset

 is the likelihood of the TFBS 
\begin_inset Formula $\overline{x}$
\end_inset

 to be emitted by PWM 
\begin_inset Formula $W$
\end_inset

: 
\begin_inset Formula $\mathcal{L}\left(W;\overline{x}\right)=P\left(\overline{x};W\right)=\underset{i\in\{1,...,|\overline{x}|\}}{\prod}W_{\overline{x}_{i},i}$
\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
Note that the last addition component, which holds the TFBS log likelihood,
 does not contain elements from  
\begin_inset Formula $θ$
\end_inset

 since the PWMs are not learned in HOP-HMM and thus is not reestimated in
 the M-steps.
 
\end_layout

\begin_layout Standard

\lang english
Similarly to the process we covered in the regular EM, the 
\begin_inset Formula $\theta$
\end_inset

 which optimizes 
\begin_inset Formula $Q(\theta,\theta')$
\end_inset

 is achieved by optimizing its 3 independent parts, each with its own constraint
 under which we optimize 
\begin_inset Formula $Q$
\end_inset

 are:
\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $\sum_{j\in[m]}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $\sum_{j_{2}\in[m]}T_{j_{1},j_{2}}+\sum_{l\in[k]}G_{j_{1}l}=1$
\end_inset

 for all 
\begin_inset Formula $j_{1}\in[m]$
\end_inset


\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $\sum_{b_{o}\in[n]}E_{j,b_{1},...,b_{o}}=1$
\end_inset

 for all 
\begin_inset Formula $j\in[n]$
\end_inset


\end_layout

\begin_layout Subsubsection

\lang english
M-step
\end_layout

\begin_layout Standard

\lang english
The 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $E$
\end_inset

 conditions produce a very similar maximization as in the regular Baum-Welch
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Pi-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "E-Update"

\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
\pi_{j}=\frac{P\left(x_{1:L},y_{1}=(j,0)|\theta^{'};\theta^{'}\right)}{P\left(x_{1:L}|\theta^{'};\theta^{'}\right)}=P\left(y_{1}=(j,0)|x_{1:L};\theta^{'}\right)\label{HOP-Pi-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
E_{j,b_{1},...,b_{o}}=\frac{\sum_{t\in o,...,L}P\left(x_{1:L},y_{t}=(j,0);\theta^{'}\right)\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1,...,t})}{\sum_{t\in o,...,L}P\left(x_{1:L},y_{t}=(j,0);\theta^{'}\right)}\label{HOP-E-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
As for the second condition of 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

, we will define the Lagrange multipliers 
\begin_inset Formula $\lambda_{j_{1}}$
\end_inset

 for 
\begin_inset Formula $j_{1}\in[m]$
\end_inset

 and derive the two terms that contain 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\frac{\partial}{\partial T_{j_{1,}j_{2}}}\left(\sum_{t\in2...L}logT_{j_{1},j_{2}}\cdot P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0);\theta^{'}\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}-\sum_{l\in[k]}G_{j_{1}l}\right)\right)=0
\]

\end_inset


\begin_inset Formula 
\[
\frac{\partial}{\partial G_{j_{1},l}}\left(\sum_{t\in2...L}logG_{j_{1},l}\cdot P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l);\theta^{'}\right)+\lambda_{j_{1}}\left(1-\sum_{j'\in[m]}T_{j_{1},j'}-\sum_{l\in[k]}G_{j_{1}l}\right)\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
which yields 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0);\theta^{'}\right)}{T_{j_{1},j_{2}}}$
\end_inset

 and 
\begin_inset Formula $\lambda_{j_{1}}=\frac{\sum_{t\in2...L}\cdot P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l);\theta^{'}\right)}{G_{j_{1}l}}$
\end_inset

 
\end_layout

\begin_layout Standard

\lang english
for 
\begin_inset Formula $j_{2}\in[m]$
\end_inset

 and 
\begin_inset Formula $l\in[k]$
\end_inset

.
 When the 
\begin_inset Formula $m+k$
\end_inset

 equations are summed we receive:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\lambda_{j_{1}}=\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0);\theta^{'}\right)+\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{1},l);\theta^{'}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j_{1},0);\theta^{'}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
which gives us the updates 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
T_{j_{1},j_{2}}=\frac{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0);\theta^{'}\right)}{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j_{1},0);\theta^{'}\right)}=\frac{\sum_{t\in2...L}P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L};\theta^{'}\right)}{\sum_{t\in2...L}P\left(y_{t-1}=(j_{1},0)|x_{1:L};\theta^{'}\right)}\label{HOP-T-Update}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
G_{j,l}=\frac{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j,0),y_{t}=(j,l);\theta^{'}\right)}{\sum_{t\in2...L}P\left(x_{1:L},y_{t-1}=(j,0);\theta^{'}\right)}=\frac{\sum_{t\in2...L}P\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L};\theta^{'}\right)}{\sum_{t\in2...L}P\left(y_{t-1}=(j,0)|x_{1:L};\theta^{'}\right)}\label{HOP-G-Update}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection

\lang english
E-step
\end_layout

\begin_layout Standard

\lang english
Preceding the M-step where we update components of 
\begin_inset Formula $\theta$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-E-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-G-Update"

\end_inset

, in the E-step we will calculate the three probability terms they contain,
 denoted as 
\begin_inset Formula $\gamma,$
\end_inset

 
\begin_inset Formula $\xi$
\end_inset

 and 
\begin_inset Formula $\eta$
\end_inset

:
\begin_inset Newline newline
\end_inset


\begin_inset Formula 
\begin{equation}
\gamma_{j,t}=P\left(y_{t}=(j,0)|x_{1:L};\theta^{'}\right)\label{HOP-gamma}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
\xi_{j_{1},j_{2},t}=P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L};\theta^{'}\right)\label{HOP-xi}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
\eta_{j,l,t}=P\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L};\theta^{'}\right)\label{HOP-eta}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
For the calculation of these probabilities, we first need to calculate the
 forward and backward probabilities output from a HOP-HMM adjusted forward-backw
ard algorithm.
 In the forward-backward algorithm adaptation for HOP-HMM, we will only
 build the probabilities for entering the background states since the TF
 states probabilities are not needed in the later parts of the E-step.
 The adjustments for the forward and backward algorithm evolve the new requireme
nt to support transitions into both background states and TF states.
\end_layout

\begin_layout Standard

\lang english
The forward probabilities for the HOP-HMM are:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Forward Algorithm for HOP-HMM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[2,...,L]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha_{j,t}=\underset{\text{background state transitions}}{\underbrace{\sum_{j'\in[m]}\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $+\underset{\text{TF state transitions}}{\underbrace{\sum_{l\in[k]}\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot\mathcal{L}\left(W_{l};x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
In the beginning of the sequence, when 
\begin_inset Formula $1\leq t<o$
\end_inset

, part of the preceding observable variables are missing.
 Since 
\begin_inset Formula $E$
\end_inset

 has 
\begin_inset Formula $o+1$
\end_inset

 dimensions, 
\begin_inset Formula $E_{j,x_{1},...,x_{t}}$
\end_inset

 is not defined for such locations, so we define it here as: 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
E_{j,x_{1},...,x_{t}}=\underset{b_{1},...,b_{o-t}\in\{A,C,G,T\}}{\sum}\frac{1}{4^{o-t}}\cdot E_{j,b_{1},..,.b_{o-t},x_{1},...,x_{t}}
\]

\end_inset

 
\end_layout

\begin_layout Standard

\lang english
We use the fact that 
\begin_inset Formula $P(A)=\sum_{b\in B}P(b)\cdot P(A|b)$
\end_inset

 and the assumption that the observable variables preceding the sequence
 came from a uniform distribution.
 In addition, when summing the TF state transition part, PWMs with a length
 equal or bigger than 
\begin_inset Formula $t+1$
\end_inset

 are out-of-sequence TFBSs and therefore are not part of the summation.
\end_layout

\begin_layout Standard

\lang english
The backward probabilities for the HOP-HMM are:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
The noticable difference between the backwards probabilities of HMM in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:BackwardProp"

\end_inset

 and these ones are the dependency on 
\begin_inset Formula $x_{1:t}$
\end_inset

.
 In a regular HMM, this dependency is insignificant because the emissions
 after 
\begin_inset Formula $t$
\end_inset

 are dependent on the hidden state 
\begin_inset Formula $y_{t}$
\end_inset

 and not the previous variables, meaning 
\begin_inset Formula $P\left(x_{t+1:L}|y_{t}=j,x_{1:t}\right)=P\left(x_{t+1:L}|y_{t}=j\right)$
\end_inset

.
 On the other hand, this is not the case in HOP-HMM since the emission of
 the background states is high-order and therefore has dependency on the
 previous variables.
 After describing the adjustment backward algorithm, we will show that this
 adjustment leads to the required terms of the M-step of the Baum-Welch
 algorithm.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Backward Algorithm for HOP-HMM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{1:m,L}=1$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,t=[L-1,...,1]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta_{j,t}=\underset{\text{background state transitions}}{\underbrace{\sum_{j'\in[m]}\beta_{j',t+1}\cdot E_{j',x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $+\underset{\text{TF state transitions}}{\underbrace{\sum_{l\in[k]}\beta_{j,t+|W_{l}|+1}\cdot\mathcal{L}\left(W_{l};x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t-o+|W_{l}|+2},...,x_{t+|W_{l}|+1}}\cdot G_{j,l}}}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
Note that when 
\begin_inset Formula $t>L-|W_{l}|$
\end_inset

, some observable variables are missing for the full calculation of the
 TF state transition.
 In these locations, the contribution of those components to the summation
 is zero, meaning that our HOP-HMM avoids the transition into a TF state
 at a location where the PWM is too long to fit into the sequence 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/HOP-EM forward Algorithm.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Forward-backward dynamic algorithm for HOP-HMM.
 In HOP-HMM, the  tables 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 cells are filled from both the adjacent background states transitions and
 the background states preceding or proceeding the motifs emitted by the
 TF states.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
We will now explain why the described calculations result in 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{align*}
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)\,\,\, & \beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\lang english
starting with the forward probabilities matrix 
\begin_inset Formula $\alpha$
\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
From the law of total probability, the probability 
\begin_inset Formula $\alpha_{j,t}$
\end_inset

 is the sum of probabilities of all the possible transitions that ended
 in the background state (j,0):
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\alpha_{j,t}=P\left(y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\underset{\text{background state transitions}}{\underbrace{\underset{j'\in[m]}{\sum}P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)}}+\underset{\text{TF state transitions}}{\underbrace{\underset{l\in[k]}{\sum}P\left(y_{t-|W_{l}|-1}=(j,0),y_{t-|W_{l}|:t-1}=(j,l),x_{1:t}\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
The right-side term of a TF state transition can be split with the chain
 rule to:
\end_layout

\begin_layout Standard
\paragraph_spacing single
\noindent

\lang english
\begin_inset Formula 
\[
P\left(y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
\,P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1},y_{t-|W_{l}|:t-1}=(j,l),y_{t-|W_{l}|-1}=(j,0)\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Since 
\begin_inset Formula $x_{t}$
\end_inset

 is dependent only on 
\begin_inset Formula $y_{t}$
\end_inset

 and 
\begin_inset Formula $x_{t-o:t-1}$
\end_inset

 and since 
\begin_inset Formula $y_{t}$
\end_inset

 is dependent only on 
\begin_inset Formula $y_{t-1}$
\end_inset

, we can simplify the probabilities:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(y_{t-|W_{l}|-1}=(j,0),x_{1:t-|W_{l}|-1}\right)\cdot P\left(y_{t-|W_{l}|:t-1}=(j,l)|y_{t-|W_{l}|-1}=(j,0)\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t-|W_{l}|:t-1}|y_{t-|W_{l}|:t-1}=(j,l)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{t-o:t-1}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\alpha_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot\mathcal{L}\left(W_{l};x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
This process is similar for the left-side background state transitions.
 Using the chain rule:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(y_{t-1}=(j',0),y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(x_{t}|y_{t}=(j,0),y_{t-1}=(j',0),x_{1:t-1}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(y_{t-1}=(j',0),x_{1:t-1}\right)\cdot P\left(y_{t}=(j,0)|y_{t-1}=(j',0)\right)\cdot P\left(x_{t}|y_{t}=(j,0),x_{1:t-1}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\alpha_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
For the backward probabilities 
\begin_inset Formula $\beta,$
\end_inset

 the explanation we will use the law of total probability:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\beta_{j,t}=P\left(x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\underset{\text{background state transitions}}{\underbrace{\sum_{j'\in[m]}P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)}}+
\]

\end_inset


\begin_inset Formula 
\[
+\underset{\text{TF state transitions}}{\underbrace{\sum_{l\in[k]}P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)}}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
For the background state transition term, we can use the chain rule and
 the Markovian independence of the transitions and emissions:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(y_{t+1}=(j',0),x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{t+2:L}|y_{t+1}=(j',0),y_{t}=(j,0),x_{1:t+1}\right)\cdot P\left(x_{t+1}|y_{t+1}=(j',0),y_{t}=(j,0),x_{1:t}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{t+2:L}|y_{t+1}=(j',0),x_{1:t+1}\right)\cdot P\left(x_{t+1}|y_{t+1}=(j',0),x_{1:t}\right)\cdot P\left(y_{t+1}=(j',0)|y_{t}=(j,0)\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\beta_{j',t+1}\cdot E_{j',x_{t-o+2},...,x_{t+1}}\cdot T_{j,j'}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
For the TF state transition term, we use once more the chain rule, followed
 by the simplification using the independencies of HOP-HMM:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{t+\left|W_{l}\right|+2:L}|y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0),x_{1:t+\left|W_{l}\right|+1}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0),x_{1:t+\left|W_{l}\right|}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),y_{t}=(j,0),x_{1:t}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0),x_{1:t}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{t+\left|W_{l}\right|+2:L}|y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:t+\left|W_{l}\right|+1}\right)\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0),x_{t-o+\left|W_{l}\right|+1:t+\left|W_{l}\right|}\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\cdot P\left(y_{t+1:t+\left|W_{l}\right|}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0)|y_{t}=(j,0)\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\beta_{j,t+|W_{l}|+1}\cdot E_{j,x_{t-o+|W_{l}|+1},...,x_{t+|W_{l}|+1}}\cdot\mathcal{L}\left(W_{l};x_{t+1},...,x_{t+|W_{l}|}\right)\cdot G_{j,l}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Using the forward and the backward probability matrices 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

, we can calculate two more probabilities that will help us to achieve the
 auxiliary probabilities 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
The first is a 
\begin_inset Formula $m\times k\times L$
\end_inset

 array 
\begin_inset Formula $\psi$
\end_inset

.
 We will use the chain rule several times in the first two steps, and in
 the third step we will simplify the 5 terms by the independencies of HOP-HMM:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\psi_{j,l,t}=P\left(y_{t}=(j,0),y_{t+1}=(j,l),x_{1:L}\right)=P\left(y_{t}=(j,0),y_{t+1}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:L}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(y_{t}=(j,0),y_{t+1}=(j,l),y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)\cdot P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{1:t},y_{t}=(j,0)\right)\cdot P\left(y_{t+1}=(j,l)|x_{1:t},y_{t}=(j,0)\right)\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l),x_{1:t},y_{t}=(j,0)\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|x_{t+|W_{l}|+2:L},y_{t+\left|W_{l}\right|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)\text{\cdot}P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=P\left(x_{1:t},y_{t}=(j,0)\right)\cdot P\left(y_{t+1}=(j,l)|y_{t}=(j,0)\right)\cdot P\left(x_{t+1:t+\left|W_{l}\right|}|y_{t+1:t+\left|W_{l}\right|}=(j,l)\right)\cdot
\]

\end_inset


\begin_inset Formula 
\[
\cdot P\left(x_{t+\left|W_{l}\right|+1}|y_{t+\left|W_{l}\right|+1}=(j,0)\right)\text{\cdot}P\left(x_{t+|W_{l}|+2:L}|y_{t+|W_{l}|+1}=(j,0),x_{1:t+|W_{l}|+1}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\alpha_{j,t}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1},...,x_{t+|W_{l}|}\right)\cdot E_{j,x_{t+|W_{l}|-o+2},...,x_{t+|W_{l}|+1}}\cdot\beta_{j,t+|W_{l}|+1}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
The second probability is the likelihood of the observed sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

.
 We will use the law of total probability followed by the chain rule:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(x_{1:L}\right)=\underset{j\in[m]}{\sum}\left(P\left(y_{t}=(j,0),x_{1:L}\right)+\underset{l\in\left[k\right]}{\sum}P\left(y_{t}=(j,l),x_{1:L}\right)\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\underset{j\in[m]}{\sum}\left(P\left(x_{t+1:L}|y_{t}=(j,0),x_{1:t}\right)\cdot P\left(y_{t}=(j,0),x_{1:t}\right)+\underset{l\in\left[k\right],\ t'\in\left[|W_{l}|\right]}{\sum}P\left(y_{t-t'}=(j,0),y_{t-t'+1}=(j,l),x_{1:L}\right)\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\underset{j\in[m]}{\sum}\left(\alpha_{j,t}\cdot\beta_{j,t}+\underset{l\in\left[k\right],\ t'\in\left[|W_{l}|\right]}{\sum}\psi_{j,l,t-t'}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
We will now calculate the three auxiliary probabilities.
 First is the 
\begin_inset Formula $m\times L$
\end_inset

 array 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 which holds the probability distribution of the background state at a given
 position given the sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\gamma_{j,t}=P\left(y_{t}=(j,0)|x_{1:L}\right)=\frac{P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{1:t},y_{t}=(j,0)\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{P\left(y_{t}=(j,0),x_{1:t}\right)\cdot P\left(x_{t+1:L}|x_{1:t},y_{t}=(j,0)\right)}{P\left(x_{1:L}\right)}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Second is the 
\begin_inset Formula $m\times m\times L$
\end_inset

 array 
\begin_inset Formula $\xi$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 which holds the probability distribution of the background-to-background
 state transitions given the sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\xi_{j_{1},j_{2},t}=P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)|x_{1:L}\right)=\frac{P\left(y_{t-1}=(j_{1},0),y_{t}=(j_{2},0),x_{1:L}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{P\left(x_{1:t-1},y_{t-1}=(j_{1},0),y_{t}=(j_{2},0)\right)\cdot P\left(x_{t:L}|y_{t}=(j_{2},0),x_{1:t-1}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{P\left(x_{1:t-1},y_{t-1}=(j_{1},0)\right)\cdot P\left(y_{t}=(j_{2},0)|y_{t-1}=(j_{1},0)\right)}{P\left(x_{1:L}\right)}\cdot
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\cdot\frac{P\left(x_{t}|y_{t}=(j_{2},0),x_{1:t-1}\right)\cdot P\left(x_{t+1:L}|y_{t}=(j_{2},0),x_{1:t-1}\right)}{P\left(x_{1:L}\right)}=
\]

\end_inset


\begin_inset Formula 
\[
=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+1},...,x_{t}}\cdot\beta_{j_{2},t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Finally, the 
\begin_inset Formula $m\times k\times L$
\end_inset

 array 
\begin_inset Formula $\eta$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 which holds the probability distribution for background-to-background state
 transitions given the sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

, denoted as :
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
\eta_{j,l,t}=P\left(y_{t-1}=(j,0),y_{t}=(j,l)|x_{1:L}\right)=\frac{\psi_{j,l,t}}{P\left(x_{1:L}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Now with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-xi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 at hand, we can complete the M-step and update 
\begin_inset Formula $\theta$
\end_inset

 by assigning the updates of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-Pi-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-E-Update"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-T-Update"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-G-Update"

\end_inset

.
\end_layout

\begin_layout Standard

\lang english
The iterative execution of the adjusted E-step and M-step described in this
 section concludes the adaptation of the Baum-Welch algorithm for HOP-HMM:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Baum-Welch for HOP-HMM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
X - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for s=[1...MAX_EM_ITERATIONS]:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# E-step
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\alpha=\text{hop\_forward\_algorithm(x_{1:L}) }$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\beta=\text{hop\_backward\_algorithm(x_{1:L}) }$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $l=[1,...,k]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\psi_{j,l,t}=\begin{cases}
\alpha_{j,t}\cdot G_{j,l}\cdot L_{W_{l,}}\left(x_{t+1:t+|W_{l}|}\right)\cdot E_{j,x_{t+|W_{l}|-o+2},...,x_{t+|W_{l}|+1}}\cdot\beta_{j,t+|W_{l}|+1} & |\,t+|W_{l}|+1\leq L\\
0 & |\,otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $Px=\underset{j\in[m]}{\sum}\alpha_{j,L}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\gamma_{j,t}=\frac{\alpha_{j,t}\cdot\beta_{j,t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

, 
\begin_inset Formula $l=[1,...,k]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\eta_{j,l,t}=\frac{\psi_{j,l,t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j_{1}=[1,...,m]$
\end_inset

, 
\begin_inset Formula $j_{2}=[1,...,m]$
\end_inset

, 
\begin_inset Formula $t=[1,...,L]$
\end_inset

 :
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\xi_{j_{1},j_{2},t}=\frac{\alpha_{j_{1},t-1}\cdot T_{j_{1},j_{2}}\cdot E_{j_{2},x_{t-o+1},...,x_{t}}\cdot\beta_{j_{2},t}}{Px}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# M-step
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j=[1,...,m]$
\end_inset

:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\pi_{j}=\gamma_{j,1}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $b_{1},...,b_{o}=[1,...,1]$
\end_inset

 
\begin_inset Formula $,...,[4,...,4]$
\end_inset

:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $E_{j,b_{1},b_{2},...,b_{o}}=\frac{\sum_{t\in o,...,L}\gamma_{j,t}\cdot\boldsymbol{1}_{b_{1},...,b_{o}}(x_{t-o+1},...,x_{t})}{\sum_{t\in o,...,L}\gamma_{j,t}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for  
\begin_inset Formula $l=[1,...,k]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $G_{j,l}=\frac{\underset{t\in2,...,L}{\sum}\eta_{j,l,t}}{\underset{t\in1,...,L-1}{\sum}\gamma_{j_{1},t}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

for 
\begin_inset Formula $j_{2}=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $T_{j,j_{2}}=\frac{\underset{t\in2,...,L}{\sum}\xi_{j,j_{2},t}}{\underset{t\in1,...,L-1}{\sum}\gamma_{j,t}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

If 
\begin_inset Formula $\theta$
\end_inset

 converged, break EM for loop 
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

# EM converged or stopped
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\theta$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
The Baum-Welch algorithm is described with the input of a single sequence
 of observable variables 
\begin_inset Formula $x_{1:L}$
\end_inset

.
 In reality, we are often dealing with the task of learning 
\begin_inset Formula $\hat{\theta}$
\end_inset

 from multiple sequences at once.
 In HOP-HMM we use the multi-sequence method as 
\begin_inset CommandInset citation
LatexCommand citet
key "key-50"

\end_inset

, where the E-step probabilities are calculated separately for each sequence,
 and in the M-step where positions from all sequences are summed for the
 parameters update.
\end_layout

\begin_layout Subsection

\lang english
Hidden Sequence Inference
\end_layout

\begin_layout Standard

\lang english
Acquiring the maximal likelihood estimation 
\begin_inset Formula $\hat{\theta}$
\end_inset

 from the Baum-Welch algorithm opens the door to several needed inferences
 given a sequence 
\begin_inset Formula $x_{1:L}$
\end_inset

 :
\end_layout

\begin_layout Enumerate

\lang english
Most likely hidden state at any position in a sequence
\end_layout

\begin_layout Enumerate

\lang english
Most likely hidden sequence
\end_layout

\begin_layout Enumerate

\lang english
Dominant hidden state in a short sequence
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 and 
\begin_inset Formula $\eta$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 can be used to solve inference 1 for HOP-HMM.
 Here we aim to maximize here a posterior probability in a specific position:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
y_{t}^{*}=\underset{j\in[m],l\in[k]\cup\{0\}}{argmax}P\left(y_{t}=(j,l)|x_{1:L}\right)
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
In a regular HMM, we could approximate this by taking the state with the
 maximal posterior probability from 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "gamma"

\end_inset

 built by a 
\begin_inset Formula $\hat{\theta}$
\end_inset

 that was obtained by the Baum-Welch algorithm.
 In HOP-HMM, 
\begin_inset Formula $\gamma$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-gamma"

\end_inset

 is not sufficient since it only holds the probability of being in background
 state 
\begin_inset Formula $P\left(y_{t}=(j,0)|x_{1:L};\hat{\theta}\right)$
\end_inset

.
 In order to calculate the posterior probability 
\begin_inset Formula $P\left(y_{t}=(j,l)|x_{1:L};\hat{\theta}\right)$
\end_inset

 for TF states, where 
\begin_inset Formula $l>0$
\end_inset

,  we sum all options of a TF state 
\begin_inset Formula $(j,l)$
\end_inset

 that covers position 
\begin_inset Formula $t$
\end_inset

 as described in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PWM Posterior"

\end_inset

.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
P\left(y_{t}=(j,l)|x_{1:L};\hat{\theta}\right)=\sum_{i\in\left[|W_{l}|\right]}P\left(y_{t-i+1:t-i+|W_{l}|}=(j,l)|x_{1:L};\hat{\theta}\right)=
\]

\end_inset


\begin_inset Formula 
\[
=\sum_{i\in\left[|W_{l}|\right]}P\left(y_{t-i}=(j,0),y_{t-i+1}=(j,l)|x_{1:L};\hat{\theta}\right)=\sum_{i\in\left[|W_{l}|\right]}\eta_{t-i+1,j,l}
\]

\end_inset


\end_layout

\begin_layout Standard

\lang english
Choosing the maximum value over 
\begin_inset Formula $P\left(y_{t}=(j,l)|x_{1:L};\hat{\theta}\right)$
\end_inset

 and 
\begin_inset Formula $P\left(y_{t}=(j,0)|x_{1:L};\hat{\theta}\right)$
\end_inset

 will give us the most likely state of 
\begin_inset Formula $\hat{y}_{t}$
\end_inset

:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
\hat{y}_{t}=\underset{j\in[m],l\in[k]\cup\{0\}}{argmax}\gamma_{j,t}\cup\sum_{i\in\left[|W_{l}|\right]}\eta_{t-i+1,j,l}\label{PosteriorEstimation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/PWM_posterior_2.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "PWM Posterior"

\end_inset


\begin_inset Formula $P\left(y_{t}=(j,t)|x_{1:L}\right)$
\end_inset

 is the posterior probability to be in TF state 
\begin_inset Formula $(j,l)$
\end_inset

 at position 
\begin_inset Formula $t$
\end_inset

, marked in dark green.
 It is equal to the sum of probabilities of entering into the TF state before
 position 
\begin_inset Formula $t$
\end_inset

.
 In this example, 
\begin_inset Formula $W_{l}$
\end_inset

 is a PWM of length 5, therefore it sums 5 different possible positions
 that include 
\begin_inset Formula $y_{t}$
\end_inset

, marked in light green.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
Inference 2 aims to reach the most likely hidden sequence:
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
y_{1:L}^{*}=argmax_{y_{1:L}}P\left(y_{1:L}|x_{1:L};\hat{\theta}\right)\label{Viterbi}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\lang english
The main difference with inference 1 is the consideration of the dependency
 between adjacent states.
 In inference 1, for example, two adjacent positions may be individually
 inferred states between which the transition probability equals 0.
 In such a case, even though each state maximizes the likelihood at its
 own position, the likelihood of the resulting sequence would be 0 since
 it contains an impossible transition.
 As a consequence, the requirement in inference 2 for the most likely hidden
 sequence, with the transitions inside it taken into account, could not
 be simply achieved by concatenating all the most likely states at every
 position into a sequence.
\end_layout

\begin_layout Subsection

\lang english
Viterbi Algorithm Adaptation
\end_layout

\begin_layout Standard

\lang english
In HMM, deriving the maximal likelihood hidden sequence of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "Viterbi"

\end_inset

 is done by the Viterbi algorithm, named after Andrew Viterbi who proposed
 it in 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-65"

\end_inset

.
 The Viterbi algorithm resembles the forward algorithm, with two main difference
s:
\end_layout

\begin_layout Enumerate

\lang english
Maximization replaces summation over the possible transitions.
\end_layout

\begin_layout Enumerate

\lang english
Indices of the states with the maximal likelihood are kept in the filling
 of 
\begin_inset Formula $V^{2}$
\end_inset

, and are eventually used to backtrack the chosen states in the most likely
 path.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Viterbi Algorithm
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\theta$
\end_inset

- HMM parameters 
\begin_inset Formula $\{\pi,T,E\}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{2}=0$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,t=[2,...,L]$
\end_inset

:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{1}=max_{j'\in[m]}\left(V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{2}=argmax_{j'\in[m]}\left(V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t}}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\emph on
# back tracing
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{L}=argmax_{j}V_{j,L}^{1}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
for 
\begin_inset Formula $t=[L,...,2]$
\end_inset

:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\hat{y}_{t-1}=V_{y_{t},t}^{2}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\hat{y}_{1:L}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
For HOP-HMM, the Viterbi algorithm is adapted into to HOP-HMM in two ways:
 
\end_layout

\begin_layout Itemize

\lang english
Maximization is done over two types of state transition probabilities: backgroun
d-to-background and background-to-TF, held in A and B vectors.
\end_layout

\begin_layout Itemize

\lang english
The backtracking indices held in 
\begin_inset Formula $V^{2}$
\end_inset

 tables are two indices, since states in HOP-HMM are described by two indices.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
Viterbi Algorithm for HOP-HMM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Input:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $\theta$
\end_inset

- HOP-HMM parameters 
\begin_inset Formula $\{\pi,T,G,E\}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $x_{1:L}$
\end_inset

 - Observed DNA sequence
\end_layout

\begin_layout Plain Layout

\series bold
\lang english
Algorithm:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{1}=\pi_{j}\cdot E_{j,x_{1}}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset Formula $V_{j,1}^{2}=0$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,t=[2,...,L]$
\end_inset

:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $for\,j=[1,...,m]:$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\emph on
# background-to-background state transition
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $A=\left\{ V_{j',t-1}\cdot T_{j',j}\cdot E_{j,x_{t-o+1},...,x_{t}}|j'\in[m]\right\} $
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\emph on
# background-to-TF state state transition
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $B=\left\{ V_{j,t-|W_{l}|-1}\cdot G_{j,l}\cdot\mathcal{L}\left(W_{l};x_{t-|W_{l}|},...,x_{t-1}\right)\cdot E_{j,x_{t-o+1},...,x_{t}}|l\in[k]\right\} $
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{1}=max\left(A\cup B\right)$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $V_{j,t}^{2}=\begin{cases}
\left(argmax(A),0\right) & \ensuremath{max(A)>max(B)}\\
\left(j,argmax(B)\right) & otherwise
\end{cases}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{L}=\left(argmax_{j}V_{j,L}^{1},0\right)$
\end_inset

 
\emph on
# mandatory background state at the end of the sequence
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t=L$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
while 
\begin_inset Formula $t>1$
\end_inset

:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\left(j,l\right)=V_{y_{t}[0],t}^{2}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

if 
\begin_inset Formula $l=0:$
\end_inset


\emph on
 # if 
\begin_inset Formula $l=0$
\end_inset

 the hidden state at 
\begin_inset Formula $t-1$
\end_inset

 is a background state
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{t-1}=\left(j,0\right)$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $t=t-1$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

else:
\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{t-|W_{l}|:t-1}=\left(j,l\right)$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $\hat{y}_{t-|W_{l}|-1}=\hat{y}_{t}$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

 
\begin_inset Formula $t=t-|W_{l}|-1$
\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

return 
\begin_inset Formula $\hat{y}_{1:L}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
The Viterbi algorithm outputs a sequence of hidden states, also called a
 Viterbi path, which can be used to evaluate the trained model by comparing
 it to the epigenetic data, as done in this work.
 In cases where the exact true boarders of the active element are unknown
 due to noisy data, short DNA sequences can be classified by their dominant
 states.
 We found this method useful in our preliminary evaluation of the algorithm,
 but did not include it in the results of this work.
 This simplistic classification is made by choosing the most abundant state
 in the estimated Viterbi path 
\begin_inset Formula $\hat{y}_{1:L}:$
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\[
y_{class}=mode_{t\in[L]}\hat{y}_{t}
\]

\end_inset


\end_layout

\begin_layout Section

\lang english
Results
\end_layout

\begin_layout Subsection

\lang english
Synthetic Data
\end_layout

\begin_layout Standard

\lang english
In order to evaluate HOP-HMM, we first measured its capabilities on synthetic
 DNA data that were created in a controlled way.
 We could then experiment with HOP-HMM on real human DNA sequences.
 The evaluation process on synthetic data was performed through the following
 steps (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

):
\end_layout

\begin_layout Enumerate

\lang english
We generated parameters for a HOP-HMM 
\begin_inset Formula $θ$
\end_inset

, which were treated as the true 
\begin_inset Formula $θ$
\end_inset

.
 
\begin_inset Formula $θ$
\end_inset

 was sampled in the following way:
\end_layout

\begin_deeper
\begin_layout Itemize

\lang english
Each 
\begin_inset Formula $T$
\end_inset

 cell was sampled from a uniform distribution
\begin_inset Formula 
\begin{equation}
T_{i,j}\sim U\left(minT_{i,j},maxT_{i,j}\right)\label{minTmaxT}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize

\lang english
Each cell 
\begin_inset Formula $G$
\end_inset

 cell was sampled both from a uniform and from a Bernoulli distribution
 
\begin_inset Formula 
\begin{equation}
G_{i,j}\sim U\left(minG,noiseG\right)+\boldsymbol{1}_{\left(i,0\right)\in Reg}\cdot Bern\left(\frac{k}{m}\right)\cdot maxG\label{noiseG}
\end{equation}

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard

\lang english
where 
\begin_inset Formula 
\[
\boldsymbol{1}_{\left(i,0\right)\in ENH}=\begin{cases}
1 & \left(i,0\right)\in ENH\\
0 & otherwise
\end{cases}
\]

\end_inset


\begin_inset Formula $ENH$
\end_inset

 is the set of “enhancer-mimicking” background states, which are predefined
 background states that have a high probability of transitioning into TF
 states.
 The rest of the background states will have a low probability to create
 TFBS, since we want some of the states to model sparse TFBSs (non-regulatory
 elements) surrounding the enhancers.
 In our experiments 
\begin_inset Formula $ENH$
\end_inset

 contained all but one state: 
\begin_inset Formula $\left(m,0\right)$
\end_inset

 meaning that one background state had almost no TFBS and the other 
\begin_inset Formula $m-1$
\end_inset

 background states did have TFBSs
\end_layout

\end_deeper
\begin_layout Itemize

\lang english
After being sampled, 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

 cells were divided element-wise by the sum of their rows, so that the ensemble
 of every row of 
\begin_inset Formula $T$
\end_inset

 and its corresponding row of 
\begin_inset Formula $G$
\end_inset

 became a distribution:
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{align}
T_{i,j}=\frac{T_{i,j}}{\sum_{j'\in[m]}T_{i,j'}+\sum_{j'\in[k]}G_{i,j'}} &  & G_{i,j}=\frac{G_{i,j}}{\sum_{j'\in[m]}T_{i,j'}+\sum_{j'\in[k]}G_{i,j'}}\label{GT_normalization}
\end{align}

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\lang english
\begin_inset Formula $E$
\end_inset

 was sampled from a uniform distribution 
\begin_inset Formula $E_{j,b_{1},...,b_{o}}\sim U\left(0,1\right)$
\end_inset

 and divided by the sum of its last index to become a distribution array,
 as in the previous step:
\begin_inset Formula 
\[
E_{j,b_{1},...,b_{o}}=\frac{E_{j,b_{1},...,b_{o}}}{\sum_{b'=[4]}E_{j,b_{1},...,b_{o-1},b'}}
\]

\end_inset


\end_layout

\begin_layout Itemize

\lang english
The start state distribution 
\begin_inset Formula $\pi$
\end_inset

 was non-random, and was set so that the first states were always one of
 the non-enhancer background states
\begin_inset Formula 
\[
\pi_{i}=\frac{\boldsymbol{1}_{\left(i,0\right)\notin ENH}}{m-|ENH|}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\lang english
Sequences were generated using the HOP-HMMs with the true 
\begin_inset Formula $θ$
\end_inset

.
 Both the observed and the hidden sequences were used, denoted 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

.
 We split the 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 sequences into train and test sections for cross validation.
 
\end_layout

\begin_layout Enumerate

\lang english
From the DNA sequences of 
\begin_inset Formula $X_{train}$
\end_inset

 , we trained a 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the HOP Baum-Welch algorithm.
\end_layout

\begin_layout Enumerate

\lang english
Using the trained parameters 
\begin_inset Formula $\hat{\theta}$
\end_inset

, we estimated 
\begin_inset Formula $\hat{Y}_{test}$
\end_inset

 from 
\begin_inset Formula $X_{test}$
\end_inset

 and 
\begin_inset Formula $\hat{Y}_{train}$
\end_inset

 from 
\begin_inset Formula $X_{train}$
\end_inset

 by the Viterbi algorithm adaptation to HOP-HMM.
 We also calculated the posterior probability of 
\begin_inset Formula $P\left(y_{t}|x_{1:L};\hat{\theta}\right)$
\end_inset

 from 
\begin_inset Formula $X_{test}$
\end_inset

 and 
\begin_inset Formula $X_{train}$
\end_inset

.
 These results were then compared to the real 
\begin_inset Formula $Y_{test}$
\end_inset

 and 
\begin_inset Formula $Y_{train}$
\end_inset

 to check for accuracy.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/Workflow.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Workflow"

\end_inset

Workflow of the evaluation process.
 A 
\begin_inset Formula $\theta$
\end_inset

 is sampled and a HOP-HMM is created with which several fixed-length sequences
 are generated.
 A new model 
\begin_inset Formula $\hat{\theta}$
\end_inset

 is then fitted to the train section of the observed sequences, via a Baum-Welch
 algorithm.
 With 
\begin_inset Formula $\hat{\theta},$
\end_inset

 a hidden sequence is then estimated by a Viterbi algorithm adapted for
 HOP-HMM, and a posterior probability estimation is calculated by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PosteriorEstimation"

\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset

The Baum-Welch algorithm ensures the increase of the likelihood for each
 step.
 However it does not ensure convergence to the optimal 
\begin_inset Formula $\theta^{*}$
\end_inset

 (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-50"

\end_inset

; 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-66"

\end_inset

) since there is no known analytical way to reach it.
 Consequently, the Baum-Welch algorithm converges into a local maximum 
\begin_inset Formula $\hat{\theta}$
\end_inset

 that could be a relatively low likelihood estimation, depending on the
 initialization point of the first 
\begin_inset Formula $\theta$
\end_inset

.
 During the initial evaluation of the inference EM algorithm, many runs
 converged to local maxima which tended to overshoot the inter-states transition
 probability, resulting in a tendency to irregular Viterbi paths with frequent
 state changes.
 This resembles the known issue of HMM parameter overfitting on small training
 data.
 
\end_layout

\begin_layout Standard

\lang english
We therefore addressed this issue in two ways that had a significant positive
 impact on the convergence rate and solution quality:
\end_layout

\begin_layout Enumerate

\lang english
We used regularization for faster and better 
\begin_inset Formula $\hat{\theta}$
\end_inset

 convergence (see figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization1"

\end_inset

 and  
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization2"

\end_inset

).
 Following each M-step update, we drew the background states transition
 probabilities 
\begin_inset Formula $T$
\end_inset

 to remain between 
\begin_inset Formula $maxT$
\end_inset

 and 
\begin_inset Formula $minT$
\end_inset

 matrices from 
\begin_inset CommandInset ref
LatexCommand eqref
reference "minTmaxT"

\end_inset

:
\end_layout

\begin_deeper
\begin_layout Itemize

\lang english
If 
\begin_inset Formula $T_{i,j}<minT_{i,j}$
\end_inset

 then we set 
\begin_inset Formula $T_{i,j}=minT_{i,j}$
\end_inset


\end_layout

\begin_layout Itemize

\lang english
If 
\begin_inset Formula $T_{i,j}>maxT_{i,j}$
\end_inset

 then we set 
\begin_inset Formula $T_{i,j}=maxT_{i,j}$
\end_inset


\end_layout

\begin_layout Itemize

\lang english
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

 cells were divided by the sum of their rows, so that the ensemble of their
 rows remained a distribution as in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "GT_normalization"

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\lang english
Since Baum-Welch seeks local maxima, running it multiple times with different
 initializations would cause convergence for different 
\begin_inset Formula $\hat{\theta}$
\end_inset

 results.
 As could be expected, we observed throughout multiple initializations that
 the higher the log likelihood of final 
\begin_inset Formula $\hat{\theta}$
\end_inset

, the lower its root mean square error (RMSE) compared to the true 
\begin_inset Formula $\theta$
\end_inset

 (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "LikelihoodVsErr"

\end_inset

).
 This is important since on observed real sequences only the estimated 
\begin_inset Formula $\hat{\theta}$
\end_inset

 likelihood is known, while the true 
\begin_inset Formula $θ$
\end_inset

 is unknown.
 This correlation implies that in order to obtain an estimated 
\begin_inset Formula $\hat{\theta}$
\end_inset

 as close as possible to the true 
\begin_inset Formula $\theta$
\end_inset

, one should redo several EM runs and choose the 
\begin_inset Formula $\hat{\theta}$
\end_inset

 with the highest likelihood.
 
\end_layout

\begin_layout Standard

\lang english
The experiment was done on a dataset of 500 synthetic sequences (85% train,
 15% test), all of them 1500 bp-long.
 The trained model had 5 hidden background states with an emission order
 of 3, and each background state had 25 TF states.
 The background states mean test precision was 98.5% and the mean test recall
 was 97.6%.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/rmse_vs_likelihood_m5bg1k25o3b1s0r0N3000L1000.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "LikelihoodVsErr"

\end_inset

Over multiple runs of Baum-Welch adaptation for HOP-HMM, higher sequences
 likelihood for the estimated 
\begin_inset Formula $\theta$
\end_inset

 resulted in lower errors compared to the true 
\begin_inset Formula $\theta$
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/dec_theta_error_scatter.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/dec_theta_error.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Regularization1"

\end_inset

Regularization aids the EM to converge faster and with less error compared
 to the true parameters 
\begin_inset Formula $\theta$
\end_inset

.
 
\series bold
A)
\series default
 The iterations of a single EM execution.
 The dots represent the updates of the 
\begin_inset Formula $\hat{\theta}$
\end_inset

 values during the EM iterations.
 The diagram shows that with the regularization enabled, the estimated 
\begin_inset Formula $\hat{θ}$
\end_inset

 values mostly advance toward the true value of 
\begin_inset Formula $θ$
\end_inset

.

\series bold
 B)
\series default
 The RMSE between true 
\begin_inset Formula $θ$
\end_inset

 and estimated 
\begin_inset Formula $\hat{θ}$
\end_inset

 during multiple EM executions.
 The regularization results in a significant error decrease during the EM
 iterations.
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/dec_likelihood.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/dec_viterbi.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "Regularization2"

\end_inset

 On average, the regularization causes to 
\begin_inset Formula $\hat{\theta}$
\end_inset

 estimations with higher likelihoods that produce Viterbi paths with lower
  misclassification rates.
 
\series bold
A)
\series default
 The mean log likelihood of the sequences increases until convergence during
 the EM iterations.
 With the regularization enabled, the likelihood is not always monotonous
 since with it the likelihood increase of Baum-Welch updates is no longer
 guaranteed.

\series bold
 B)
\series default
 During EM iterations, the learned 
\begin_inset Formula $\hat{θ}$
\end_inset

 values yield a more accurate Viterbi path.
 Note that not even the true 
\begin_inset Formula $θ$
\end_inset

 could produce a Viterbi path that is a perfect match to the true hidden
 sequence, as the value of the purple and yellow charts is 0.1% and not 0%.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/synthetic_posterior_with_tfs.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "PostiriorProbability"

\end_inset

Posterior probability of sequences, estimated by a trained HOP-HMM 
\begin_inset Formula $\hat{\theta}$
\end_inset

 on test dataset of sequences that were synthetically generated by a HOP-HMM
 
\begin_inset Formula $\theta$
\end_inset

.
 The Viterbi path by 
\begin_inset Formula $\hat{\theta}$
\end_inset

 and the true hidden states of each sequence are shown at the bottom of
 each posterior probability.
 The black TFBS is the sum of all the probabilities of being in any of the
 TF states.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/confusion_matrix.jpg
	scale 50

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "ConfutionMatrix"

\end_inset

Confusion matrix of true and estimated states by the Viterbi algorithm for
 synthetic sequences.
 Rows are normalized so their sum is equal to 1.
 For a smaller confusion matrix that can be easily presented, the HOP-HMMs
 in this experiment contained 5 background states and only 10 TF states.
 Similar to the experiment with the larger HOP-HMM shown in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PostiriorProbability"

\end_inset

, the majority of true and estimated states are background states, with
 the highlighted indices 
\begin_inset Formula $(1,0)$
\end_inset

, 
\begin_inset Formula $(2,0)$
\end_inset

, 
\begin_inset Formula $(3,0)$
\end_inset

, 
\begin_inset Formula $(4,0)$
\end_inset

 and 
\begin_inset Formula $(5,0)$
\end_inset

.
 Note that the Viterbi algorithm often missclassify TF states as their backgroun
d state.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection

\lang english
Human DNA Experiment
\end_layout

\begin_layout Standard

\lang english
For the testing of HOP-HMM on human genetic data, we sought to assess if
 HOP-HMM could distinguish and detect enhancers active in two human tissues.
 We created a dataset of enhancer sequences based on epigenetic data collected
 from 57 tissues by the Roadmap project.
 To choose the location of the enhancer elements, we manipulated the Roadmap
 project BED files with BEDTools (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-68"

\end_inset

).
 We chose the intersection of DNase-I, H3K27ac and H3K4me1 peaks, while
 avoiding peaks of H3K27me3 and H3K4me3, and sequences within 5000 bp from
 known genes.
 The sequences chosen were 5000 bp-long sequences from the hg19 assembly,
 centered around their DNase-I peak to ensure the flanks of the enhancer.
 Among these enhancers, we chose only sequences of tissue-specific enhancers
 in one of two types of tissues, which were selected out of the 57 tissues.
 After some trial and error, we chose the somewhat arbitrary cutoff of the
 top 40% strongest DNase-seq peaks, which yielded enough sequences (around
 500 sequences per tissue sample on average) with distinguishable distributions
 between the tissues.
 We added sequences with no known role from random locations in the genome,
 distant from genes or enhancers background sequences.
 A HOP-HMM was trained by the Baum-Welch algorithm on the collected sequences.
 The trained model was then used to produce a Viterbi estimated hidden states
 sequence and posterior probability, which could be compared to the epigenetic
 tracks.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset

For the set of PWMs used by the TF states of the HOP-HMM, we used a JASPAR
 dataset of 519 vertebrates PWMs, out of which we selected 50 PWMs for a
 practical run-time.
 The selected PWMs were chosen by three methods, each method being responsible
 for one third of these 50 PWMs: 
\end_layout

\begin_layout Itemize

\lang english
PWMs of TFs relatively expressed for one tissue compared to the other, according
 to the Roadmap RNA-seq data.
 This method does not depend on the sequences themselves, but on the epigenetic
 properties of the tissues.
\end_layout

\begin_layout Itemize

\lang english
PWMs which were abundant in the sequences, i.e.
 PWMs with the highest mean likelihood of binding to sequences.
 The average likelihood of PWM 
\begin_inset Formula $W$
\end_inset

 to bind to a sequence 
\begin_inset Formula $x$
\end_inset

 was simplified as the mean of the three highest binding likelihoods in
 the sequence, as described in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PWM"

\end_inset

.
 Note that in order to compare between PWM likelihoods we used PSSM form
 as in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "PSSM"

\end_inset

 for its length-independence property.
 
\end_layout

\begin_layout Itemize

\lang english
PWMs that had stronger presence in sequences from one tissue when compared
 to the other.
 Specifically, the PWMs with sequence binding likelihoods (as defined in
 the previous method) that could best distinguish between the sequences
 from one tissue and the sequences of the other tissues in terms of AUC-ROC.
 
\end_layout

\begin_layout Standard

\lang english
In our experiment, the posterior probability of some sequences had a good
 resemblance to the DNase-seq track, causing a good overlap between the
 Viterbi-path and the ChromHMM classifications (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RealSequences"

\end_inset

), though such similarity did not always occur.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/realSeq1.jpg
	scale 40

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/realSeq2.jpg
	scale 40

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/realSeq3.jpg
	scale 40

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\lang english
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 1
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\lang english
\begin_inset Graphics
	filename Figures/realSeqLegend.jpg
	scale 42

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\lang english
\begin_inset CommandInset label
LatexCommand label
name "fig:RealSequences"

\end_inset

Examples of HOP-HMM classification of 5000 pb-long tissue specific enhancer
 sequences from the human genome.
 Each of the three graphs is the output of a different HOP-HMM with three
 background states (two enhancer states and one non-enhancer state) and
 50 TF states, and each was trained on enhancers from the two chosen tissues.
 H3K27ac and DNase-I measurements are in 
\begin_inset Formula $-log_{10}(p-value)$
\end_inset

 units.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section

\lang english
Discussion and Conclusions
\end_layout

\begin_layout Standard

\lang english
In this work we aimed to develop a generalized HMM, HOP-HMM, tailored for
 the enhancer structure.
 We developed the mathematical adjustments to the different parts of the
 EM algorithm and provided reasoning for the correctness of inferring the
 altered model from the data.
 We also implemented a model and an algorithm in Matlab code for the evaluation
 on real or synthetic data, as described in the results.
 During the algorithm implementation, we overcame a few difficulties originating
 from the scale of the data, such as caching the costly response of the
 PWMs to the sequences during the forward-backward algorithms, and splitting
 sequences into batches in order to hold and manipulate the large 
\begin_inset Formula $\eta$
\end_inset

 
\begin_inset CommandInset ref
LatexCommand eqref
reference "HOP-eta"

\end_inset

 array in the memory.
 The implementation also included a code for generating DNA sequences from
 a randomly selected HOP-HMM to which a different model could be fitted
 and compared.
 Naturally, in the synthetic data experiment, the larger the generated dataset
 that is used to fit the model the better the performance of the fitting.
 Overall, the generated DNA sequences experiment results were positive and
 provided evidence for the ability of the algorithm to train successfully
 on DNA sequences created under our HOP-HMM assumptions.
\end_layout

\begin_layout Standard

\lang english
Like in other machine learning challenges, comparison to the state-of-the-art
 (SOTA) of regulatory sequences prediction model is not straight forward.
 Several softwares accurately predict epigenetic features of DNA sequences:
 gkm-SVM by 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-5"

\end_inset

, DeepBind by 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-2"

\end_inset

, DeepSEA by 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-63"

\end_inset

 and Basset by 
\begin_inset CommandInset citation
LatexCommand citealp
key "key-31"

\end_inset

, while each of them approach the task with different datasets and definition
 to the problem.
 Among these softwares, DeepSEA seems the most comprehensive since it was
 trained on all the human genome and since it predicts the most epigenetic
 features for multiple cell types.
 Though all of these softwares extract substantial information about how
 sequences determine their epigenetic, they are all based on a model that
 define the problem as supervised learning task.
 Using a model that defines the problem as an unsupervised learning task
 (such as ours) holds the potential to annotate whole genome 
\emph on
de novo
\emph default
 without the need for epigenetic data of extracted cells.
\end_layout

\begin_layout Standard

\lang english
The implementation of the HOP-HMM for this work was done in Matlab, and
 its run-time and memory requirements for training a significant parts of
 the human genome are intractable (several days for each EM iteration).
 In order to assess the ability of the model to detect real human enhancers
 on a smaller subset of the data, we have created a dataset of tissue-specific
 enhancers from two tissues and non-regulatory “background” sequences whose
 locations were deducted from epigenetic data of the Roadmap project.
 Though some of these sequences were correctly classified by the trained
 model, no tested pair of tissues had a classification with consistent similarit
y to its epigenetic data, and surely didn't surpass the results of DeepSEA.
 We have found that some of the tissues had many enhancers that were are
 well classified though no good classifications could be found for the rest.
 Over all, the small scale of experiment we executed is not sufficient to
 determine if the model could accurately predict enhancer sequences from
 the human genome.
 The causes for the mixed results of the human genome experiment compared
 to the positive results of the generated synthetic data experiment might
 origin from one of two reasons: the EM algorithm did not converge toward
 good enough parameters, or no such parameters existed in the HOP-HMM hypothesis
 space.
\end_layout

\begin_layout Standard

\lang english
As for the former possibility, the experiments done with our generated data
 showed a tradeoff between the amount of data provided to the EM algorithm,
 and its ability to converge toward parameters that could detect the difference
 between background states holding similar emission distributions (
\begin_inset Formula $E$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

) in the generating HOP-HMM parameters.
 In other words, convergence of the EM to low quality local maxima mainly
 occurred when the emission distributions in the generating parameters were
 not significantly different.
 This tradeoff is common in the machine learning field, as the ability of
 many models to distinguish between similar classes depends on the amount
 of relevant samples in the training dataset (
\begin_inset CommandInset citation
LatexCommand citealp
key "key-75"

\end_inset

).
 In our dataset of human enhancers, most tissues had only several hundreds
 of enhancer sequences, which might have been insufficient for a high quality
 convergence of the EM algorithm.
 
\end_layout

\begin_layout Standard

\lang english
As for the latter possibility, this could mean that the spanned solution
 space of the HOP-HMM assumption does not match our human enhancers dataset.
 This could stem from several reasons: wrong PWMs selection as hyperparameters,
 too small or noisy dataset building from the Roadmap data, and even a more
 complex enhancer structure than assumed by the HOP-HMM hypothesis.
 
\end_layout

\begin_layout Standard

\lang english
In further research, the use of updated data with cleaner experiments and/or
 more tissue diversity would be likely to provide better results.
 Even without new data, a more efficient implementation of the algorithms
 would allow executing it on more significant parts of the genome in reasonable
 time, which might result in better classifications.
 Improvements to HOP-HMM which should be tried in the future include the
 introduction of learning to the PWMs preceding or during EM iterations,
 or the entire replacement of the PWMs emissions by a different TFBS modeling
 method.
 
\end_layout

\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section

\lang english
Appendix: Source Code
\end_layout

\begin_layout Standard

\lang english
The code for this research was written in Matlab, and can be found in 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/David-Taub/HOP-HMM
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard

\lang english
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="2">
<features tabularvalignment="middle">
<column alignment="left" valignment="top">
<column alignment="left" valignment="top" width="10cm">
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Variable
\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Meaning
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
L
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
DNA sequences length
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
N
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Number of DNA sequences
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
m
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Number of background states
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
k
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Number of TF states of each background state
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
order
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="left" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Dependency order of the emission of the background states done by 
\begin_inset Formula $E$
\end_inset

.
 For example, if 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
order
\end_layout

\end_inset

 equals 3, then the emission is conditional on 2 previous observable variables.
 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
backgroundAmount
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell multicolumn="1" alignment="left" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none" width="10cm">
\begin_inset Text

\begin_layout Plain Layout

\lang english
Number of background states which are non-enhancers by having low transition
 probability into TF states
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\lang english
The prominent code files in the project:
\end_layout

\begin_layout Itemize

\series bold
\lang english
HOP-HMM/data/peaks/scripts/download_and_process_all.sh
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Linux bash script which downloads data files of epigenetic from Roadmap
 website, JASPAR PWMs and hg19 genome.
 After downloading, the data is per-processed with BEDtools and bigWigToBEDGraph.
 The only part in this project that requires Linux is the bigWigToBEDGraph.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/+peaks/minimizeMergePeak.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Reads downloaded bed files, processes them and saves them into MAT-file
 v7.3.
 
\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
 
\end_layout

\end_inset


\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
mergedPeaksMin = minimizeMergePeak(params, L)
\end_layout

\end_inset

;
\end_layout

\begin_layout Standard

\lang english
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
doGTBound
\end_layout

\end_inset

 indicates whether or not to apply regularization on 
\begin_inset Formula $T$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

 transition probabilities and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
doESharing
\end_layout

\end_inset

 indicates whether or not to force 
\begin_inset Formula $E$
\end_inset

 to share the emission across all background states 
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/misc/genSyntheticMergedPeaksMin.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Generates DNA sequences 
\begin_inset Formula $X$
\end_inset

 and hidden variables 
\begin_inset Formula $Y$
\end_inset

 out of a random 
\begin_inset Formula $\theta$
\end_inset

, which was sampled by genTheta.m
\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
params = genParams(m, k, backgroundAmount, L, order, doESharing, doGTBound);
\end_layout

\end_inset

 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
mergedPeaksMin = genSyntheticMergedPeaksMin(N, L, params,
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

startWithBackground, backgroundGNoise);
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
startWithBackground
\end_layout

\end_inset

 indicates whether or not to force 
\begin_inset Formula $\pi$
\end_inset

 to allow starting only from non-enhancer background states and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
backgroundGNoise
\end_layout

\end_inset

 is the background rate of background-to-TF state transition, marked as
 
\begin_inset Formula $noiseG$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "noiseG"

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/misc/genTheta.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Generates a random 
\begin_inset Formula $\theta$
\end_inset

, with options to sample a total random 
\begin_inset Formula $T$
\end_inset

 and a total random 
\begin_inset Formula $\pi$
\end_inset

.
 Note that 
\begin_inset Formula $\pi$
\end_inset

 is called 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
theta.startT
\end_layout

\end_inset

 throughout the code.
\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
params = genParams(m, k, backgroundAmount, L, order, true, true); 
\end_layout

\end_inset


\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
theta = genTheta(params, false, false);
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/mainRealData.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Entry point of the code, reads data from the human genome, trains HOP-HMMs
 model and compares posterior probability to real epigenetic data.
 Execution of mainRealData will produce figures similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RealSequences"

\end_inset


\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
mainRealData();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/mainPosterior.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Entry point of the code, follows the workflow of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

.
 Execution of mainPosterior plots random set of sequences with their Viterbi
 path and posterior probabilities similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "PostiriorProbability"

\end_inset

, and a confusion matrix similar to figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "ConfutionMatrix"

\end_inset

.
\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
mainPosterior();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/mainDecErrorPlot.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
Entry point of the code, follows the workflow of figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "Workflow"

\end_inset

.
 At each iteration of the EM, likelihood and errors are collected to form
 plots similar to figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization1"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "Regularization2"

\end_inset

.
\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
mainDecErrorPlot();
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\lang english
HOP-HMM/src/+EM/EM.m
\end_layout

\begin_deeper
\begin_layout Standard

\lang english
The function actually trains the HOP-HMM from a given DNA sequence is the
 EM().
 The neighboring code files residing in the +EM folder which contains it
 are the implementations of the E and M steps described in the introduction
 part of this work.
\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
[test, train] = misc.crossValidationSplit(params,
\begin_inset Newline newline
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

mergedPeaksMin, testTrainRatio);
\end_layout

\end_inset


\end_layout

\begin_layout Quote

\lang english
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
[bestTheta, bestLikelihood, bestThetas] = EM(train, params, 
\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset


\begin_inset space ~
\end_inset

maxIter, patience, repeat);
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lang english
where 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
maxIter
\end_layout

\end_inset

 is the maximal number of iterations allowed in a run, 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
parience
\end_layout

\end_inset

 is the number of iterations without likelihood increase allowed in a run
 and 
\begin_inset Flex Code
status open

\begin_layout Plain Layout

\lang english
repeat
\end_layout

\end_inset

 is the number of different runs with different initializations which are
 tried.
\end_layout

\end_deeper
\begin_layout Standard

\lang english
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ahituv et al.(2007)"
key "key-1"

\end_inset

 Ahituv, N., Zhu, Y., Visel, A., Holt, A., Afzal, V., Pennacchio, L.
 A., & Rubin, E.
 M.
 (2007).
 Deletion of ultraconserved elements yields viable mice.
 PLoS biology, 5(9), e234.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ainscough et al.(1998)"
key "key-57"

\end_inset

 Ainscough, R., Bardill, S., Barlow, K., Basham, V., Baynes, C., Beard, L., ...
 & Burrows, C.
 (1998).
 Genome sequence of the nematode C.
 elegans: a platform for investigating biology.
 Science, 282(5396), 2012-2018.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Alipanahi et al.(2015)"
key "key-2"

\end_inset

 Alipanahi, B., Delong, A., Weirauch, M.
 T., & Frey, B.
 J.
 (2015).
 Predicting the sequence specificities of DNA-and RNA-binding proteins by
 deep learning.
 Nature biotechnology, 33(8), 831.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Baum and Petrie(1966)"
key "key-4"

\end_inset

 Baum, L.
 E., & Petrie, T.
 (1966).
 Statistical inference for probabilistic functions of finite state Markov
 chains.
 The annals of mathematical statistics, 37(6), 1554-1563.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Bejerano et al.(2004)"
key "key-23"

\end_inset

 Bejerano, G., Pheasant, M., Makunin, I., Stephen, S., Kent, W.
 J., Mattick, J.
 S., & Haussler, D.
 (2004).
 Ultraconserved elements in the human genome.
 Science, 304(5675), 1321-1325.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Benko et al.(2009)"
key "key-6"

\end_inset

 Benko, S., Fantes, J.
 A., Amiel, J., Kleinjan, D., Thomas, S., Ramsay, J., et al.
 (2009).
 Highly conserved non.
 Nature Genetics 64(2), p.
 10-12.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Boyle et al.(2008)"
key "key-71"

\end_inset

 Boyle, A.
 P., Davis, S., Shulha, H.
 P., Meltzer, P., Margulies, E.
 H., Weng, Z., ...
 & Crawford, G.
 E.
 (2008).
 High-resolution mapping and characterization of open chromatin across the
 genome.
 Cell, 132(2), 311-322.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Burge and Karlin(1997)"
key "key-22"

\end_inset

 Burge, C., & Karlin, S.
 (1997).
 Prediction of complete gene structures in human genomic DNA.
 Journal of molecular biology, 268(1), 78-94.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Calo and Wysocka(2013)"
key "key-34"

\end_inset

 Calo, E., & Wysocka, J.
 (2013).
 Modification of enhancer chromatin: what, how, and why?.
 Molecular cell, 49(5), 825-837.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Claverie(1997)"
key "key-69"

\end_inset

 Claverie, J.
 M.
 (1997).
 Computational methods for the identification of genes in vertebrate genomic
 sequences.
 Human molecular genetics, 6(10), 1735-1744.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Creyghton et al.(2010)"
key "key-8"

\end_inset

 Creyghton, M.
 P., Cheng, A.
 W., Welstead, G.
 G., Kooistra, T., Carey, B.
 W., Steine, E.
 J., ...
 & Boyer, L.
 A.
 (2010).
 Histone H3K27ac separates active from poised enhancers and predicts development
al state.
 Proceedings of the National Academy of Sciences, 107(50), 21931-21936.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Cutter and Hayes(2015)"
key "key-9"

\end_inset

 Cutter, A.
 R., & Hayes, J.
 J.
 (2015).
 A brief review of nucleosome structure.
 FEBS letters, 589(20), 2914-2922.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "De Beer et al.(2014)"
key "key-5"

\end_inset

 De Beer, Z.
 W., Duong, T.
 A., Barnes, I., Wingfield, B.
 D., & Wingfield, M.
 J.
 (2014).
 Redefining Ceratocystis and allied genera.
 Studies in Mycology, 79, 187-219.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Doniger et al.(2005)"
key "key-12"

\end_inset

 Doniger, S.
 W., Huh, J., & Fay, J.
 C.
 (2005).
 Identification of functional transcription factor binding sites using closely
 related Saccharomyces species.
 Genome research, 15(5), 701-709.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Dupin et al.(2011)"
key "key-75"

\end_inset

 Dupin, M., Reynaud, P., Jarošík, V., Baker, R., Brunel, S., Eyre, D., ...
 & Makowski, D.
 (2011).
 Effects of the training dataset characteristics on the performance of nine
 species distribution models: application to Diabrotica virgifera virgifera.
 PLoS One, 6(6).
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Du Preez(1998)"
key "key-47"

\end_inset

 Du Preez, J.
 A.
 (1998).
 Efficient training of higher-order hidden Markov models using first-order
 representations.
 Computer speech & language, 12(1), 23-39.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Emison et al.(2005)"
key "key-13"

\end_inset

 Emison, E.
 S., McCallion, A.
 S., Kashuk, C.
 S., Bush, R.
 T., Grice, E., Lin, S., ...
 & Chakravarti, A.
 (2005).
 A common sex-dependent mutation in a RET enhancer underlies Hirschsprung
 disease risk.
 Nature, 434(7035), 857.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ernst and Kellis(2012)"
key "key-14"

\end_inset

 Ernst, J., & Kellis, M.
 (2012).
 ChromHMM: automating chromatin-state discovery and characterization.
 Nature methods, 9(3), 215.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ernst et al.(2011)"
key "key-15"

\end_inset

 Ernst, J., Kheradpour, P., Mikkelsen, T.
 S., Shoresh, N., Ward, L.
 D., Epstein, C.
 B., ...
 & Ku, M.
 (2011).
 Mapping and analysis of chromatin state dynamics in nine human cell types.
 Nature, 473(7345), 43.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ezkurdia et al.(2014)"
key "key-16"

\end_inset

 Ezkurdia, I., Juan, D., Rodriguez, J.
 M., Frankish, A., Diekhans, M., Harrow, J., ...
 & Tress, M.
 L.
 (2014).
 Multiple evidence strands suggest that there may be as few as 19 000 human
 protein-coding genes.
 Human molecular genetics, 23(22), 5866-5878.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ferguson(1980)"
key "key-17"

\end_inset

 Ferguson, J.
 D.
 (1980).
 pp.
 143–179, Variable duration models for speech.
 In Proc.
 of the Symposium on the applications of hidden Markov models to text and
 speech, JD Ferguson, Ed.
 Princeton: IDA-CRD.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Fishilevich et al.(2017)"
key "key-20"

\end_inset

 Fishilevich, S., Nudel, R., Rappaport, N., Hadar, R., Plaschkes, I., Iny Stein,
 T., ...
 & Lancet, D.
 (2017).
 GeneHancer: genome-wide integration of enhancers and target genes in GeneCards.
 Database, 2017.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Friedli et al.(2010)"
key "key-21"

\end_inset

 Friedli, M., Barde, I., Arcangeli, M., Verp, S., Quazzola, A., Zakany, J., ...
 & Duboule, D.
 (2010).
 A systematic enhancer screen using lentivector transgenesis identifies
 conserved and non-conserved functional elements at the Olig1 and Olig2
 locus.
 PLoS One, 5(12), e15741.
 
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Galperin and Fernández-Suarez(2012)"
key "key-18"

\end_inset

 Galperin, M.
 Y., & Fernández-Suarez, X.
 M.
 (2011).
 The 2012 nucleic acids research database issue and the online molecular
 biology database collection.
 Nucleic acids research, 40(D1), D1-D8.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Haussler and Eeckman(1996)"
key "key-24"

\end_inset

 Haussler, D.
 K.
 D., & Eeckman, M.
 G.
 R.
 F.
 H.
 (1996).
 A generalized hidden Markov model for the recognition of human genes in
 DNA.
 In Proc.
 int.
 conf.
 on intelligent systems for molecular biology, st.
 louis (pp.
 134-142).
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Hayashi-Takanaka et al.(2011)"
key "key-25"

\end_inset

 Hayashi-Takanaka, Y., Yamagata, K., Wakayama, T., Stasevich, T.
 J., Kainuma, T., Tsurimoto, T., ...
 & Kimura, H.
 (2011).
 Tracking epigenetic histone modifications in single cells using Fab-based
 live endogenous modification labeling.
 Nucleic acids research, 39(15), 6475-6488.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Heintzman et al.(2007)"
key "key-26"

\end_inset

 Heintzman, N.
 D., Stuart, R.
 K., Hon, G., Fu, Y., Ching, C.
 W., Hawkins, R.
 D., ...
 & Wang, W.
 (2007).
 Distinct and predictive chromatin signatures of transcriptional promoters
 and enhancers in the human genome.
 Nature genetics, 39(3), 311.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Heintzman et al.(2009)"
key "key-19"

\end_inset

 Heintzman, N.
 D., Hon, G.
 C., Hawkins, R.
 D., Kheradpour, P., Stark, A., Harp, L.
 F., ...
 & Ching, K.
 A.
 (2009).
 Histone modifications at human enhancers reflect global cell-type-specific
 gene expression.
 Nature, 459(7243), 108.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Hu et al.(1996)"
key "key-27"

\end_inset

 Hu, J., Brown, M.
 K., & Turin, W.
 (1996).
 HMM based online handwriting recognition.
 IEEE Transactions on pattern analysis and machine intelligence, 18(10),
 1039-1045.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Jin et al.(2011)"
key "key-28"

\end_inset

 Jin Q, Yu L-R, Wang L, Zhang Z, Kasper LH, Lee J-E, Wang C, Brindle PK,
 Dent SYR, Ge K.
 2011.
 Distinct roles of GCN5/PCAF-mediated H3K9ac and CBP/p300-mediated H3K18/27ac
 in nuclear receptor transactivation.
 The EMBO Journal 30:249–262.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Jones(2012)"
key "key-29"

\end_inset

 Jones, P.
 A.
 (2012).
 Functions of DNA methylation: islands, start sites, gene bodies and beyond.
 Nature Reviews Genetics, 13(7), 484.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kaplan and Biggin(2012)"
key "key-64"

\end_inset

 Kaplan, T., & Biggin, M.
 D.
 (2012).
 Quantitative models of the mechanisms that control genome-wide patterns
 of animal transcription factor binding.
 In Methods in cell biology (Vol.
 110, pp.
 263-283).
 Academic Press.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Karmodiya et al.(2012)"
key "key-30"

\end_inset

 Karmodiya, K., Krebs, A.
 R., Oulad-Abdelghani, M., Kimura, H., & Tora, L.
 (2012).
 H3K9 and H3K14 acetylation co-occur at many gene regulatory elements, while
 H3K14ac marks a subset of inactive inducible promoters in mouse embryonic
 stem cells.
 BMC genomics, 13(1), 424.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kelley et al.(2016)"
key "key-31"

\end_inset

 Kelley, D.
 R., Snoek, J., & Rinn, J.
 L.
 (2016).
 Basset: learning the regulatory code of the accessible genome with deep
 convolutional neural networks.
 Genome research, 26(7), 990-999.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Khan et al.(2018)"
key "key-32"

\end_inset

 Khan, A., Fornes, O., Stigliani, A., Gheorghe, M., Castro-Mondragon, J.
 A., van der Lee, R., ...
 & Baranasic, D.
 (2017).
 JASPAR 2018: update of the open-access database of transcription factor
 binding profiles and its web framework.
 Nucleic acids research, 46(D1), D260-D266.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kleftogiannis et al.(2016)"
key "key-33"

\end_inset

 Kleftogiannis, D., Kalnis, P., Arner, E., & Bajic, V.
 B.
 (2016).
 Discriminative identification of transcriptional responses of promoters
 and enhancers after stimulus.
 Nucleic acids research, 45(4), e25-e25.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kreimer et al.(2017)"
key "key-35"

\end_inset

 Kreimer, A., Zeng, H., Edwards, M.
 D., Guo, Y., Tian, K., Shin, S., ...
 & Li, Y.
 (2017).
 Predicting gene expression in massively parallel reporter assays: a comparative
 study.
 Human mutation, 38(9), 1240-1250.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kulakovskiy et al.(2011)"
key "key-36"

\end_inset

 Kulakovskiy, I.
 V., Belostotsky, A.
 A., Kasianov, A.
 S., Esipova, N.
 G., Medvedeva, Y.
 A., Eliseeva, I.
 A., & Makeev, V.
 J.
 (2011).
 A deeper look into transcription regulatory code by preferred pair distance
 templates for transcription factor binding sites.
 Bioinformatics, 27(19), 2621-2624.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Kundaje et al.(2015)"
key "key-37"

\end_inset

 Kundaje, A., Meuleman, W., Ernst, J., Bilenky, M., Yen, A., Heravi-Moussavi,
 A., ...
 & Amin, V.
 (2015).
 Integrative analysis of 111 reference human epigenomes.
 Nature, 518(7539), 317.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lee and Lee(2006)"
key "key-38"

\end_inset

 Lee, L.
 M., & Lee, J.
 C.
 (2006, June).
 A study on higher-order hidden Markov models and applications to speech
 recognition.
 In International Conference on Industrial, Engineering and Other Applications
 of Applied Intelligent Systems (pp.
 682-690).
 Springer, Berlin, Heidelberg.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lettice et al.(2003)"
key "key-39"

\end_inset

 Lettice, L.
 A., Heaney, S.
 J., Purdie, L.
 A., Li, L., de Beer, P., Oostra, B.
 A., ...
 & de Graaff, E.
 (2003).
 A long-range Shh enhancer regulates expression in the developing limb and
 fin and is associated with preaxial polydactyly.
 Human molecular genetics, 12(14), 1725-1735.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Lindblad-Toh et al.(2011)"
key "key-40"

\end_inset

 Lindblad-Toh, K., Garber, M., Zuk, O., Lin, M.
 F., Parker, B.
 J., Washietl, S., ...
 & Ward, L.
 D.
 (2011).
 A high-resolution map of human evolutionary constraint using 29 mammals.
 Nature, 478(7370), 476.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Mari et al.(1997)"
key "key-41"

\end_inset

 Mari, J.
 F., Haton, J.
 P., & Kriouile, A.
 (1997).
 Automatic word recognition based on second-order hidden Markov models.
 IEEE Transactions on speech and Audio Processing, 5(1), 22-25.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Markov(1906)"
key "key-42"

\end_inset

 Markov, A.
 A.
 (1906).
 Extension of the law of large numbers to dependent quantities.
 Izv.
 Fiz.-Matem.
 Obsch.
 Kazan Univ.(2nd Ser), 15, 135-156.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Miguel-Escalada et al.(2015)"
key "key-44"

\end_inset

 Miguel-Escalada, I., Pasquali, L., & Ferrer, J.
 (2015).
 Transcriptional enhancers: functional insights and role in human disease.
 Current opinion in genetics & development, 33, 71-76.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Ng et al.(2009)"
key "key-45"

\end_inset

 Ng, S.
 B., Turner, E.
 H., Robertson, P.
 D., Flygare, S.
 D., Bigham, A.
 W., Lee, C., ...
 & Bamshad, M.
 (2009).
 Targeted capture and massively parallel sequencing of 12 human exomes.
 Nature, 461(7261), 272.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Pennacchio et al.(2006)"
key "key-11"

\end_inset

 Pennacchio, L.
 A., Ahituv, N., Moses, A.
 M., Prabhakar, S., Nobrega, M.
 A., Shoukry, M., ...
 & Plajzer-Frick, I.
 (2006).
 In vivo enhancer analysis of human conserved non-coding sequences.
 Nature, 444(7118), 499-502.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Pennacchio et al.(2015)"
key "key-46"

\end_inset

 Pennacchio, L.
 A., Bickmore, W., Dean, A., Nobrega, M.
 A., & Bejerano, G.
 (2013).
 Enhancers: five essential questions.
 Nature Reviews Genetics, 14(4), 288.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Przybilla et al.(2012)"
key "key-48"

\end_inset

 Przybilla, J., Galle, J., & Rohlf, T.
 (2012).
 Is adult stem cell aging driven by conflicting modes of chromatin remodeling?.
 Bioessays, 34(10), 841-848.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Quinlan and Hall(2010)"
key "key-68"

\end_inset

 Quinlan, A.
 R., & Hall, I.
 M.
 (2010).
 BEDTools: a flexible suite of utilities for comparing genomic features.
 Bioinformatics, 26(6), 841-842.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rabiner and Juang(1993)"
key "key-49"

\end_inset

 Rabiner, L., & Juang, B.
 H.
 (1993).
 Fundamentals of speech processing.
 Prantice Hall.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rabiner(1989)"
key "key-50"

\end_inset

 Rabiner, L.
 R.
 (1989).
 A tutorial on hidden Markov models and selected applications in speech
 recognition.
 Proceedings of the IEEE, 77(2), 257-286.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rada-Iglesias et al.(2011)"
key "key-51"

\end_inset

 Rada-Iglesias, A., Bajpai, R., Swigut, T., Brugmann, S.
 A., Flynn, R.
 A., & Wysocka, J.
 (2011).
 A unique chromatin signature uncovers early developmental enhancers in
 humans.
 Nature, 470(7333), 279.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Rosin et al.(2013)"
key "key-52"

\end_inset

 Rosin, J.
 M., Abassah-Oppong, S., & Cobb, J.
 (2013).
 Comparative transgenic analysis of enhancers from the human SHOX and mouse
 Shox2 genomic regions.
 Human molecular genetics, 22(15), 3063-3076.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Smemo et al.(2012)"
key "key-53"

\end_inset

 Smemo, S., Campos, L.
 C., Moskowitz, I.
 P., Krieger, J.
 E., Pereira, A.
 C., & Nobrega, M.
 A.
 (2012).
 Regulatory variation in a TBX5 enhancer leads to isolated congenital heart
 disease.
 Human molecular genetics, 21(14), 3255-3263.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Soldner et al.(2016)"
key "key-54"

\end_inset

 Soldner, F., Stelzer, Y., Shivalila, C.
 S., Abraham, B.
 J., Latourelle, J.
 C., Barrasa, M.
 I., ...
 & Jaenisch, R.
 (2016).
 Parkinson-associated risk variant in distal enhancer of 
\begin_inset Formula $α$
\end_inset

-synuclein modulates target gene expression.
 Nature, 533(7601), 95.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Stadler et al.(2011)"
key "key-55"

\end_inset

 Stadler, M.
 B., Murr, R., Burger, L., Ivanek, R., Lienert, F., Schöler, A., ...
 & Tiwari, V.
 K.
 (2011).
 DNA-binding factors shape the mouse methylome at distal regulatory regions.
 Nature, 480(7378), 490.
 
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Stormo et al.(1982)"
key "key-7"

\end_inset

 Stormo, G.
 D., Schneider, T.
 D., Gold, L., & Ehrenfeucht, A.
 (1982).
 Use of the ‘Perceptron’ algorithm to distinguish translational initiation
 sites in E.
 coli.
 Nucleic acids research, 10(9), 2997-3011.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Taher et al.(2011)"
key "key-56"

\end_inset

 Taher, L., McGaughey, D.
 M., Maragh, S., Aneas, I., Bessling, S.
 L., Miller, W., ...
 & Ovcharenko, I.
 (2011).
 Genome-wide identification of conserved regulatory function in diverged
 sequences.
 Genome research, 21(7), 1139-1149.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Tate and Bird(1993)"
key "key-3"

\end_inset

 Tate, P.
 H., & Bird, A.
 P.
 (1993).
 Effects of DNA methylation on DNA-binding proteins and gene expression.
 Current opinion in genetics & development, 3(2), 226-231.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Thurman et al.(2012)"
key "key-58"

\end_inset

 Thurman, R.
 E., Rynes, E., Humbert, R., Vierstra, J., Maurano, M.
 T., Haugen, E., ...
 & Garg, K.
 (2012).
 The accessible chromatin landscape of the human genome.
 Nature, 489(7414), 75.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Turin and Sondhi(1993)"
key "key-59"

\end_inset

 Turin, W., & Sondhi, M.
 M.
 (1993).
 Modeling error sources in digital channels.
 IEEE Journal on Selected Areas in Communications, 11(3), 340-347.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2007)"
key "key-60"

\end_inset

 Visel, A., Minovitsky, S., Dubchak, I., & Pennacchio, L.
 A.
 (2007).
 VISTA Enhancer Browser—a database of tissue-specific human enhancers.
 Nucleic Acids Research, 35(Database issue), D88.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2008)"
key "key-70"

\end_inset

 Visel, A., Prabhakar, S., Akiyama, J.
 A., Shoukry, M., Lewis, K.
 D., Holt, A., ...
 & Pennacchio, L.
 A.
 (2008).
 Ultraconservation identifies a small subset of extremely constrained developmen
tal enhancers.
 Nature genetics, 40(2), 158-160.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Visel et al.(2009)"
key "key-61"

\end_inset

 Visel, A., Blow, M.
 J., Li, Z., Zhang, T., Akiyama, J.
 A., Holt, A., ...
 & Afzal, V.
 (2009).
 ChIP-seq accurately predicts tissue-specific activity of enhancers.
 Nature, 457(7231), 854.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Viterbi(1967)"
key "key-65"

\end_inset

 Viterbi, A.
 (1967).
 Error bounds for convolutional codes and an asymptotically optimum decoding
 algorithm.
 IEEE transactions on Information Theory, 13(2), 260-269.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Williamson et al.(2011)"
key "key-43"

\end_inset

 Williamson, I., Hill, R.
 E., & Bickmore, W.
 A.
 (2011).
 Enhancers: from developmental genetics to the genetics of common human
 disease.
 Developmental cell, 21(1), 17-19.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Winter et al.(1981)"
key "key-67"

\end_inset

 Winter, R.
 B., Berg, O.
 G., & Von Hippel, P.
 H.
 (1981).
 Diffusion-driven mechanisms of protein translocation on nucleic acids.
 3.
 The Escherichia coli lac repressor-operator interaction: kinetic measurements
 and conclusions.
 Biochemistry, 20(24), 6961-6977.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Yang et al.(2015)"
key "key-66"

\end_inset

Yang, F., Balakrishnan, S., & Wainwright, M.
 J.
 (2015, December).
 Statistical and computational guarantees for the Baum-Welch algorithm.
 In 2015 53rd Annual Allerton Conference on Communication, Control, and
 Computing (Allerton) (pp.
 658-665).
 IEEE.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zentner et al.(2011)"
key "key-62"

\end_inset

 Zentner, G.
 E., Tesar, P.
 J., & Scacheri, P.
 C.
 (2011).
 Epigenetic signatures distinguish multiple classes of enhancers with distinct
 cellular functions.
 Genome research, 21(8), 1273-1283.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zhang et al.(2008)"
key "key-73"

\end_inset

 Zhang, Y., Liu, T., Meyer, C.
 A., Eeckhoute, J., Johnson, D.
 S., Bernstein, B.
 E., ...
 & Liu, X.
 S.
 (2008).
 Model-based analysis of ChIP-Seq (MACS).
 Genome biology, 9(9), R137.
\end_layout

\begin_layout Bibliography

\lang english
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Zhou and Troyanskaya(2015)"
key "key-63"

\end_inset

 Zhou, J., & Troyanskaya, O.
 G.
 (2015).
 Predicting effects of noncoding variants with deep learning–based sequence
 model.
 Nature methods, 12(10), 931.
\end_layout

\end_body
\end_document
